{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xSItPJipBaZ5"
      },
      "source": [
        "## Gathering Dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "1a821417-b2e6-4bf3-ad0b-494bb85bea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.21.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_दिल्ली WIND SPEED_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.000000\n",
            "1       2.980000\n",
            "2       4.633333\n",
            "3       1.233333\n",
            "4       3.700000\n",
            "          ...   \n",
            "1457    3.547826\n",
            "1458    6.000000\n",
            "1459    6.266667\n",
            "1460    7.325000\n",
            "1461    0.000000\n",
            "Name: wind_speed, Length: 1462, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/delhi.csv\")\n",
        "training_set = data.iloc[:, 3]\n",
        "print(training_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, _and_ $\\frac{d^2x}{dt^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42.22\n",
            "1       2.980000\n",
            "2       1.653333\n",
            "3      -3.400000\n",
            "4       2.466667\n",
            "5      -2.220000\n",
            "          ...   \n",
            "1457   -4.787174\n",
            "1458    2.452174\n",
            "1459    0.266667\n",
            "1460    1.058333\n",
            "1461   -7.325000\n",
            "Name: wind_speed, Length: 1461, dtype: float64\n",
            "2      -1.326667\n",
            "3      -5.053333\n",
            "4       5.866667\n",
            "5      -4.686667\n",
            "6       7.040000\n",
            "          ...   \n",
            "1457   -4.337963\n",
            "1458    7.239348\n",
            "1459   -2.185507\n",
            "1460    0.791667\n",
            "1461   -8.383333\n",
            "Name: wind_speed, Length: 1460, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1 # Daily Data\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:]\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:]\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       2.980000\n",
            "1       1.653333\n",
            "2      -3.400000\n",
            "3       2.466667\n",
            "4      -2.220000\n",
            "          ...   \n",
            "1456   -4.787174\n",
            "1457    2.452174\n",
            "1458    0.266667\n",
            "1459    1.058333\n",
            "1460   -7.325000\n",
            "Name: wind_speed, Length: 1461, dtype: float64\n",
            "0      -1.326667\n",
            "1      -5.053333\n",
            "2       5.866667\n",
            "3      -4.686667\n",
            "4       7.040000\n",
            "          ...   \n",
            "1455   -4.337963\n",
            "1456    7.239348\n",
            "1457   -2.185507\n",
            "1458    0.791667\n",
            "1459   -8.383333\n",
            "Name: wind_speed, Length: 1460, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True)\n",
        "gradient_t = gradient_t.reset_index(drop=True)\n",
        "gradient_tt = gradient_tt.reset_index(drop=True)\n",
        "print(gradient_t)\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1461,)\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "print(gradient_t.shape)\n",
        "print(training_set.shape[:-1])\n",
        "df = pd.concat((training_set[:-1], gradient_t), axis=1)\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df[:-1], gradient_tt), axis=1)\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation (_Duffing Equation_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "45058d71-6952-4a40-afa5-84c2f42197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "a=0.5\n",
        "b=1\n",
        "c=3\n",
        "d=1\n",
        "L = df.iloc[:, 2] -c + d*df.iloc[:, 1] - a*df.iloc[:, 0] - b*df.iloc[:, 0]**3\n",
        "L.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI8Yfkw6oA0l",
        "outputId": "01d7b72a-3934-4f62-ca10-27be3fc0310c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var1(t-9)', 'var2(t-9)',\n",
              "       'var3(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var1(t-7)',\n",
              "       ...\n",
              "       'var3(t+361)', 'var1(t+362)', 'var2(t+362)', 'var3(t+362)',\n",
              "       'var1(t+363)', 'var2(t+363)', 'var3(t+363)', 'var1(t+364)',\n",
              "       'var2(t+364)', 'var3(t+364)'],\n",
              "      dtype='object', length=1125)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Supervised(df.values, n_in = 10, n_out = 365)\n",
        "dat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "f37830fc-a93f-4216-e5d6-8e44bb1f83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
            "10    0.000000   2.980000   4.633333   1.233333   3.700000   1.480000   \n",
            "11    2.980000   4.633333   1.233333   3.700000   1.480000   6.300000   \n",
            "12    4.633333   1.233333   3.700000   1.480000   6.300000   7.142857   \n",
            "13    1.233333   3.700000   1.480000   6.300000   7.142857  12.500000   \n",
            "14    3.700000   1.480000   6.300000   7.142857  12.500000   7.400000   \n",
            "\n",
            "    var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)  ...  var3(t+361)  var1(t+362)  \\\n",
            "10   6.300000   7.142857  12.500000   7.400000  ...    18.133333     1.850000   \n",
            "11   7.142857  12.500000   7.400000  10.571429  ...    -0.616667     1.233333   \n",
            "12  12.500000   7.400000  10.571429  13.228571  ...     7.958333     0.000000   \n",
            "13   7.400000  10.571429  13.228571   4.633333  ...   -10.200000     6.725000   \n",
            "14  10.571429  13.228571   4.633333   0.616667  ...     1.387500     3.250000   \n",
            "\n",
            "    var2(t+362)  var3(t+362)  var1(t+363)  var2(t+363)  var3(t+363)  \\\n",
            "10    -0.616667    -0.616667     1.233333    -1.233333     7.958333   \n",
            "11    -1.233333     7.958333     0.000000     6.725000   -10.200000   \n",
            "12     6.725000   -10.200000     6.725000    -3.475000     1.387500   \n",
            "13    -3.475000     1.387500     3.250000    -2.087500     3.712500   \n",
            "14    -2.087500     3.712500     1.162500     1.625000    -3.950000   \n",
            "\n",
            "    var1(t+364)  var2(t+364)  var3(t+364)  \n",
            "10       0.0000       6.7250   -10.200000  \n",
            "11       6.7250      -3.4750     1.387500  \n",
            "12       3.2500      -2.0875     3.712500  \n",
            "13       1.1625       1.6250    -3.950000  \n",
            "14       2.7875      -2.3250     3.448214  \n",
            "\n",
            "[5 rows x 1105 columns]\n",
            "Index(['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       ...\n",
            "       'var3(t+361)', 'var1(t+362)', 'var2(t+362)', 'var3(t+362)',\n",
            "       'var1(t+363)', 'var2(t+363)', 'var3(t+363)', 'var1(t+364)',\n",
            "       'var2(t+364)', 'var3(t+364)'],\n",
            "      dtype='object', length=1105)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 10, n_out = 365)\n",
        "data.drop(['var2(t-10)', 'var3(t-10)', 'var2(t-9)', 'var3(t-9)', 'var2(t-8)',\n",
        "       'var3(t-8)', 'var2(t-7)', 'var3(t-7)', 'var2(t-6)', 'var3(t-6)',\n",
        "       'var2(t-5)', 'var3(t-5)', 'var2(t-4)', 'var3(t-4)', 'var2(t-2)',\n",
        "       'var3(t-2)', 'var2(t-1)', 'var3(t-1)','var2(t-3)', 'var3(t-3)'], axis = 1, inplace = True)#,18,19\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKb5l_gUaFvi"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOndQpQaFvi",
        "outputId": "56d94a79-1d05-4ff7-d70e-e2d8d00c83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(868, 1, 1096) (868, 9) (218, 1, 1096) (218, 9)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "test_size = len(data) - train_size\n",
        "train_1 = np.array(data[0:train_size])\n",
        "test_1 = np.array(data[train_size:len(data)])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train = scaler.fit_transform(train_1)\n",
        "test = scaler.transform(test_1)\n",
        "trainY = train[:,-9:]\n",
        "trainX = train[:,:-9]\n",
        "testY = test[:,-9:]\n",
        "testX = test[:,:-9]\n",
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-D_j8UaFvj"
      },
      "source": [
        "## Defining the Physical Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Jw7vitLaFvj"
      },
      "outputs": [],
      "source": [
        "a = tf.Variable(0.5, name=\"alpha\", trainable=True, dtype=tf.float32)\n",
        "b = tf.Variable(1, name=\"beta\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(3, name=\"gamma\", trainable=True, dtype=tf.float32)\n",
        "d = tf.Variable(1, name=\"delta\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def phys(y_pred, y_true):\n",
        "    return mean_absolute_error((y_true[:, 2] -c + d*y_true[:, 1] - a*y_true[:, 0] - b*y_true[:, 0]**3), (y_pred[:, 2] -c + d*y_pred[:, 1] - a*y_pred[:, 0] - b*y_pred[:, 0]**3))\n",
        "\n",
        "def phys2(y_pred, y_real):\n",
        "    pred = y_pred[2:]-2*y_pred[1:-1]-y_pred[:-2] -c + d*(y_pred[1:-1]-y_pred[:-2]) - a*y_pred[:-2] - b*y_pred[:-2]**3\n",
        "    real = y_real[2:]-2*y_real[1:-1]-y_real[:-2] -c + d*(y_real[1:-1]-y_real[:-2]) - a*y_real[:-2] - b*y_real[:-2]**3\n",
        "    return(mean_absolute_error(pred, real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874xZ-_u7X_s",
        "outputId": "883c11bb-1fe0-48af-e119-65529c186443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "14/14 [==============================] - 3s 50ms/step - loss: 0.0643 - val_loss: 0.0369\n",
            "Epoch 2/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0287 - val_loss: 0.0245\n",
            "Epoch 3/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0179\n",
            "Epoch 4/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0149\n",
            "Epoch 5/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0145\n",
            "Epoch 6/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0150\n",
            "Epoch 7/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0160\n",
            "Epoch 8/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0171\n",
            "Epoch 9/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0177\n",
            "Epoch 10/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0155 - val_loss: 0.0174\n",
            "Epoch 11/500\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0163\n",
            "Epoch 12/500\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0155\n",
            "Epoch 13/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0152\n",
            "Epoch 14/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0150\n",
            "Epoch 15/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0146\n",
            "Epoch 16/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 17/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0140\n",
            "Epoch 18/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0136\n",
            "Epoch 19/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0133\n",
            "Epoch 20/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0129\n",
            "Epoch 21/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0125\n",
            "Epoch 22/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0124\n",
            "Epoch 23/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0126\n",
            "Epoch 24/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0127\n",
            "Epoch 25/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0116\n",
            "Epoch 26/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 27/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0263\n",
            "Epoch 28/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0156\n",
            "Epoch 29/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0146\n",
            "Epoch 30/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0149\n",
            "Epoch 31/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0121\n",
            "Epoch 32/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0126\n",
            "Epoch 33/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0130\n",
            "Epoch 34/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0177\n",
            "Epoch 35/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0155\n",
            "Epoch 36/500\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0153\n",
            "Epoch 37/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0141\n",
            "Epoch 38/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0119\n",
            "Epoch 39/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0124\n",
            "Epoch 40/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0125\n",
            "Epoch 41/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0139\n",
            "Epoch 42/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0128\n",
            "Epoch 43/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0146\n",
            "Epoch 44/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0118\n",
            "Epoch 45/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0116\n",
            "Epoch 46/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0125\n",
            "Epoch 47/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0149\n",
            "Epoch 48/500\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0188\n",
            "Epoch 49/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0136\n",
            "Epoch 50/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0283\n",
            "Epoch 51/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0106\n",
            "Epoch 52/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0140\n",
            "Epoch 53/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0105\n",
            "Epoch 54/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0143\n",
            "Epoch 55/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0105\n",
            "Epoch 56/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0108\n",
            "Epoch 57/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0181\n",
            "Epoch 58/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0130\n",
            "Epoch 59/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0126\n",
            "Epoch 60/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0148\n",
            "Epoch 61/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0148\n",
            "Epoch 62/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0100\n",
            "Epoch 63/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0149\n",
            "Epoch 64/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0130\n",
            "Epoch 65/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.0108\n",
            "Epoch 66/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0104\n",
            "Epoch 67/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0145\n",
            "Epoch 68/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0137\n",
            "Epoch 69/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0100\n",
            "Epoch 70/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0097\n",
            "Epoch 71/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0161\n",
            "Epoch 72/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0130\n",
            "Epoch 73/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0100\n",
            "Epoch 74/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0131\n",
            "Epoch 75/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0102\n",
            "Epoch 76/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0165\n",
            "Epoch 77/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0094\n",
            "Epoch 78/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0117\n",
            "Epoch 79/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0186\n",
            "Epoch 80/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0111\n",
            "Epoch 81/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0138\n",
            "Epoch 82/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0126\n",
            "Epoch 83/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0104\n",
            "Epoch 84/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0126\n",
            "Epoch 85/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0092\n",
            "Epoch 86/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0114\n",
            "Epoch 87/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0168\n",
            "Epoch 88/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0107\n",
            "Epoch 89/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0126\n",
            "Epoch 90/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0116\n",
            "Epoch 91/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0101\n",
            "Epoch 92/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0100\n",
            "Epoch 93/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0184\n",
            "Epoch 94/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0103\n",
            "Epoch 95/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0091\n",
            "Epoch 96/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0153\n",
            "Epoch 97/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0121\n",
            "Epoch 98/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0097\n",
            "Epoch 99/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0098\n",
            "Epoch 100/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0113\n",
            "Epoch 101/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0122\n",
            "Epoch 102/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0091\n",
            "Epoch 103/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0104\n",
            "Epoch 104/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0135\n",
            "Epoch 105/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0152\n",
            "Epoch 106/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0108\n",
            "Epoch 107/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0157\n",
            "Epoch 108/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0141\n",
            "Epoch 109/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0098\n",
            "Epoch 110/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0119\n",
            "Epoch 111/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0085\n",
            "Epoch 112/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0135\n",
            "Epoch 113/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0134\n",
            "Epoch 114/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0094\n",
            "Epoch 115/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0088\n",
            "Epoch 116/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0134\n",
            "Epoch 117/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0109\n",
            "Epoch 118/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0090\n",
            "Epoch 119/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0092\n",
            "Epoch 120/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0093\n",
            "Epoch 121/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0110\n",
            "Epoch 122/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0172\n",
            "Epoch 123/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0188\n",
            "Epoch 124/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0114\n",
            "Epoch 125/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0093\n",
            "Epoch 126/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0095\n",
            "Epoch 127/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0091\n",
            "Epoch 128/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0148\n",
            "Epoch 129/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0093\n",
            "Epoch 130/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0114\n",
            "Epoch 131/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0149\n",
            "Epoch 132/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0099\n",
            "Epoch 133/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0100\n",
            "Epoch 134/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0108\n",
            "Epoch 135/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0109\n",
            "Epoch 136/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0086\n",
            "Epoch 137/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0100\n",
            "Epoch 138/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0118\n",
            "Epoch 139/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0124\n",
            "Epoch 140/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0100\n",
            "Epoch 141/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0113\n",
            "Epoch 142/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0090\n",
            "Epoch 143/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0135\n",
            "Epoch 144/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0086\n",
            "Epoch 145/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0157\n",
            "Epoch 146/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0088\n",
            "Epoch 147/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0096\n",
            "Epoch 148/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0113\n",
            "Epoch 149/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0118\n",
            "Epoch 150/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0095\n",
            "Epoch 151/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0104\n",
            "Epoch 152/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0083\n",
            "Epoch 153/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0131\n",
            "Epoch 154/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0079\n",
            "Epoch 155/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0132\n",
            "Epoch 156/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0115\n",
            "Epoch 157/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0089\n",
            "Epoch 158/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0088\n",
            "Epoch 159/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0119\n",
            "Epoch 160/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0101\n",
            "Epoch 161/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0092\n",
            "Epoch 162/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0087\n",
            "Epoch 163/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0086\n",
            "Epoch 164/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0084\n",
            "Epoch 165/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0169\n",
            "Epoch 166/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0093\n",
            "Epoch 167/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0084\n",
            "Epoch 168/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0083\n",
            "Epoch 169/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0134\n",
            "Epoch 170/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0093\n",
            "Epoch 171/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0099\n",
            "Epoch 172/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0089\n",
            "Epoch 173/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0088\n",
            "Epoch 174/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0077\n",
            "Epoch 175/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0172\n",
            "Epoch 176/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0082\n",
            "Epoch 177/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0087\n",
            "Epoch 178/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0088\n",
            "Epoch 179/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0085\n",
            "Epoch 180/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0087\n",
            "Epoch 181/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0112\n",
            "Epoch 182/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0187\n",
            "Epoch 183/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0058 - val_loss: 0.0206\n",
            "Epoch 184/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0101\n",
            "Epoch 185/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0092\n",
            "Epoch 186/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0085\n",
            "Epoch 187/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0076\n",
            "Epoch 188/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0144\n",
            "Epoch 189/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0078\n",
            "Epoch 190/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0143\n",
            "Epoch 191/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0083\n",
            "Epoch 192/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0082\n",
            "Epoch 193/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0086\n",
            "Epoch 194/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0103\n",
            "Epoch 195/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0133\n",
            "Epoch 196/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0124\n",
            "Epoch 197/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0089\n",
            "Epoch 198/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0086\n",
            "Epoch 199/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0132\n",
            "Epoch 200/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0072\n",
            "Epoch 201/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0159\n",
            "Epoch 202/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0085\n",
            "Epoch 203/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0102\n",
            "Epoch 204/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0137\n",
            "Epoch 205/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0085\n",
            "Epoch 206/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0082\n",
            "Epoch 207/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0107\n",
            "Epoch 208/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0095\n",
            "Epoch 209/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0082\n",
            "Epoch 210/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0081\n",
            "Epoch 211/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0077\n",
            "Epoch 212/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0082\n",
            "Epoch 213/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0139\n",
            "Epoch 214/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0190\n",
            "Epoch 215/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0085\n",
            "Epoch 216/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0076\n",
            "Epoch 217/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0125\n",
            "Epoch 218/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0072\n",
            "Epoch 219/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0138\n",
            "Epoch 220/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0079\n",
            "Epoch 221/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0086\n",
            "Epoch 222/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0100\n",
            "Epoch 223/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0092\n",
            "Epoch 224/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0081\n",
            "Epoch 225/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0075\n",
            "Epoch 226/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0069\n",
            "Epoch 227/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0167\n",
            "Epoch 228/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0061 - val_loss: 0.0087\n",
            "Epoch 229/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0077\n",
            "Epoch 230/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0074\n",
            "Epoch 231/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0080\n",
            "Epoch 232/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0138\n",
            "Epoch 233/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0080\n",
            "Epoch 234/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0074\n",
            "Epoch 235/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0070\n",
            "Epoch 236/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0132\n",
            "Epoch 237/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0096\n",
            "Epoch 238/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0090\n",
            "Epoch 239/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0079\n",
            "Epoch 240/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0071\n",
            "Epoch 241/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0147\n",
            "Epoch 242/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0066\n",
            "Epoch 243/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0134\n",
            "Epoch 244/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0086\n",
            "Epoch 245/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0076\n",
            "Epoch 246/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0075\n",
            "Epoch 247/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0077\n",
            "Epoch 248/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0108\n",
            "Epoch 249/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0170\n",
            "Epoch 250/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0098\n",
            "Epoch 251/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0082\n",
            "Epoch 252/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0114\n",
            "Epoch 253/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0070\n",
            "Epoch 254/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0099\n",
            "Epoch 255/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0114\n",
            "Epoch 256/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0078\n",
            "Epoch 257/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0073\n",
            "Epoch 258/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0086\n",
            "Epoch 259/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0123\n",
            "Epoch 260/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0073\n",
            "Epoch 261/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0070\n",
            "Epoch 262/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0084\n",
            "Epoch 263/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0137\n",
            "Epoch 264/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0092\n",
            "Epoch 265/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0048 - val_loss: 0.0075\n",
            "Epoch 266/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 267/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0129\n",
            "Epoch 268/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0066\n",
            "Epoch 269/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0107\n",
            "Epoch 270/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0114\n",
            "Epoch 271/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0075\n",
            "Epoch 272/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 273/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0098\n",
            "Epoch 274/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0109\n",
            "Epoch 275/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0075\n",
            "Epoch 276/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 277/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0073\n",
            "Epoch 278/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0142\n",
            "Epoch 279/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0082\n",
            "Epoch 280/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0069\n",
            "Epoch 281/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 282/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0115\n",
            "Epoch 283/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0103\n",
            "Epoch 284/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0084\n",
            "Epoch 285/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0073\n",
            "Epoch 286/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0071\n",
            "Epoch 287/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0130\n",
            "Epoch 288/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0064\n",
            "Epoch 289/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0121\n",
            "Epoch 290/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0093\n",
            "Epoch 291/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0070\n",
            "Epoch 292/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0067\n",
            "Epoch 293/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0103\n",
            "Epoch 294/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0117\n",
            "Epoch 295/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0081\n",
            "Epoch 296/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 297/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0082\n",
            "Epoch 298/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0118\n",
            "Epoch 299/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0068\n",
            "Epoch 300/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0089\n",
            "Epoch 301/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0129\n",
            "Epoch 302/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0077\n",
            "Epoch 303/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0067\n",
            "Epoch 304/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0071\n",
            "Epoch 305/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0139\n",
            "Epoch 306/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0069\n",
            "Epoch 307/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0077\n",
            "Epoch 308/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0101\n",
            "Epoch 309/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0099\n",
            "Epoch 310/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0082\n",
            "Epoch 311/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 312/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0062\n",
            "Epoch 313/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0150\n",
            "Epoch 314/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0063\n",
            "Epoch 315/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0108\n",
            "Epoch 316/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0114\n",
            "Epoch 317/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0072\n",
            "Epoch 318/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0064\n",
            "Epoch 319/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0123\n",
            "Epoch 320/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0079\n",
            "Epoch 321/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0089\n",
            "Epoch 322/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0071\n",
            "Epoch 323/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 324/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0079\n",
            "Epoch 325/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0145\n",
            "Epoch 326/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0071\n",
            "Epoch 327/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0067\n",
            "Epoch 328/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0098\n",
            "Epoch 329/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0113\n",
            "Epoch 330/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0077\n",
            "Epoch 331/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0067\n",
            "Epoch 332/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0084\n",
            "Epoch 333/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0114\n",
            "Epoch 334/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0067\n",
            "Epoch 335/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0079\n",
            "Epoch 336/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0123\n",
            "Epoch 337/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0086\n",
            "Epoch 338/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0068\n",
            "Epoch 339/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 340/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0114\n",
            "Epoch 341/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0092\n",
            "Epoch 342/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0081\n",
            "Epoch 343/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 344/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0066\n",
            "Epoch 345/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0140\n",
            "Epoch 346/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0065\n",
            "Epoch 347/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0084\n",
            "Epoch 348/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0114\n",
            "Epoch 349/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0075\n",
            "Epoch 350/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 351/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 352/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0141\n",
            "Epoch 353/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0068\n",
            "Epoch 354/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0080\n",
            "Epoch 355/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0083\n",
            "Epoch 356/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0073\n",
            "Epoch 357/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 358/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0070\n",
            "Epoch 359/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0111\n",
            "Epoch 360/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0213\n",
            "Epoch 361/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0074\n",
            "Epoch 362/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 363/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0107\n",
            "Epoch 364/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0075\n",
            "Epoch 365/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0081\n",
            "Epoch 366/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0075\n",
            "Epoch 367/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 368/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0063\n",
            "Epoch 369/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0102\n",
            "Epoch 370/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0172\n",
            "Epoch 371/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0074\n",
            "Epoch 372/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0061\n",
            "Epoch 373/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0117\n",
            "Epoch 374/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0070\n",
            "Epoch 375/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0094\n",
            "Epoch 376/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0076\n",
            "Epoch 377/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0062\n",
            "Epoch 378/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0061\n",
            "Epoch 379/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0143\n",
            "Epoch 380/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0068\n",
            "Epoch 381/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0075\n",
            "Epoch 382/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0073\n",
            "Epoch 383/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0069\n",
            "Epoch 384/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0075\n",
            "Epoch 385/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0105\n",
            "Epoch 386/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0176\n",
            "Epoch 387/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0082\n",
            "Epoch 388/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0066\n",
            "Epoch 389/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0106\n",
            "Epoch 390/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 391/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0095\n",
            "Epoch 392/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0114\n",
            "Epoch 393/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0071\n",
            "Epoch 394/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0059\n",
            "Epoch 395/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0115\n",
            "Epoch 396/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0078\n",
            "Epoch 397/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0082\n",
            "Epoch 398/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0063\n",
            "Epoch 399/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0059\n",
            "Epoch 400/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0116\n",
            "Epoch 401/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0100\n",
            "Epoch 402/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0074\n",
            "Epoch 403/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 404/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0106\n",
            "Epoch 405/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0084\n",
            "Epoch 406/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0071\n",
            "Epoch 407/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 408/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0072\n",
            "Epoch 409/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0109\n",
            "Epoch 410/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0142\n",
            "Epoch 411/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0067\n",
            "Epoch 412/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0057\n",
            "Epoch 413/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0128\n",
            "Epoch 414/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0064\n",
            "Epoch 415/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0107\n",
            "Epoch 416/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0083\n",
            "Epoch 417/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0061\n",
            "Epoch 418/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 419/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0121\n",
            "Epoch 420/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0063\n",
            "Epoch 421/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0096\n",
            "Epoch 422/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0118\n",
            "Epoch 423/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0067\n",
            "Epoch 424/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0085\n",
            "Epoch 425/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0115\n",
            "Epoch 426/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0069\n",
            "Epoch 427/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0082\n",
            "Epoch 428/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0122\n",
            "Epoch 429/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0069\n",
            "Epoch 430/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0063\n",
            "Epoch 431/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0093\n",
            "Epoch 432/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0021 - val_loss: 0.0114\n",
            "Epoch 433/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0071\n",
            "Epoch 434/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0058\n",
            "Epoch 435/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0091\n",
            "Epoch 436/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0111\n",
            "Epoch 437/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0069\n",
            "Epoch 438/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 439/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0100\n",
            "Epoch 440/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0109\n",
            "Epoch 441/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0069\n",
            "Epoch 442/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0057\n",
            "Epoch 443/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0092\n",
            "Epoch 444/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0117\n",
            "Epoch 445/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0070\n",
            "Epoch 446/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0070\n",
            "Epoch 447/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0117\n",
            "Epoch 448/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0081\n",
            "Epoch 449/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0064\n",
            "Epoch 450/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0061\n",
            "Epoch 451/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0092\n",
            "Epoch 452/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0140\n",
            "Epoch 453/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0071\n",
            "Epoch 454/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.0059\n",
            "Epoch 455/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0091\n",
            "Epoch 456/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0110\n",
            "Epoch 457/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0069\n",
            "Epoch 458/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 459/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0090\n",
            "Epoch 460/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0124\n",
            "Epoch 461/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0071\n",
            "Epoch 462/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0058\n",
            "Epoch 463/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0084\n",
            "Epoch 464/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0127\n",
            "Epoch 465/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0069\n",
            "Epoch 466/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 467/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0098\n",
            "Epoch 468/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0095\n",
            "Epoch 469/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 470/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0057\n",
            "Epoch 471/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0071\n",
            "Epoch 472/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0145\n",
            "Epoch 473/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0069\n",
            "Epoch 474/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0069\n",
            "Epoch 475/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0082\n",
            "Epoch 476/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0069\n",
            "Epoch 477/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0066\n",
            "Epoch 478/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0072\n",
            "Epoch 479/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.0107\n",
            "Epoch 480/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0173\n",
            "Epoch 481/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0068\n",
            "Epoch 482/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0057\n",
            "Epoch 483/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0082\n",
            "Epoch 484/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0114\n",
            "Epoch 485/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0070\n",
            "Epoch 486/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0058\n",
            "Epoch 487/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0083\n",
            "Epoch 488/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0127\n",
            "Epoch 489/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0079\n",
            "Epoch 490/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0059\n",
            "Epoch 491/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0101\n",
            "Epoch 492/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0091\n",
            "Epoch 493/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0067\n",
            "Epoch 494/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 495/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0092\n",
            "Epoch 496/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0124\n",
            "Epoch 497/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 498/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0031 - val_loss: 0.0057\n",
            "Epoch 499/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0097\n",
            "Epoch 500/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0104\n"
          ]
        }
      ],
      "source": [
        "a = tf.Variable(0.1, name=\"alpha\", trainable=True, dtype=tf.float32)\n",
        "b = tf.Variable(0.05, name=\"beta\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(1.1, name=\"gamma\", trainable=True, dtype=tf.float32)\n",
        "d = tf.Variable(0.1, name=\"delta\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(y_pred[:, 2] -c + d*y_pred[:, 1] - a*y_pred[:, 0] - b*y_pred[:, 0]**3)\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(9))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=500, batch_size=64, validation_data=(testX, testY), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "(218, 9)\n",
            "(218, 1096)\n",
            "Test RMSE: 14.930\n",
            "Test MAE: 14.371\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "yhat = model.predict(testX)\n",
        "print(yhat.shape)\n",
        "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
        "print(testX.shape)\n",
        "inv_yhat = np.concatenate((testX, yhat), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat1 = inv_yhat[:, -3:]\n",
        "inv_yhat = inv_yhat[:, -3]\n",
        "inv_y = np.concatenate((testX, testY), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y1 = inv_y[:, -3:]\n",
        "inv_y = inv_y[:, -3]\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
