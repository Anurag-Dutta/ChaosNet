{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xSItPJipBaZ5"
      },
      "source": [
        "## Gathering Dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "1a821417-b2e6-4bf3-ad0b-494bb85bea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.3.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.21.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_दिल्ली WIND SPEED_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.000000\n",
            "1       2.980000\n",
            "2       4.633333\n",
            "3       1.233333\n",
            "4       3.700000\n",
            "          ...   \n",
            "1457    3.547826\n",
            "1458    6.000000\n",
            "1459    6.266667\n",
            "1460    7.325000\n",
            "1461    0.000000\n",
            "Name: wind_speed, Length: 1462, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/delhi.csv\")\n",
        "training_set = data.iloc[:, 3]\n",
        "print(training_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, _and_ $\\frac{d^2x}{dt^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42.22\n",
            "1       2.980000\n",
            "2       1.653333\n",
            "3      -3.400000\n",
            "4       2.466667\n",
            "5      -2.220000\n",
            "          ...   \n",
            "1457   -4.787174\n",
            "1458    2.452174\n",
            "1459    0.266667\n",
            "1460    1.058333\n",
            "1461   -7.325000\n",
            "Name: wind_speed, Length: 1461, dtype: float64\n",
            "2      -1.326667\n",
            "3      -5.053333\n",
            "4       5.866667\n",
            "5      -4.686667\n",
            "6       7.040000\n",
            "          ...   \n",
            "1457   -4.337963\n",
            "1458    7.239348\n",
            "1459   -2.185507\n",
            "1460    0.791667\n",
            "1461   -8.383333\n",
            "Name: wind_speed, Length: 1460, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1 # Daily Data\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:]\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:]\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       2.980000\n",
            "1       1.653333\n",
            "2      -3.400000\n",
            "3       2.466667\n",
            "4      -2.220000\n",
            "          ...   \n",
            "1456   -4.787174\n",
            "1457    2.452174\n",
            "1458    0.266667\n",
            "1459    1.058333\n",
            "1460   -7.325000\n",
            "Name: wind_speed, Length: 1461, dtype: float64\n",
            "0      -1.326667\n",
            "1      -5.053333\n",
            "2       5.866667\n",
            "3      -4.686667\n",
            "4       7.040000\n",
            "          ...   \n",
            "1455   -4.337963\n",
            "1456    7.239348\n",
            "1457   -2.185507\n",
            "1458    0.791667\n",
            "1459   -8.383333\n",
            "Name: wind_speed, Length: 1460, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True)\n",
        "gradient_t = gradient_t.reset_index(drop=True)\n",
        "gradient_tt = gradient_tt.reset_index(drop=True)\n",
        "print(gradient_t)\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1461,)\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "print(gradient_t.shape)\n",
        "print(training_set.shape[:-1])\n",
        "df = pd.concat((training_set[:-1], gradient_t), axis=1)\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df[:-1], gradient_tt), axis=1)\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation (_Lorrenz Equation_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "45058d71-6952-4a40-afa5-84c2f42197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD4CAYAAAD//dEpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABKuElEQVR4nO2dd5gV1fnHv+/dXXpZOgroUhVEQUEEKygiGiPGGIOJSoyRWOLPlgIxscQYoykmpmiIGkuMikYjERSBqNgAQVEEBVZAeu9l6z2/P+bMvefOnGl3Zm7ZfT/Ps8/ee6ade2bmvOct5z0khADDMAzDeJHIdwUYhmGY4oAFBsMwDOMLFhgMwzCML1hgMAzDML5ggcEwDMP4ojTfFYiLjh07ioqKinxXg2EYpqhYtGjRdiFEJ922BiswKioqsHDhwnxXg2EYpqggoi+dtrFJimEYhvEFCwyGYRjGFywwGIZhGF+wwGAYhmF8wQKDYRiG8QULDIZhGMYXLDAYhmEYXxSNwCCisUS0nIgqiWhSvutTW59EdV19vqtREGzdV4WZSzfnuxoMw8RMUQgMIioB8BcA5wIYAOBSIhqQi2vvq6rVll/w53dx1M9ey0UVYqOmLoko1kO5dMo8fP+pRVi5ZV8EtWIYO/NX7cCHa3fluxqNnqIQGACGAagUQqwSQtQAeBbAuDgu9PLiDfjGw++huq4eLyxaj2PvfB2VW+0d4Web9sZx+ZxxsKYO/X72Ku57bTlue2kJnnhvDapq67G/ug7XPLUIW/dW4ZG3V2H+qh2pY/ZW1eLBOStRn8wUMl9sOwAAOPuBudhzUC9gi52t+6rw70XrkUx6C9hDNfW45bnFWLpxDyomTccDs1bkoIbx894X2/GH2SuwdW9VJOd7at6XeH3pZjz2zmrsr65z3K+qth7fnDIPF/31vUiuy2RPsaQG6QZgnfJ9PYCT4rjQlr1V+GDNLtTWC0z/ZCMAYO3Og+jTuXUcl8sbu2TH/vBbX6TKlm/Zh/5dW+O1pZvRoVUTPD1/LQBgza+/AgC4d8ZneGbBOvTt3ArnHnuY9rzV9fUAyuKtfB648M/vYuOeKmzYfQgTRlSgbQvn3/j3t1fhxY82AGR8/+Oclbj57H45qmk87DlYi2/9fT4AYMaSTXj95jNCn/Pn//k09Xn19gO4+8KB2v1+NeOz0NdioqFYNAxfENFEIlpIRAu3bduW1TlKE0aT1NUnU6Oelk2KRa76p77ePlKu3Lo/9XnTHvsocs8hQ8jUC4ENuw/hI42J4PNNDdMstVG2x+9nrcD1//oQm/dUoapW78OqqUsCAI5s3zJVVjFpelF3fDX1ydTnFVv227bvq6rFlzsO2MqFEBmmytr6JFZtsx9/oMZZw1i1zX5eJj8Ui8DYAKCH8r27LMtACDFFCDFUCDG0UydtskVPykqMYWFtvcCOAzUAgOZNSrI6Vz7ZJevuRG0yaStbsz39Yv7v862pz++s3A4AqJNCpjSRwKjfvImvaUwEVzy2IOM8DZG1Ow9i+L1zMPGpRdrtiYTxDNXUZwqUKXNXYeu+Krzx+Va8W7k9Y9veqlrU1tvvSb544r01uOPltAaQ9PB1jZ8yD2f85k1b+YsfbsDZD8zFWyuMAdyd05bizN+9hZue/Shjv6alme+YEAJT5n6BHfurXbU5ANh9sAY3PPMR9jr4G5noKBaB8QGAvkTUk4iaABgPYFocFyotkRpGMpka2fgwW0MIgXumL8MXmtFTrpm/ageOv3sWXneJXLL6IQBg675qvPfFDlv5ZY/Ox96q2tQx1/xzUWrEqXOab9tfjWRSYNayLbbtq7btj8wGni0Tn1yIv89dlfXxZuc5d4Vei5WWKFTX2gXAsHvm4MrHP8C3H5mPB+esxDkPzMWmPYdw3J2v49p/6gWQG8s27sWKGIIN7pi2FE+8byQt/XjdbmzbV+26/9KNhk/Per837D4EAJgnfWFzVxpt9p/FGzP2W7llH3bsr8aB6jrU1ifx7Ufm41czPsfkF5egpceA7aG3vsB/P96If85zTLLaYNl1oMZR042DohAYQog6AD8AMBPAZwCmCiGWxnGtUjk6rFNMNkkhsGzjXnz/qYWOo8D1uw7h72+vxncf/yCOavlm7Y6DeGHRegDA/NU7sXH3IVzx2IKMaK93K7fjUI3+IXv1U72QEQKo1QiZSf9eYiurrk3i6flf4uonF+LFDzMVwTN/9xaG/WqO798TB68v24J7ApqHShKU+qwK2+WbMzvrT9bvTj0jVR5h17+ftQLLt+zDiHv/BwCY/Vlaq1uxZR9W+9DUznvwbYx5YK73DwjBuL+8i/P/9I6vfd9YvjXje7uWTQAAu6XPrEojRAFg4Ze7MOSXs3HMHTPxw+c/Tg1cDtXWY+rC9dpjTr53Dp56fw1IiugIAv6Khrr6JA7V1OP4u2fhwr+8C8AYjL3yyUaPI8NRFAIDAIQQM4QQ/YQQvYUQ98R1nTKpYZx2/xupsmRS4JapizFz6ZZUZ2yvn9w3z0/t6b95A8/LOiaFwAOzVmDuim14dYkhCD7dsAfffmQ+7vpvMHm791CtdkT93MJ1trJbn1+csvlvzrM2EZRkUmi1RFVgqIOGTXsOpT5/umEPLvjzu/jrm0YgwaGa7E1MYx6Yi1G/fdNx+/LN+wpyHtAjb68GAOw8UIPH3lmd0rY27D6EP81Z6ampAMDLivZRZ/G1JZMCB2vqIITAxj1V+PnLS0FkPUPD55p/foj+txth/Z9v3of6pMCZv3sLP/jXRx5HhqNoBEauKC2xP331SQGST+XkF+0j6kJFiLQ5zXypdh00fBvLAoYF3/TcYt/7btlbjRJ5wd/MXI43LaPObPl8814cdHGORsEDs1fgrN+9hX+8uzqjXDW11CqdWEmCcKimHh+v2431uw5mHBOXqWDXgRqc84e5+MkLn8Ry/jB0bdsMAHDr1MX4xSvLUuHnc1dsw++yCC+23u+LHnoPA26fieq6tDA239go5hTFQZh6rd91EBWTpmPRlztx9ZMLcfbv3wIAzP5sS8Z+ufJ/scCwYEZJqSRF+qF0QiDzofjTnJW4/7XPI6xZdpgPa0J24OZ/J9OAE4u+DDZpShmQ4+onjZUPT743e1PUoZp6jP3D25GOoGrq7G0wVzr47/rvsgzHtGqNU1/Oyx9dgBuf/Qjj/vIuNlsiy7IRGPur6zz9K2bAwjsWx3kUZNO5qccM79UBgKFhAOE17gGHt834vnjdbgDAQcWkag6GzEu9s3I7xjzwFrbv99Zm4uDDtbtSEYVCCJxw9yzXvmDtjoPauV4AcOp9hqXjn/PWYtayLVi5Ve8j1fkk44AFhoUyjYYR5KE37am/m7UiZZrIF0khUnU3X6pcaO8jenVIRQoZ9TCigDZqQnX9YjrZP1izM3T9TJ58f42trErpiLbuS9c3maFhZAqa15cZo70DFr+Qlw9Dx/VPf+jpXzG1Nyc/VLas23kQPSfPwLSPg9nB1c5qmXR+m0WqKS8bnCb0mZpHgoBNu437ZNbinhmfYcWW/Vi386D22Kh4e+U2/EvOVTKpqq3HRX99D9fICLoDNfXYdbDWtS84/TdvYPTv7X4odcChG9yo1OdIu2KBYUH3gL/yySbP4/zer4pJ0zHxyfBrja/beRAzlrjXKynSek8ih4be+qTIuF5SiIyOOCtieB8Oaup0SHlJVfu5yNAw9JXZV5XZuWXToevmtlgxO+NDGg1m2ca9mO7jedWxUo5y/6346Zw0jqraejz3wVoIIVCnCIzH31sj62iUlYR87j5YrR8gmJ1pUsCYJAn7O1gX86j78kcX4KcvZZqozdDe5TJyzW2w+dg7q1ExabrjdvXQ6R7vushRRDYLDAum01vlmQVrPW3+QbQQc0QahvP/9A6ue/pD1310PgwnFeOSod1D18mkpj6ZIXjVevilqrY+I67eFH3Zdj/zVu3A7oOZc1N051K1B3Pk7DW6M1FnzQNIzeMJgh/TgtmJ63Y978G3cf2/3J8LJ1rICaqq09+pOg/MWoGf/HsJZi7dorWfm8eF7bJ3HdS3oU7YJ4XAix+uT/lNzHpV19Wn5iW9uXwrHnk7+5BqN+rqk3j83TUAgJZNjVBgt478F68scz2fU5+iy2+nahh+0tdkCwsMC6VZqtDmi56rgbxqI3UiKdIPnTniJ4cu9//O6htZ3WrqkrZ2sPp4TJZt3IvqunpU1dZndDxff+g9HHfn6+nj5eGqqWvgHTN9aWt19UmMnzIPlz+6wHNftcM2X8IDLnmO3PhyR3CTiC502YpuF6swzIYWcr7D+l3pyC+nTmuLjH7bX11ni2QC0s+lkzbmFydn7gV/ftd+TQC3TP1YOda49veeWIjj754FAPjOPz7AL6fHM+P++UXrU6an5mVGWwYZSJrmPBOnY49V3gsT3XMbBywwLJRqNAw/BL1Jew7VZt0Rqbi/kCL14t7wzEeomDQdj76zWrtnkyx/t46a+qTNFKHr5DbtOYTzHnwbZ9z/Jo7++Wu4QXFoL7W8PObh6ln3V9f50tbMa1u1xN/NWmGL4FJfUrMjdEuMFzVWDWPngRrboEDXkby1Ypvn7H4rM5duRsWk6Slbv84c66TxqOYea9aAt1ZsS827CBv6G2iwbGmXOils3l4ZLjjgskfm+0ogqV7eHKAFERjnPfh2xmTbIL9dvU6cDnAWGBZ0Tm8/pDQMn/tf8vD7OOaOmdh5oCY1CzYb6uTLWltvT1X+zIJ12L4vsxOxhuOZZCsoddTWJ20Pu05NNrUkc67Gay4z04NE78xbtQMPvfmFYud2PvaqJzI1FPVlMzvFnQ4d8eRzj/ZdJ79YX/YT7p5lc5jqfs2Nzy5OjaIB4Japiz0nkX5fOmbvnGbMydE1k1PTZbSTZdAy4bEFqXvq15wXB1btxGmpAi/eqdyOP85Z6blf2+b2FCbzVgUL0pj41KLUsx7kmVfvR5xzwVhgWNCF1fohbZLyJzJMp9ilU+Zh/JR5Wcdq19YZWkTf217Fz5XcPyYLfEYVZSsoddTUJdGmebQJG9O+GO96jp8yD/e99jmGyA7UbcRl1YQyXjz52UxvYaVl09wkpZxl0aL82Khf/HBDRj4wN0wzmO4RdNKc3QSGip+Akaiw1sKqfQ+7Jx3W/b4mBU62OJmj12w/kJU/6UmZkiWIpvCUkhaFNYwc4qfj1EU2mDdp9fYDjjHVOtLRFL4PyaA2mUxNYvrnvLUeezujc/Zni25UGXbxG1OgBhFrZpirm7nQ+pKr98HUMJxMh6ZjMyitAwoa64gx6gHkyH5Gok6dn8mp86l3MUnlC2u7WDUMNars0r/Pi+y6TlrUVh+z2nV8sn4PgGB9wkOKFhpnVmQWGBayNc2oL/U3Hn5fu4+bz6Iuy5eutj4ZiS8kUoFRn7SNgm98dnHG90v+9r42OZ8V0w5tdvrpSVr+3qZek6e7jshNW/PeqlrcMnUxjmjfIrWtXt4TJxVfl/Z+UI9yzzqVBNTmausFzv9T2r4dlcmhSWki47+umVTB0F7mhQIyhXCuJo158ec3KjO+u2k+KpVb92ekeAmKKTDUu0pE2qwE+6uNtCZuz2+tS2JPPzyzYF1ss95ZYFjINkpKfTidZlEfc8dMx+OzHaTdNW1ZJE7ZsBOsVGrqkp6dyILVO1ORNq7nqjc7bbPEqKffTiop3AMDzJ899YN1ePHDDRmOcVPDcIrn15mk/LyoQZ+x/dW1+HTDXkx8ahG27qsKLDC27K3SjoLNMrMD0+2jjtIvGHQ4vjrocAAWDaOA0rKr+NV8Rv/+rVQCyGyolmnsVW1VCGGbh7N+10EMvGMmHn9vjTYs2KQuaX3mgxOXEGeBYSHoSHv+qh14YdF6fHNKWsVVHxy/S5bqNAwhBN5YvtX15r+2dDP2HspdFI8fauuT8DO4q/HR0dTWGSdKWuzE6rFeNn11xqw1RYOpYegcltM+3ogP1+5KnX/kUZlrrOgEhp8XNahwVh+NYffM8ZXFVq3PSb+ag5unLnY+vzCSBl7yN7tmrAqRBBFGyNQfqszyO5LPNbUuDnci47l574vMCKpkUuDOaUszFhPzIi1402Wb91bZfF9rthvRaLM/24Ifu+QBqzGf+RBaQlyTFllgWAg60P7mlHn44fMfO24f9AsjZtorWkQ3GHpz+TZc+Y8PbBPCrDw1b41nPXOJMar3FgY6TcwahrlFpucw3x3z9piCBMicYf3yYtu6WhkCwxpxZM7rKG/RBFZWbTuAi/76XkoIWDUD3ToNnVo3tZVZCToD3CpYnZzwOkzHt9vs7zumLbUlWzRROx6ndyNbc2rcuHWaQgCPvbs6teysydZ91Xj8vTW4/NH5DkfaqalLomLSdNymLDm7+2Ctbb7HZfKcCSIs3bjH8Xy19e6mUD+wwMgRfqOcXM+hKfPyM+heut2HjHBO65oLVqd70MyzucBPp/i8JjX6Z5YlXs21Hqwvj/r914rW8LvX7fHypmDSjf7NTrDORcCZA2irZqBbibFTK2+BsS+gCdE62AgSyfeTf/vLaOuU50sV/OqkSdVBHnZyXlx4abBfWJZ+/fWrn2O4TJAZJC2/mcHaKfzaSkmCbOamXh3Ty/mafUEYN4Tb8xwGFhgWopzApuK2ZjGQ7swO1dTj2QVGjp5mctlKN3snAHy6ofAEhp9MrfM1eYLaNCvVrkdhc3or255ZkI4O0/kHdDmXTEyTlFvnYjq/rQER3du10O3uSdC8XnaB4f/4auW3v7pkE4QQ+MPsFdp1tb2u/eGXu1Ltr85Kjssk1f+wNqGO96rXDks2W1WTD9JZ655jN0oT5Gq6rI3AJBWXEGeBYaFtizJ8c2gP7x1d0GkpfrNN3vvqZ5j04hK8uWKb6zKo+cZ0fjrh1kl78crHdvOJNU27U5vo/AOuAiORXsPdCVOW+Omo/dypoAn5rMIsEUBgqMde+/SHePXTzfjD7JW47BF/JhdVw1CDK3Ypvrm4wmrN6K1smfP5Vtd3J4qcbtmQILILA+WWmtvCWJXiMhOywNAw7nj3zjAoFZOmY6HHehJ19UakypINhm3zQHUdDlQbHZ363MQZkfL4lSf63terzzLrHhQjw27mmzJl7hep9M+pxXIcjtcJDKdVEoF05+2mwpvhkVFFkgWdG2odjbr5zKxYBaGZzM9vZJ1qC2/TzB4YIISITcPINmLR5ON1u7Vr1EeBde2TIBgmKec2SwuMED4M1jByh5PJIMzzq3PGqiSFwP0zl+OjtbsByDW0ZSemvrS/9MhwGYaRR3UOfY6mclR4qDa7yK2ksJsD7nttuW0/p3dJd+/+67K+w+a9VXh58QZXQWxOjMymAxvd396mppC6dmRvtGth74TjxNR0/TpF1UijpmUJm38uKUTKZOeXP3/r+FRyvvu+fmzGNnVSY9DcWDqiXjPEZHiIxcB0Pgy1Xc1NYSwL7PTOIU4jSb/3QJ822/3guqTAU++np/cLpG+6upZE2ERqcdOszJ/fBQC6tLE7iOuT9klN6nfT3GfVQpbLdY11S+x6ceOzi1Hjcn+myBXwSrJIG6MTYGbZ0V1bY/K5/QOfMwymYPRzfwDv7Ll1SRHYXn7+cYfjMLmU6+Ae7TK2qfdvlQwfbtW0FN3Kmwe6Rrp+0WvkYQVZSYJsoeA9Fae3uWmaxjSrw2xLFXZ655DQlgfN8V5RUsmkyDA9CCFSD5U6q9bP3AW/9GjfHL+/ZBBeueHUVNmT3x0W6pzNAwgMXVituuhTukxzsKXsnD/MxUNvVmZtNvJj6vN76lHKfA2twJAnIp0tO2aCdu6qhiGEPZVKfVJk1SkP69keQHoNcBPd/auuqw802v76Cem1XdwGAtmiJnnMBp1J6ox+yhwfue1BHwkPAeC0vh1tZaxh5JA4Vqezpuu2Upe02+7Nm54gQ4As3bgnUh9G/65tcNEJ3TGwW9tU2en9Orkckcbp/W1WJk1SvgSGZhGcpHuEitutWbZpb9YrvPkRcH5OLQTwjyuH4fgjyh2PMTtFQiwLCbpSHTB77Krt6mJK9trWZ6FhAMBd447BWz8aibbNy3DuwK4YICOidO9e0POrp3jTZwJGHWY25agpIXuU1LdOOjL12drXD6to73iuJ747TLvGTVx1Z4GhIduMtWGoT4qMB0WIdDjn8s37cNd/l+ErD76DLXujW9jeaxSiqsl+aZoKBfb2Yeg6r5r6eux0WQzIXNxHFyc/57Otvk0tVvzk48pmIKE7JLWYVe5WzU0RNN34r2ak57hos9kms3N6Ny0twZEdjOfrocuG4G+XDwGQqWH8/PwB6WsHOLeqpJjLt2bDoLtex7YsEwi6UZIgW1uqv7u6rh43PvtR6nvvzq205+l/WJtMzURh5Rb/CVCDwAJDQ6tm+myifs0d1rWd/VCfFLa3wlQm9lbVpdZKjhIvbcXt1zq9wM3kZDbrpCi/3Pzcx/jXfO+su5dOsWcbra5LZj2J0Y/AcGsPJxu7bvRnTucg2DuOuFmyYXfWxwoI2+/J1iTlhCqU/fotvnXSEY7nCMv2/fEIDLcMyiu27MfLi9OBGk7+CLM70v3csQMPC1VHJ1hgaNDlFQKyX0/aD1aTlEDw6JPA1/QaGWbxg5v5jJ1voZklDQBrd3ova7qvqjaVujwq/ISZumUBuGm0wxK3OpOUomHk2ofxbmW0YabZOL11pFK/KO2lzqR3ayarGTKKbA3pcwU/5t6LjnXdXuIxcc+K077kIjD8pKjJhtgEBhH9hog+J6JPiOglIipXtk0mokoiWk5E5yjlY2VZJRFNUsp7EtF8Wf4cEdkT/0RIGwcN42vHd4vtmkkhMl4KIeJzXJnEkdFy3GB/bWRGU2WDbk3jsESRIh5IR2+59TMJDx/GKX06RFKXqBECth9mmKTCD2zMEbeqxTsNKkwGdjP9HpnlESZe1mqIXpzax+6EVklQMM3SqR+Iw9fqRZwaxiwAA4UQxwFYAWAyABDRAADjARwDYCyAvxJRCRGVAPgLgHMBDABwqdwXAO4D8IAQog+AXQCuirHe2jUxltw5Bn276G2JUfCNh9/PeDBumfpx7Dmisl0AyImvHHcYjuve1ntHpKOp8oU1ssTPRMPBLmtdWEe15p3UvdIppzdBO3SeH3BZz1zh6MNwGXhMPL2Xr3ObgxdVW1CfEd3iTmZKHGuG6Sg70t0Wf9qrS7xDXZt6aNmlHhP3rDiZr0jzKW5iExhCiNeFEOawbR4AM9ZtHIBnhRDVQojVACoBDJN/lUKIVUKIGgDPAhhHxpt4JoAX5PFPALgwrno7kSDKarQRhjeXb4v1/L06uQtAqw25NEHo0d4ocwpzHNitLVo7aGgmbZqVamPHc8mZR3fG0V1bp777MUldqNEwLx12hDas0URnHkl3ioQRvXMXEhkWXae9t6oW77jMDfrpef7mmXRv1xztWpRhsrK/LrmjjnYtMw0OUQ68v2nxlV37tPeSq14pTbx8GFacNDjKQ/BErnwY3wXwqvzcDYCapnS9LHMq7wBgtyJ8zHIbRDSRiBYS0cJt26LtbInyE9USFWrnCBgd5vfPcB/9TT63P64b2TvwtbzyTF0zsrdnqpS4+eaJPTJGojptrmOrdEekS2UOGPbqp646CX1lJMtJcn7BfpfAh4SiYfTp3Eo7G7wQEcI+lv3Hu2vw/qrwfpFmZSX46PYxOHtAF/zonKNwx1cHZJik3PrXDhaBEZepxu9cEK81dXRRUm5MPF3/DqZ8GP5PFZpQAoOIZhPRp5q/cco+twGoA/B02Mp6IYSYIoQYKoQY2qmTv/kEfsmHvTAunrpqGB77zono3Np9lH9Ehxa4bHg6PtzvM25m2XWiEHIptmhS6hn1duUpPVOfRx7t3qkP6lGOeZPPwiUyceVKuQDPdhmWaU5UA9IpRsyrF6hCEZgpMjQ2LNeP6oMrT+mZ8Ry5NVELy0JWcb2qfp9br+cqyOTSwT3KM5bGVclHjxRsNXoLQojRbtuJ6DsAzgdwlkiL5w0A1HSw3WUZHMp3ACgnolKpZaj75wyihiM0TuvrX5iqv9nvCKtpmfs45NQ+HfGbmfb8ULnG63aqv93PhEDrrGUgHQWl9hHlMn9UKs1JIUhQHwi4RyB1a5dd+g4n1LXPrX6B8hZlOLl3B8xYstl2b+J6T/2akbw0jCDZGhLk7MQ3f2cu+6U4o6TGAvgxgAuEEGqs5DQA44moKRH1BNAXwAIAHwDoKyOimsBwjE+TguYNABfL4ycAeDmuejuRICpqk1Q2EJwzq7q9Oj07uE/4G+TiPM4lXrdTfVGzzZyantVN+Nf3TsIvLxyY8oWZZywOceEdAuw1cn7jhyMDZURW27xlk8yx7Vs/HJVylCcI+NlX+qeuH2WUlMqGXc4rHY49pisAI9NBSYJw51cHOO5brUmJ4wQROQoEsziqLMp+iNOH8WcArQHMIqLFRPQwAAghlgKYCmAZgNcAXC+EqJfaww8AzATwGYCpcl8A+AmAW4ioEoZP49EY663FcHo3Pmwx7ppWuHvcMRnfK7KYIV6IqC9qkDUoVNRO9uQ+HTNMfKYwLhIFA/93lsNcE4mXFtazY8tAGZHVjlCN6EuQsW6NacpLJAjfO61XqtOOa8Q98rdvasublCRwzOFGiG8raR7r16W1dl/A3sG//eNRjvsmyPnZM7W9BiEwhBB9hBA9hBCD5d81yrZ7hBC9hRBHCSFeVcpnCCH6yW33KOWrhBDD5Dm/IYSIfvqlB4RoJwQVA65mOE0nZ+6py0JbkHjcT3VztjmqzLmXOk3NFL5RTd7719UnRXIeHdN+cApGHdXZ1/ySqFDbXJ0DZbZWMqVhWKKFcvSannds19T1zN/eQmpCbpFS1tvdoZXztDJDw3DYJv9bBUac8oNnevskkaCisTVHSeY6zkpopctD2Vqz0E4h4m2SSu9xxclHuuxpx0ym10KOjA9rm7bve3Vs2Y4YvWznQVFnC/sZtWcrVB3Pp7TDZcOPxEvXnQwg3eGa82IOL2+WUcdc2fRNX+AR7Vuk7mmZ9Ls0dQn8eOzd1Rnf3WwXCZdBW8JBw4hTw2eB4YOHLzsBgLuzalCPchzlooYWIwTKeBhVeXmhOqPb8kA3c3F6q6nU841Xv6L+9mMONyYk+rXBjx7QBQAwqHs5/jh+MH5hMdsBig/Dmoguyw4v7Ap1VtR6+EmYGLVpRNXoicg2v+e6UX3w2k2npe6NeflcWWjKShJ4+LIh+Nf3TrJ13joN429ZRJERvH0Y1vse5xorLDA8uHZk71QiLy9nlW5iU5yEXfPYC3KJ0HATCm5htYUUaRbE6W3iFYpsPVYIgXGDu6VMFYCaA0hGSVmem++d1hNBGditTeQahvr7/QiDqE1SVqwm4ZIE4eiubdLXz0PU0NiBXdG5TTNFWBkfdO9HH4ess27VTSSc30Gd0/uUPh1wthysxAELDA9U+7LrWgKWXFC5YM4tZ8Tu8HJSrVU12loDt44jmxXx4sLLJxXGZ5VICQPNea1RUpadrhhREfh6TUtLYh3h+zl11CYpK56CwCKIc0laAzP+d2/XwrZPkywEesIlSspcAbLUwQoQBywwPFBvQHWde76hXGce7dG+RaBOYnT/Lvi2JRW0F07nz/adLCQNwwvdb/dbfXM3P8+EdZ9s+v1B3ctT9vOoUB316ux0P/vHgVe7mIJY3U9NQVPRwd6J62jV1Ht62lFdWuMsZTInUea1dc+Okwbo1qZuYbUlqWulzxt3H8QCwwN17d2gi8/kgmt8JncDgEcmDMU9X3NPvewX9REOIgPMF8map8pvkrogeNmMvYIYwgzYzTbRXcLaXrefn+nfyMa0c9PZfSNf+EvVGPxoD3FrGH4D29X91FnSfjUPp5nVKjNvPj0jh5WboDApKwk+l4sAkMNtNQWFKhTjzhrAAsODZIaG4eXDyD3fi6GjNTEf7qV3naPZqNs/XThv8llaW6rZqTwyYWhGuTUfkJVjlWVk/TK8l3uacK/7Zf6e3p1aKmX+rk0uJinr9Qcc3iajPBstrDRBkZv71Ptp+svcOu24zaOeFimN01ttS7/Nms3vsJqkAHv+sXYtmmjvrVeUlJMgNk1R4wYfnkqAGXckJwsMD1QVT7cGtYlAfiZgxTmqS6v4wR5ywEiT0Vqj2puDYDXVwzNXD3dNWHh6v054/poRfqqceS2PpvG6Xzo/hO9RrouGkb6+fqOfe2o1LRIocqe3Wg3romLdypvbRuJx+w68NC+zOdX91EP81i4buaeL0PrgZ+nMSV8ddDgSCf3T42rmczNJlaSF1Dly0iJrGHlGODi9zTTfTvtaiSucNBc+Acp46ey27CBz4M3Rm2o+GdG7g+uorl2LsqwWXFLP+V0lkaCJ17uV6n+zeAnNNtE9E57O9gTwx/GDXffRreUc9QjfFFwlCbItZlTeosy2umLcGobf02c8m5rQYC+y+R1pH0b6WDUy7oYz+9jqljrW9bzOAiXDZCjrzD6MPKM2v+nD+M7JFbaRo9d9GnBYm8jj5IF4U66nwz8123T7+zinujypitvLbLatVydqRT3n7ZrcPt4+DI2GEbDT8mOSslJChHGDu7ma4aztRQSUReTDSJt2jA9tm5fZ1l5IENnaJW4fht9Ft9S2UR3YfgVGNkmA0iG9TtuN/36XszX3TwrnepdqNCmOksozqsQ+/ohyAIY5QHdj3O5VXDHqphniwsHua1CEQWuSysI2DKTbIUg6A/MejBvcDZcO6+G8owWvkaLXyxUmm2zqhdfYCLyay6vzAfS/zcmHcc4xweLyrUL9kGb99ARltl+CKJYoqfsvPg7PXD0cgL/oJSCzfX9/ySB0l1l0gzynbuvAXK7kAzMxb4eT9uimVeq2mY/N/z7f6vgclGQIjOyf1SCwwPBAndx97cg+eOOHI9FXM6NbQHiqg3HcypIE4eM7xuCBbw7GB7e5ZpsPjPk46gVGgBMolKQ6w8yNbp272m53XTDQx4Uzr+V8XuF67dSoTSnz2+ekTFI+98+4rnwr3ToZ6wCEyPl3HH9Eu4DXz7xHh3S+O6KMCYd+nLPZcMnQHhjR2whe0C2drCNBhNm3nIH/XH8KOrdphlvO7hf4um6rUerSnKdmejsJDJdrebWO031VBwjmPnG7UVlgeKBK7JIEoafM06KT5NYiM5+Q7lxRYpoM1Nw/UZAyQ+i2OXz2It0Z6a/lRZDZ7X61ulvO7oebRtszsZovfzZ24T5y/ff+lmcgA4fT+tIwrCYpEJqWJtCuhT2PV9DuOiXUXZraqmEQkWPHtvBnozH/p2cFrIUzYzxmMhMZs6rNXFN+AhAA4FYpWLwexatOtfvDUqY6hzZzM4d5R385DWjsGkZ9zF5vFhgeOHUW1lIh7A+k9T4Xa+pCrQ8jy0Fjas0CS+fiaj6KqeHM+9WySQluGm0fhaZNUmqZv3OPOqozXr/5dHz9BPtqwl7ncNLCVLTZb4m0o+mg98p6L75zcoX9nMi8Lf0Pa+PYsZW3aIIubaJZw/2LX53nOb/G5t9JaXvuD1Kb5v6SZvbWaB/mb3eazR1VcMqNZ/XFRfKZ0qXf5yipPOM0KvEz6PR6SNzyMRUCZu3VjiD90mVnpnLqDP34MKJGF4aponck+n/x+3Vp7ao5OXVgVqezvm52k1TmB+U6AZvPKjA6aCa/JSi9LvXVp/XE49/xvzBSGEoS5KmN2rVX479bOwyraJ+x7n1Qa4B5TScN2K3KQcKRbz67HyrkAmUZub7Yh1EYOEls68suhD0Sx6ZhWM7llgK50Djz6M6YcvmQ1G9QO5UggyenVdH8REmF5envZa4X4Sz6DOIKEzXPqvtdL113si0iSYe1bmT5r+J3aVGnc+sEqlE347yn9+uUMes53zgNAJo3cX7ffvqV/qECU8x75TQXJsqgl9ScD46SKjycJPZ1I/tk7gekJs+kj3U/d8FrGMoz/th3TsSYY7qmR+U+nn+deu5kknIVGBHZpIZWZDp/zXvrZSNWn4EoLAuu62IrKVOsbTKsZ/vUZ5vAcBEyQTuRVMSPZs5N6nqKaIo6JUlYrNU127FFkxK89aORqdXxrMfoNGogc6a/E2ZwjJNJylonnZnPL2nfot0kFXfG7MK60wWIkzlkwskVWPPrr6S+67oAL1NKx1ZFsjKdgtl5ZqRccBij69RzaxpoE7fR/JAj2zluC4JTPb3WG4jrFdQ+HkpVrP3w1O+PQBu5JkQbh0WqdL9RF9rrjrMwVy1fZv0LKQMxYO/w1a9HdmiZkWVA3UfdT20xPyntzTlaTiYp6zPm13T0o3OOspWZp1Lb3Tw/+zDyhDlJLMwNcHsmendqic4RRzVFjWtYp4+htqqe/2Ts0RnntJuknM9z9WnR5MtyMhE6T7bSOL2jqIfv/ex7HpBzIqypOsw9dQPcoM+wtZ107UOUHhDFMSE1DE5ObxNdAk5SdAzrrylThIC6VKxKrVQxHE1S1mdPu5cddQ34XqkITeO72u7mZXmmd54IOtVeawpw2V9d+CUIL8plKvOF+ZsyRr8O/YU62rp2ZO8MjczutE1///sV6cSEfpycfrGexVTfvTSMuNArGO6+IXO2s3X1udSoU2MeCtqJOJl01OuoZYVmknJyeptt208zj8qqYag3p4kcyfft3AoPfHOw9pr7q+sAAC0dJhdan2G/98TUhmbdfDpeuu4UAEBdvV1Qp+4Haxj5QTe6DIqb2tm1bTNfHeHpSs6gQd3b4oSAk7CixnzQdROUrCVuC8a4aSjmjHog2qgPa3ubp3aqim6EH4XwSkft+EtNovLidSfjlxcOtJlVzHrpzENundP/bj3D0Z5uClTdb1ZTgxSaScquYcD1OyAFhvJZxU9Sx71VtQCANs31AsOmYbjc+jm3npEKnTWv3bdLa7SVc2zqkoY2o66DkZqHwRpGfhgq7ebfHu5vwSFdP+Jklz+9Xydcc0ZvX6aJv18xBP++9mR5jfy/mOlO1rsubpPs3KwY6qZsTYJXa5Y5tWsYstzR6W0vi0fXUbaoPgzNbv26tMZlw490rHNQDaNVs9KUX8QJnTzI8GEUiEkq5fC1aRiZDmEnJ75Tm5qdttuj2LTEvjaFrg63n29EUrr57Hp3aoX7vn4cPvz52dr96uRLoZvpHbdJyl9ylkZI5zbNMkwoXuhGo06j6CeuPBFE/hZTaVpakh7Vy4fi0QlDY1/P24mUSUqpu9PPcEue5/bCRCEYb/uK8WJOPL1Xqh52H4ZpkoqvHm54vdpZrYuh1TA8ruE1r0ENoU5FTlGq/dSUHaP7d8aI3h1x9yvLglQ7UmwahYMAse6jahhqtJEfDeO6UX3QqXVTjBuk93GYTbhtfzUAoJNHwEtZScJxISdzNrfOJMVhtUWMtSMyQyaDdkT9Ohs212vPMBKindW/C07ra09vnQuERXi5cbomBbeJrg1uP38AXrnhVM9RfJBEiz89r39qrQ2bSUr+D+LDiCas1mVbxn7BL6ZbptVt1Jkg+1DH3DuVhFBzHCn7qR3XIxNO1KbOyAVOUXB+WjFhGcCpTdak1OyMnduxWVkJLh9RoQkXl3WQJ//6Cd3QulkpvqbJAOAX08GemXzQXu84iF1gENGtRCSIqKP8TkT0IBFVEtEnRHSCsu8EIlop/yYo5UOIaIk85kEqBNuMBX3nkln472tPxiNXqCvN+fsZbVuUYc2vv4LRHjl0ckE6skh1hEZzO757ak8M9LGy3h/GHx/J9VIWDEcfRrx4L+AU/Jxak5SLipEguyaY0rzSvV1qW9rpjVT7FZoPw4pu3oJ9H+WzZT83X5wX1omqfTq3xpI7z0H3dv7WF9eh0zBSyQeL2YdBRD0AjAGwVik+F0Bf+TcRwENy3/YA7gBwEoBhAO4gonbymIcAXK0cNzbOekeF9YXv2rZZRqev6xAW/Ww0Fv0s2qyzUZK2++e1GpHgpWHoJkNls1aCFbczZLPgj0pQkxQRYfSALnj7x6NSZdZBga4WGU7vAouSsuKnFd32CbOSYTqRZHQvjLmmhmoKbCi5pB4A8GNkmmvHAXhSGMwDUE5EhwE4B8AsIcROIcQuALMAjJXb2ggh5glDfD4J4MKY6x0Yp5fK9RjN5g6tmqJDAU/oS6bs/qpdOz4mn3t0bOdOz/TWb8+3TMymj9F1blantDqXwNzUo316xGuNhHMyzaV8GIXm9Lbgpx1VJ77hw0jTyiMowI3S1KAjOvbJiCw1tDo9ca9INQwiGgdggxDiY8umbgDWKd/XyzK38vWact01JxLRQiJauG3btpC/IDy5WD7Vyts/HqVdSzsqdLmkTCKbLyFP07Z5Gb5/hvNCNmGx2uqd6uFVFr4GyvmVz1lpGJr7csXJFfj+6enJj3d+9ZjUZ919TNUqZX7SDQ4Uc0iBmaSsz6G/dnTex2lWvR9OkNGWUcrUnQdqAAAdWqYHlqnkg9FdRksogUFEs4noU83fOAA/BXB7NNX0hxBiihBiqBBiaKdOOXYK62LVPVrXdMZGSY/2LXynac4Gr1F5MZG02uptxPMj/badGqL5/TP8zXbXmYe6lTfHJFVTU66v60ytM+CdquslcPOFzY7vo3oJi1bRr0s6hbl1PfMgPHTZELx43ckZ63uH5fpRfVDeogyDeqR9T37n9oQllMAQQowWQgy0/gFYBaAngI+JaA2A7gA+JKKuADYAUNfZ7C7L3Mq7a8oLHi979/nHHY7V956X3r+w3jstOru/W70fnTAUN5zZx3kH3TXiHiZJ5PynQBpGFPTsaHRG7VrYwybVa/5o7FH44/jBWH3veZh8bn/bvm/8cKStzMkB7bSkru43WsO4nfa/fISRtiJfId5+8aVfWLSoIUe2x0/PM4RsGAd1q6alkU+2PaVPRyy+fQxaK5pPSTH7MIQQS4QQnYUQFUKIChhmpBOEEJsBTANwhYyWGg5gjxBiE4CZAMYQUTvp7B4DYKbctpeIhsvoqCsAvBxHvcOg9WH4aN2wTk4vnr9mRLQnNE1SPut6Vv8uuHWMPYGaH+IWoNaO0XZ9XVkEdbp1TD88fuWJOKlXB9f9mpaWYNzgbo6mPnP1RxU1rPaJ7w7D7FvOsO3jZfayO73115809mh88avzQjmFo6ReM6EN8GcqJdhH5xNPN9LZtGtpdMw5GsdkRUOeuDcDwHkAKgEcBHAlAAghdhLR3QA+kPv9QgixU36+DsDjAJoDeFX+FTwJIjx+5Ym+s9IWiO/QFZ2GEfUzWqrk7okTq0nqzR+OxLb91fjGw+8DiG/iXllJAiOP6qzdFjYKyzRJlZUQznCYB+M1SLEFNjj4cohIOws8X6RzLFnSpvg4NqMZbKlFCuhHOmD2HcEzEwcjJwJDahnmZwHgeof9HgPwmKZ8IYCBcdUvCnR9S+9OrRw7BpVu5c2xYfehgkj94UXKh6FbIjTguf52+RDtWgOtm5Xhn1ed5DpTPAqSFm2pomNLVGhG7SqFfo9MYeu2tnOmhmHf7u7DKNzfn84YG9zprYYJW8nVLW9amkC1TJMelNRM7ygrpIFTg8TEU1cNw0k93U0OJv+5/hSceM/sWDSMqE9p7WTDYF1wSuXUvh1Dn9+L9AQ1/XZK7Rd7VewXzRLTPOQ+90L9rIuSytQwCl1ImqRyLFk1DJfqt2tRhl0HazP3t+yTq5//9k9GYbelLn5JT9yLskZ2WGBEhPWZCpK6w2lRoazrEuMDrkvgVsi2XTe8hJ82rDbG+kSBnzkRXiYWs12c1i4pVHRJ+QB/EyXVeRhWcpU6vHPrZr4Wa9JR9PMwGP+kX8z0o31Gv0649ex+WZ0vzmdGlxoknxxzeBs8fuWJWR1rmm2CrN0d988Oe34/s649r2E1SRWJ4KzzWMRIh/k7nKLI1H0KmQRrGMVFGLVd92I+8d1hIWtkP2cU5NQ844O/XT4k67BH7yipYugqMokir5MtrLZI2kG3sBDgrhik80y57ROyYjkg5fRmDaPxUAwmqZ+f3x9EDgnZ8vBihYmRd5u1DjiNrOP9kWHPHkZgTPvBKXjtptNsHWwxdJgA0FtG1XVopU8LriOdTJFgihb7zy38BkjN9GYNozgI80glLSaAsJgPzf0XH5cqi8pxefmIClw+oiKSc+UbXV6sYqcshEnquO7lAICXrjsZ0z/ZhLU7DwKwCtQCUzEV7vjqAFww6HD06Zy5BGvgsNoA2wqFRAOeh9EgCfNQmdE6Uc+YHdGrA7buq8q4BpPGyyRlorZc/D6McBdwTnNiDCAGHNbGU0s6rns5jutejolPLgSgd6QXYifarKwEI3r7i0y0Ykzck58dflwhv0G5cnqzwIiY/1x/Cr7Yuj/QMe1bNsEPRvXBhcdHk1sq83kvwDe7QEhmYZIqBo45vA0maNbpvmSokXnHnK/gRUPUwLKhGH59rpIPssAIySVDu2PqwvWpUdvgHuUY3KM80DmICD88J7v0GYVAsWov5qzYIB1ioXUenVs3xdZ91Rll0//vNNdj/P4Gp1QbxYbb06k+uqm1XuKsTEyYlkj2YRQ4Fw7uhqkL13vv2AgohGiaB745CMd2K/e1b1ZRUnGbpALuP+PG07Bpd1Wwa/gUkHUagVqkYwNv8v/ohiJXWiALjLCQ5X+B0disCSdWtPeMnBrd31j10Gni3n+uPwXvVm4virbr2Kqp71xlJn5/lptALYTBgV/81lRdQCkXmNaJKAgylygMLDBCUkwvTmPAa6S14pfn2py41gWATLPiZ5v22o6PPaw2B4+TeY3hvdq77pea2FgMkjMCKjoYA42vHd/dY89ouP/iQbj/4kGRnIs1jCKj0F+pYskHFBavn6mLRCvzcHo3NDMMEWH2Lafj8PLmrvuZ64W4RV4VA35vX+c2zTLWpykmcnWLeOJeSJzWEc4n1440ljVVJzAVq2M6KNloAIFSScTuw8jNm9+nc2vPVeDqfYYdFwv6eycs+5BzWG0Bv0NskioyCmkA/+2TjsS3TzJWQ8tFtQrpNcrmvXFcpa7g9cZ4qdc5vX0ee3TX1ujezl2DKSTc7nUxaOe5qiMLjLAUUm/pQi4eqIJ4r7Kog5OGkY+kewXRhhLT6Z3NxL3Xbjo9jiqFQlUQFv5sNABg7B/m+j8+6goVISwwIqLQR6OFrE5HSfwmqcK+z1FiJvMrdpOUrvZBIsuK6df38lgALCwsMEJS6N1wQ+3gPvr52ahN2mcsZ/Nzg6zp3Zj4/hm9cOOzi3FEh3SYcjGOO9yqfP/Fx+E3M1egXYuynNUnLl687mRUdGCBURQ00H65YGnXUp+RNMrwwmJZByIuxg3uhnGDu+W7GpGhu59nHt0FZx7dJfeViYETjmgX+zU4SiokxTLiilXTKKA2KPYOnQceTCHDGkZEFPqLHsSH8dpNp2HFlmAJFAuFaO+DebJ02xX6fY4b3RK9xUKxDO4KGdYwQlKI8zBUsnmvj+7aBhcMiiZzbq4JokndenY/9JWL7ujPFUWNglHowRNM44Y1jIgo9Bc9TpOUcFypLPcE+Zk3nNUXN5zVN9j5C+JXMtlQjFpRocEaRkiKRc2NM6w210nb3IiyCtpzxb6AUrznZ5gwxCowiOgGIvqciJYS0f1K+WQiqiSi5UR0jlI+VpZVEtEkpbwnEc2X5c8Rkf9Fe2MmlUO/QF/0XNQrvY5A/hsh2iip/P8epnAolsFhnMQmMIhoFIBxAAYJIY4B8FtZPgDAeADHABgL4K9EVEJEJQD+AuBcAAMAXCr3BYD7ADwghOgDYBeAq+KqNxOcgtIwilwDKIAmdCV1rwu+pnay7fCPaN8Clw7rgSlXDIm2QkVInBrGtQB+LYSoBgAhxFZZPg7As0KIaiHEagCVAIbJv0ohxCohRA2AZwGMI2OYdyaAF+TxTwC4MMZ6B6JYZlDnxIdRABIjyo4s/7+GKQQSCcK9Fx2Ho7u2yXdV8k6cAqMfgNOkKektIjpRlncDsE7Zb70scyrvAGC3EKLOUm6DiCYS0UIiWrht27YIf4o3hdBZuhGnYEs2UA0jP7mkCqARGyjctOEJFSVFRLMBdNVsuk2euz2A4QBOBDCViHqFuZ4XQogpAKYAwNChQ3My9C90/SInpgNhZjWN/1JecKeQI4qonbvJdT9O7dsxzzUpfkIJDCHEaKdtRHQtgBeFMbRdQERJAB0BbADQQ9m1uyyDQ/kOAOVEVCq1DHX/gqHQ3584R66mhpGrVb/ciNYkZZxLVc7i1gDy34INj4qOLTFv8lno0ibYUraMnThNUv8BMAoAiKgfgCYAtgOYBmA8ETUlop4A+gJYAOADAH1lRFQTGI7xaVLgvAHgYnneCQBejrHewSh0FUMSr0mqcOZhRKnlNPZcUjqK5HG30bVtMzb3RUCcE/ceA/AYEX0KoAbABNn5LyWiqQCWAagDcL0Qoh4AiOgHAGYCKAHwmBBiqTzXTwA8S0S/BPARgEdjrHdWFOqzmJOw2pQPI/+NUAh1CEORV59p4MQmMGSk02UO2+4BcI+mfAaAGZryVTCiqAqOQk8NYhJvlJR5jdgu4ZvGtMARw+QanukdEY25HxEpk1T+W6HYO/RC15BEAZkfmdzDAiMkRTINo/GkBol9PYwC+JEMkydYYEREoY8M48Q0yxVCWG2UNOZ7yjA6WGCEpGVTww3UuXVhh+w1lrDauGkEP9EXLEwbJ5zePCQn9WyP335jEM47Vjd/sXGQTCcYyhvNyhKoqrWv8R0G+/JJaZzWAWeYhgwLjJAQES4e0j3f1cgrogA0jOn/dxoWrdkV6Tndfk4Jj7CZRggLjAZOLvu1fHahvTu1Qu9OzqvnRUVKOLIxl2mE8GPPhCYVatnABt26iKjSEqPsW8OOzHV1GCbvsIbBhCaVrbaBhZzqBGBZSQKf3z0WTUoa91irYd1pxi8sMJjQpH0Y+a1HrmhWVpLvKjBMXmjcwyQmElLJBxuYTSoVJVUsszNzADdF44YFBhOahurDYLuLMw3uXjO+YIHBhMYcdDaGiXsM05hhgcGEpgDm7cVCQ3PiM0xYWGAwoTFzSTU0BaOh/R6GCQsLDCY0yQJaQImJl2JZ/4WJBxYYTGiSDdTp3cB+TqRw2zROWGAw4SmAXFIMw8QPCwwmNKOO7gwAOKV3xzzXJFpMExsbYRjGgGd6M6EZ3qsD1vz6K/muBpMDeOJe44Y1DIZhAsMBDo0TFhgM4wB3iQyTCQsMhikAupU3z3cVGMYT9mEwTAHwn+tPwdqdB/JdDYZxJTYNg4gGE9E8IlpMRAuJaJgsJyJ6kIgqiegTIjpBOWYCEa2UfxOU8iFEtEQe8yCxAZXJIblw9HZq3RRDjmwf/4VCwk7vxk2cJqn7AdwlhBgM4Hb5HQDOBdBX/k0E8BAAEFF7AHcAOAnAMAB3EFE7ecxDAK5WjhsbY70bFPyCM3HAI7bGSZwCQwBoIz+3BbBRfh4H4ElhMA9AOREdBuAcALOEEDuFELsAzAIwVm5rI4SYJ4w82k8CuDDGejMMwzAa4vRh3ARgJhH9FoZgOlmWdwOwTtlvvSxzK1+vKbdBRBNhaC044ogjQv+AhgAb77KH284OK6yNm1ACg4hmA+iq2XQbgLMA3CyE+DcRXQLgUQCjw1zPCyHEFABTAGDo0KH8bDNMXLAwbZSEEhhCCEcBQERPArhRfn0ewCPy8wYAPZRdu8uyDQBGWsrflOXdNfszDMMwOSROH8ZGAGfIz2cCWCk/TwNwhYyWGg5gjxBiE4CZAMYQUTvp7B4DYKbctpeIhsvoqCsAvBxjvRkmA17TOw23ReMmTh/G1QD+SESlAKogfQsAZgA4D0AlgIMArgQAIcROIrobwAdyv18IIXbKz9cBeBxAcwCvyj+GYRgmh8QmMIQQ7wAYoikXAK53OOYxAI9pyhcCGBh1HRsDPCBkGCYqODUIwzCB4fXOGycsMBo4HBrKMExUsMBo4LBJKnualBqvx/FHtPPYs/HAj1PjhpMPMowDLZqU4pUbTkXPji3zXRWGKQhYYDRw2CQVjoHd2ua7CgxTMLBJimEY/0ibFA9EGicsMBo47MNgGCYqWGAwDMMwvmCB0cBh0wHDMFHBAqOBwyYphmGiggUGwzC+EdLrzYpr44QFRgOHTVIMw0QFCwyGYRjGFywwGjjsw2CipDRhdBlm2hSmccEzvRmG8c0Fgw/Hiq37cP2oPvmuCpMHWGA0cNiHwURJWUkCk8/tn+9qMHmC9coGDpukGIaJChYYjQRWNBiGCQsLjEYCKxoMw4SFBQbDMAzjCxYYjQQ2STEMExaOkmokxGGS+uP4wWhSwmMOhmkssMBo4MQZVjtucLf4Ts4wTMHBw8MGDofVMgwTFaEEBhF9g4iWElGSiIZatk0mokoiWk5E5yjlY2VZJRFNUsp7EtF8Wf4cETWR5U3l90q5vSJMnRsr7MNgGCYsYTWMTwFcBGCuWkhEAwCMB3AMgLEA/kpEJURUAuAvAM4FMADApXJfALgPwANCiD4AdgG4SpZfBWCXLH9A7scEhBUNhmHCEkpgCCE+E0Is12waB+BZIUS1EGI1gEoAw+RfpRBilRCiBsCzAMYREQE4E8AL8vgnAFyonOsJ+fkFAGfJ/RmGYZgcEpcPoxuAdcr39bLMqbwDgN1CiDpLeca55PY9cn8bRDSRiBYS0cJt27ZF9FMaBixhGYYJi2eUFBHNBtBVs+k2IcTL0Vcpe4QQUwBMAYChQ4eyFUaBG4NhmLB4CgwhxOgszrsBQA/le3dZBofyHQDKiahUahHq/ua51hNRKYC2cn+GYRgmh8RlkpoGYLyMcOoJoC+ABQA+ANBXRkQ1geEYnyaEEADeAHCxPH4CgJeVc02Qny8G8D+5PxMANkkxDBOWsGG1XyOi9QBGAJhORDMBQAixFMBUAMsAvAbgeiFEvdQefgBgJoDPAEyV+wLATwDcQkSVMHwUj8ryRwF0kOW3AEiF4jIMwzC5I9RMbyHESwBecth2D4B7NOUzAMzQlK+CEUVlLa8C8I0w9WTYh8EwTHh4pjfDMAzjCxYYjQT2YTAMExYWGI0ENkkxDBMWFhgMwzCML1hgNBLYJMUwTFhYYDAMwzC+YIHRSGAfBsMwYWGBwTAMw/iCBUYjgX0YDMOEhQVGI4FNUgzDhIUFBsMwDOMLFhiNBDZJMQwTFhYYDMMwjC9YYDAMwzC+YIHBMAzD+IIFBsMwDOMLFhiNBA6rZRgmLCwwGIZhGF+wwGgkcFgtwzBhYYHBMAzD+IIFBsMwDOMLFhgMwzCML1hgMAzDML5ggdHAKUkY7u6mZXyrGYYJR6hehIi+QURLiShJREOV8rOJaBERLZH/z1S2DZHllUT0IBGRLG9PRLOIaKX8306Wk9yvkog+IaITwtS5sXF019a48ay++Mu3uNkYhglH2GHnpwAuAjDXUr4dwFeFEMcCmADgKWXbQwCuBtBX/o2V5ZMAzBFC9AUwR34HgHOVfSfK4xmfEBFuPrsfDi9vnu+qMAxT5IQSGEKIz4QQyzXlHwkhNsqvSwE0J6KmRHQYgDZCiHlCCAHgSQAXyv3GAXhCfn7CUv6kMJgHoFyeh2EYhskhuTBsfx3Ah0KIagDdAKxXtq2XZQDQRQixSX7eDKCL/NwNwDqHYzIgoolEtJCIFm7bti2q+jMMwzAASr12IKLZALpqNt0mhHjZ49hjANwHYEyQSgkhBBEFTn8khJgCYAoADB06lNMnMQzDRIinwBBCjM7mxETUHcBLAK4QQnwhizcA6K7s1l2WAcAWIjpMCLFJmpy2Ksf0cDiGYRiGyRGxmKSIqBzAdACThBDvmuXS5LSXiIbL6KgrAJhayjQYDnLI/2r5FTJaajiAPYrpimEYhskRYcNqv0ZE6wGMADCdiGbKTT8A0AfA7US0WP51ltuuA/AIgEoAXwB4VZb/GsDZRLQSwGj5HQBmAFgl9/+7PJ5hGIbJMWQEKzU8hg4dKhYuXJjvajAMwxQVRLRICDFUt42n/zIMwzC+aLAaBhFtA/Bllod3hDH5sNDhekZHMdQR4HpGTTHUM9d1PFII0Um3ocEKjDAQ0UInlayQ4HpGRzHUEeB6Rk0x1LOQ6sgmKYZhGMYXLDAYhmEYX7DA0DMl3xXwCdczOoqhjgDXM2qKoZ4FU0f2YTAMwzC+YA2DYRiG8QULDIZhGMYXLDAsENFYIlouV/ib5H1EbPXoQURvENEyuarhjbK8IFcmJKISIvqIiF6R33sS0XxZn+eIqIksbyq/V8rtFTmsYzkRvUBEnxPRZ0Q0otDak4hulvf7UyJ6hoiaFUJbEtFjRLSViD5VygK3HRFNkPuvJKIJumvFUM/fyHv+CRG9JHPdmdsmy3ouJ6JzlPJY+wFdPZVttxKRIKKO8nve2tOGEIL/5B+AEhj5rXoBaALgYwAD8lSXwwCcID+3BrACwAAA98NI6ggYqxLeJz+fByMvFwEYDmB+jut7C4B/AXhFfp8KYLz8/DCAa+Xn6wA8LD+PB/BcDuv4BIDvyc9NAJQXUnvCWOdlNYDmSht+pxDaEsDpAE4A8KlSFqjtALSHkReuPYB28nO7HNRzDIBS+fk+pZ4D5DveFEBP+e6X5KIf0NVTlvcAMBPGpOOO+W5PW73jfgmK6Q9GEsWZyvfJACbnu16yLi8DOBvAcgCHybLDACyXn/8G4FJl/9R+OahbdxjL6p4J4BX5YG9XXtJUu8qXYYT8XCr3oxzUsa3sjMlSXjDtifRiYe1l27wC4JxCaUsAFZaOOFDbAbgUwN+U8oz94qqnZdvXADwtP2e832Z75qof0NUTwAsABgFYg7TAyGt7qn9sksrE9+p+uUSaGo4HMB8RrEwYA38A8GMASfm9A4DdQog6TV1S9ZTb98j946YngG0A/iFNZ48QUUsUUHsKITYA+C2AtQA2wWibRSi8tjQJ2naF8H59F+kM2QVVTyIaB2CDEOJjy6aCqScLjAKHiFoB+DeAm4QQe9VtwhhW5DUumojOB7BVCLEon/XwQSkME8BDQojjARyAYUZJke/2lD6AcTCE2+EAWgIYm6/6BCHfbecHIroNQB2Ap/NdFytE1ALATwHcnu+6uMECI5OCWt2PiMpgCIunhRAvyuItZKxICCqMlQlPAXABEa0B8CwMs9QfAZQTkbmio1qXVD3l9rYAduSgnusBrBdCzJffX4AhQAqpPUcDWC2E2CaEqAXwIoz2LbS2NAnadnl7v4joOwDOB/BtKdzgUp981LM3jIHCx/Jd6g7gQyLqWkj1ZIGRyQcA+sqolCYwHInT8lERIiIAjwL4TAjxe2VTQa1MKISYLIToLoSogNFe/xNCfBvAGwAudqinWf+L5f6xj0yFEJsBrCOio2TRWQCWobDacy2A4UTUQt5/s44F1ZYKQdtuJoAxRNROalNjZFmsENFYGCbTC4QQBy31Hy+jzXoC6AtgAfLQDwghlgghOgshKuS7tB5G0MtmFFJ7xukgKcY/GBEJK2BESdyWx3qcCkPF/wTAYvl3Hgwb9RwAKwHMBtBe7k8A/iLrvQTA0DzUeSTSUVK9YLx8lQCeB9BUljeT3yvl9l45rN9gAAtlm/4HRmRJQbUngLsAfA7gUwBPwYjgyXtbAngGhl+lFkZndlU2bQfDh1Ap/67MUT0rYdj6zffoYWX/22Q9lwM4VymPtR/Q1dOyfQ3STu+8taf1j1ODMAzDML5gkxTDMAzjCxYYDMMwjC9YYDAMwzC+YIHBMAzD+IIFBsMwDOMLFhgMwzCML1hgMAzDML74fyO2B5UQ7ndkAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "s=10\n",
        "r=28\n",
        "L = df.iloc[:, 2] + df.iloc[:, 1]*(1 + s) - df.iloc[:, 0] * s * (r - 1)\n",
        "L.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI8Yfkw6oA0l",
        "outputId": "01d7b72a-3934-4f62-ca10-27be3fc0310c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var1(t-9)', 'var2(t-9)',\n",
              "       'var3(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var1(t-7)',\n",
              "       ...\n",
              "       'var3(t+361)', 'var1(t+362)', 'var2(t+362)', 'var3(t+362)',\n",
              "       'var1(t+363)', 'var2(t+363)', 'var3(t+363)', 'var1(t+364)',\n",
              "       'var2(t+364)', 'var3(t+364)'],\n",
              "      dtype='object', length=1125)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Supervised(df.values, n_in = 10, n_out = 365)\n",
        "dat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "f37830fc-a93f-4216-e5d6-8e44bb1f83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
            "10    0.000000   2.980000   4.633333   1.233333   3.700000   1.480000   \n",
            "11    2.980000   4.633333   1.233333   3.700000   1.480000   6.300000   \n",
            "12    4.633333   1.233333   3.700000   1.480000   6.300000   7.142857   \n",
            "13    1.233333   3.700000   1.480000   6.300000   7.142857  12.500000   \n",
            "14    3.700000   1.480000   6.300000   7.142857  12.500000   7.400000   \n",
            "\n",
            "    var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)  ...  var3(t+361)  var1(t+362)  \\\n",
            "10   6.300000   7.142857  12.500000   7.400000  ...    18.133333     1.850000   \n",
            "11   7.142857  12.500000   7.400000  10.571429  ...    -0.616667     1.233333   \n",
            "12  12.500000   7.400000  10.571429  13.228571  ...     7.958333     0.000000   \n",
            "13   7.400000  10.571429  13.228571   4.633333  ...   -10.200000     6.725000   \n",
            "14  10.571429  13.228571   4.633333   0.616667  ...     1.387500     3.250000   \n",
            "\n",
            "    var2(t+362)  var3(t+362)  var1(t+363)  var2(t+363)  var3(t+363)  \\\n",
            "10    -0.616667    -0.616667     1.233333    -1.233333     7.958333   \n",
            "11    -1.233333     7.958333     0.000000     6.725000   -10.200000   \n",
            "12     6.725000   -10.200000     6.725000    -3.475000     1.387500   \n",
            "13    -3.475000     1.387500     3.250000    -2.087500     3.712500   \n",
            "14    -2.087500     3.712500     1.162500     1.625000    -3.950000   \n",
            "\n",
            "    var1(t+364)  var2(t+364)  var3(t+364)  \n",
            "10       0.0000       6.7250   -10.200000  \n",
            "11       6.7250      -3.4750     1.387500  \n",
            "12       3.2500      -2.0875     3.712500  \n",
            "13       1.1625       1.6250    -3.950000  \n",
            "14       2.7875      -2.3250     3.448214  \n",
            "\n",
            "[5 rows x 1105 columns]\n",
            "Index(['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       ...\n",
            "       'var3(t+361)', 'var1(t+362)', 'var2(t+362)', 'var3(t+362)',\n",
            "       'var1(t+363)', 'var2(t+363)', 'var3(t+363)', 'var1(t+364)',\n",
            "       'var2(t+364)', 'var3(t+364)'],\n",
            "      dtype='object', length=1105)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 10, n_out = 365)\n",
        "data.drop(['var2(t-10)', 'var3(t-10)', 'var2(t-9)', 'var3(t-9)', 'var2(t-8)',\n",
        "       'var3(t-8)', 'var2(t-7)', 'var3(t-7)', 'var2(t-6)', 'var3(t-6)',\n",
        "       'var2(t-5)', 'var3(t-5)', 'var2(t-4)', 'var3(t-4)', 'var2(t-2)',\n",
        "       'var3(t-2)', 'var2(t-1)', 'var3(t-1)','var2(t-3)', 'var3(t-3)'], axis = 1, inplace = True)#,18,19\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKb5l_gUaFvi"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOndQpQaFvi",
        "outputId": "56d94a79-1d05-4ff7-d70e-e2d8d00c83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(868, 1, 1096) (868, 9) (218, 1, 1096) (218, 9)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "test_size = len(data) - train_size\n",
        "train_1 = np.array(data[0:train_size])\n",
        "test_1 = np.array(data[train_size:len(data)])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train = scaler.fit_transform(train_1)\n",
        "test = scaler.transform(test_1)\n",
        "trainY = train[:,-9:]\n",
        "trainX = train[:,:-9]\n",
        "testY = test[:,-9:]\n",
        "testX = test[:,:-9]\n",
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-D_j8UaFvj"
      },
      "source": [
        "## Defining the Physical Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Jw7vitLaFvj"
      },
      "outputs": [],
      "source": [
        "s = tf.Variable(10, name=\"sigma\", trainable=True, dtype=tf.float32)\n",
        "r = tf.Variable(28, name=\"rhow\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def phys(y_pred, y_true):\n",
        "    return mean_absolute_error((y_true[:, 2] + y_true[:, 1]*(1 + s) - y_true[:, 0] * s * (r - 1)), (y_pred[:, 2] + y_pred[:, 1]*(1 + s) - y_pred[:, 0] * s * (r - 1)))\n",
        "\n",
        "def phys2(y_pred, y_real):\n",
        "    pred = y_pred[2:]-2*y_pred[1:-1]-y_pred[:-2] + (y_pred[1:-1]-y_pred[:-2])*(1 + s) - y_pred[:-2] * s * (r - 1)\n",
        "    real = y_real[2:]-2*y_real[1:-1]-y_real[:-2] + (y_real[1:-1]-y_real[:-2])*(1 + s) - y_real[:-2] * s * (r - 1)\n",
        "    return(mean_absolute_error(pred, real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874xZ-_u7X_s",
        "outputId": "883c11bb-1fe0-48af-e119-65529c186443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "14/14 [==============================] - 3s 42ms/step - loss: 1272.1001 - val_loss: 16.7028\n",
            "Epoch 2/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 20.5299 - val_loss: 10.3886\n",
            "Epoch 3/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 5.2014 - val_loss: 1.9830\n",
            "Epoch 4/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 1.1290 - val_loss: 0.5877\n",
            "Epoch 5/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.3754 - val_loss: 0.2469\n",
            "Epoch 6/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1741 - val_loss: 0.1371\n",
            "Epoch 7/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1067 - val_loss: 0.0956\n",
            "Epoch 8/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0813 - val_loss: 0.0785\n",
            "Epoch 9/500\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0714 - val_loss: 0.0712\n",
            "Epoch 10/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0676 - val_loss: 0.0681\n",
            "Epoch 11/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0662 - val_loss: 0.0667\n",
            "Epoch 12/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0657 - val_loss: 0.0661\n",
            "Epoch 13/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0656 - val_loss: 0.0659\n",
            "Epoch 14/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0655 - val_loss: 0.0657\n",
            "Epoch 15/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0655 - val_loss: 0.0657\n",
            "Epoch 16/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0655 - val_loss: 0.0656\n",
            "Epoch 17/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0655 - val_loss: 0.0656\n",
            "Epoch 18/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0655 - val_loss: 0.0656\n",
            "Epoch 19/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0655 - val_loss: 0.0656\n",
            "Epoch 20/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0654 - val_loss: 0.0656\n",
            "Epoch 21/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0654 - val_loss: 0.0656\n",
            "Epoch 22/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0654 - val_loss: 0.0656\n",
            "Epoch 23/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0654 - val_loss: 0.0656\n",
            "Epoch 24/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0654 - val_loss: 0.0656\n",
            "Epoch 25/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0654 - val_loss: 0.0655\n",
            "Epoch 26/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0654 - val_loss: 0.0655\n",
            "Epoch 27/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0654 - val_loss: 0.0655\n",
            "Epoch 28/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0654 - val_loss: 0.0655\n",
            "Epoch 29/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0655\n",
            "Epoch 30/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0655\n",
            "Epoch 31/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0653 - val_loss: 0.0655\n",
            "Epoch 32/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0655\n",
            "Epoch 33/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0655\n",
            "Epoch 34/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0654\n",
            "Epoch 35/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0654\n",
            "Epoch 36/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0653 - val_loss: 0.0654\n",
            "Epoch 37/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0654\n",
            "Epoch 38/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0654\n",
            "Epoch 39/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0654\n",
            "Epoch 40/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0654\n",
            "Epoch 41/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0654\n",
            "Epoch 42/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0652 - val_loss: 0.0653\n",
            "Epoch 43/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0652 - val_loss: 0.0653\n",
            "Epoch 44/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0653\n",
            "Epoch 45/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0651 - val_loss: 0.0653\n",
            "Epoch 46/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0653\n",
            "Epoch 47/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0651 - val_loss: 0.0653\n",
            "Epoch 48/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0651 - val_loss: 0.0653\n",
            "Epoch 49/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0652\n",
            "Epoch 50/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0651 - val_loss: 0.0652\n",
            "Epoch 51/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0650 - val_loss: 0.0652\n",
            "Epoch 52/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0650 - val_loss: 0.0652\n",
            "Epoch 53/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0650 - val_loss: 0.0652\n",
            "Epoch 54/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0650 - val_loss: 0.0652\n",
            "Epoch 55/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0650 - val_loss: 0.0652\n",
            "Epoch 56/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0650 - val_loss: 0.0651\n",
            "Epoch 57/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0651\n",
            "Epoch 58/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0651\n",
            "Epoch 59/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0651\n",
            "Epoch 60/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0651\n",
            "Epoch 61/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0651\n",
            "Epoch 62/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0648 - val_loss: 0.0651\n",
            "Epoch 63/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0648 - val_loss: 0.0650\n",
            "Epoch 64/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0648 - val_loss: 0.0650\n",
            "Epoch 65/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0648 - val_loss: 0.0650\n",
            "Epoch 66/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0648 - val_loss: 0.0650\n",
            "Epoch 67/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0648 - val_loss: 0.0650\n",
            "Epoch 68/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0647 - val_loss: 0.0650\n",
            "Epoch 69/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0649\n",
            "Epoch 70/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0649\n",
            "Epoch 71/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0649\n",
            "Epoch 72/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0649\n",
            "Epoch 73/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.0649\n",
            "Epoch 74/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.0649\n",
            "Epoch 75/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0646 - val_loss: 0.0648\n",
            "Epoch 76/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.0648\n",
            "Epoch 77/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.0648\n",
            "Epoch 78/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0646 - val_loss: 0.0648\n",
            "Epoch 79/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0645 - val_loss: 0.0648\n",
            "Epoch 80/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0645 - val_loss: 0.0648\n",
            "Epoch 81/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.0647\n",
            "Epoch 82/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0645 - val_loss: 0.0647\n",
            "Epoch 83/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0645 - val_loss: 0.0647\n",
            "Epoch 84/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0644 - val_loss: 0.0647\n",
            "Epoch 85/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0644 - val_loss: 0.0647\n",
            "Epoch 86/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0644 - val_loss: 0.0647\n",
            "Epoch 87/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0644 - val_loss: 0.0646\n",
            "Epoch 88/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0644 - val_loss: 0.0646\n",
            "Epoch 89/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.0646\n",
            "Epoch 90/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0643 - val_loss: 0.0646\n",
            "Epoch 91/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.0646\n",
            "Epoch 92/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.0646\n",
            "Epoch 93/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0643 - val_loss: 0.0645\n",
            "Epoch 94/500\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0642 - val_loss: 0.0645\n",
            "Epoch 95/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0642 - val_loss: 0.0645\n",
            "Epoch 96/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0642 - val_loss: 0.0645\n",
            "Epoch 97/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0642 - val_loss: 0.0645\n",
            "Epoch 98/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0642 - val_loss: 0.0645\n",
            "Epoch 99/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.0644\n",
            "Epoch 100/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0641 - val_loss: 0.0644\n",
            "Epoch 101/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0641 - val_loss: 0.0644\n",
            "Epoch 102/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0641 - val_loss: 0.0644\n",
            "Epoch 103/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0641 - val_loss: 0.0644\n",
            "Epoch 104/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.0644\n",
            "Epoch 105/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0640 - val_loss: 0.0643\n",
            "Epoch 106/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0640 - val_loss: 0.0643\n",
            "Epoch 107/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0640 - val_loss: 0.0643\n",
            "Epoch 108/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0640 - val_loss: 0.0643\n",
            "Epoch 109/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0639 - val_loss: 0.0643\n",
            "Epoch 110/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0639 - val_loss: 0.0642\n",
            "Epoch 111/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0639 - val_loss: 0.0642\n",
            "Epoch 112/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0639 - val_loss: 0.0642\n",
            "Epoch 113/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0639 - val_loss: 0.0642\n",
            "Epoch 114/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0638 - val_loss: 0.0642\n",
            "Epoch 115/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0638 - val_loss: 0.0642\n",
            "Epoch 116/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0638 - val_loss: 0.0641\n",
            "Epoch 117/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0638 - val_loss: 0.0641\n",
            "Epoch 118/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0638 - val_loss: 0.0641\n",
            "Epoch 119/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0637 - val_loss: 0.0641\n",
            "Epoch 120/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0637 - val_loss: 0.0641\n",
            "Epoch 121/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0637 - val_loss: 0.0641\n",
            "Epoch 122/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0637 - val_loss: 0.0640\n",
            "Epoch 123/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0637 - val_loss: 0.0640\n",
            "Epoch 124/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0636 - val_loss: 0.0640\n",
            "Epoch 125/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0636 - val_loss: 0.0640\n",
            "Epoch 126/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0636 - val_loss: 0.0640\n",
            "Epoch 127/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0636 - val_loss: 0.0640\n",
            "Epoch 128/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0635 - val_loss: 0.0639\n",
            "Epoch 129/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0635 - val_loss: 0.0639\n",
            "Epoch 130/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0635 - val_loss: 0.0639\n",
            "Epoch 131/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0635 - val_loss: 0.0639\n",
            "Epoch 132/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0635 - val_loss: 0.0639\n",
            "Epoch 133/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0639\n",
            "Epoch 134/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0638\n",
            "Epoch 135/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0638\n",
            "Epoch 136/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0634 - val_loss: 0.0638\n",
            "Epoch 137/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0634 - val_loss: 0.0638\n",
            "Epoch 138/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0633 - val_loss: 0.0638\n",
            "Epoch 139/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0633 - val_loss: 0.0637\n",
            "Epoch 140/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0633 - val_loss: 0.0637\n",
            "Epoch 141/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0633 - val_loss: 0.0637\n",
            "Epoch 142/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0633 - val_loss: 0.0637\n",
            "Epoch 143/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0632 - val_loss: 0.0637\n",
            "Epoch 144/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0632 - val_loss: 0.0637\n",
            "Epoch 145/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0632 - val_loss: 0.0636\n",
            "Epoch 146/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0632 - val_loss: 0.0636\n",
            "Epoch 147/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0632 - val_loss: 0.0636\n",
            "Epoch 148/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0631 - val_loss: 0.0636\n",
            "Epoch 149/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0631 - val_loss: 0.0636\n",
            "Epoch 150/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0631 - val_loss: 0.0636\n",
            "Epoch 151/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0631 - val_loss: 0.0635\n",
            "Epoch 152/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0631 - val_loss: 0.0635\n",
            "Epoch 153/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0635\n",
            "Epoch 154/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0635\n",
            "Epoch 155/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.0635\n",
            "Epoch 156/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0630 - val_loss: 0.0635\n",
            "Epoch 157/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0630 - val_loss: 0.0634\n",
            "Epoch 158/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0634\n",
            "Epoch 159/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0634\n",
            "Epoch 160/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0634\n",
            "Epoch 161/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0629 - val_loss: 0.0634\n",
            "Epoch 162/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0628 - val_loss: 0.0634\n",
            "Epoch 163/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0628 - val_loss: 0.0633\n",
            "Epoch 164/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0628 - val_loss: 0.0633\n",
            "Epoch 165/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0628 - val_loss: 0.0633\n",
            "Epoch 166/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0628 - val_loss: 0.0633\n",
            "Epoch 167/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0627 - val_loss: 0.0633\n",
            "Epoch 168/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0627 - val_loss: 0.0633\n",
            "Epoch 169/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0627 - val_loss: 0.0633\n",
            "Epoch 170/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0627 - val_loss: 0.0632\n",
            "Epoch 171/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0627 - val_loss: 0.0632\n",
            "Epoch 172/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0632\n",
            "Epoch 173/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0632\n",
            "Epoch 174/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0626 - val_loss: 0.0632\n",
            "Epoch 175/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0632\n",
            "Epoch 176/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0626 - val_loss: 0.0631\n",
            "Epoch 177/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0631\n",
            "Epoch 178/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.0631\n",
            "Epoch 179/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0625 - val_loss: 0.0631\n",
            "Epoch 180/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.0631\n",
            "Epoch 181/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0625 - val_loss: 0.0631\n",
            "Epoch 182/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0625 - val_loss: 0.0630\n",
            "Epoch 183/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0624 - val_loss: 0.0630\n",
            "Epoch 184/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0624 - val_loss: 0.0630\n",
            "Epoch 185/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0630\n",
            "Epoch 186/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0624 - val_loss: 0.0630\n",
            "Epoch 187/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0624 - val_loss: 0.0630\n",
            "Epoch 188/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0630\n",
            "Epoch 189/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0629\n",
            "Epoch 190/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0629\n",
            "Epoch 191/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0623 - val_loss: 0.0629\n",
            "Epoch 192/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0623 - val_loss: 0.0629\n",
            "Epoch 193/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0629\n",
            "Epoch 194/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.0629\n",
            "Epoch 195/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0622 - val_loss: 0.0628\n",
            "Epoch 196/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0622 - val_loss: 0.0628\n",
            "Epoch 197/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0622 - val_loss: 0.0628\n",
            "Epoch 198/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0621 - val_loss: 0.0628\n",
            "Epoch 199/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0621 - val_loss: 0.0628\n",
            "Epoch 200/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0621 - val_loss: 0.0628\n",
            "Epoch 201/500\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0621 - val_loss: 0.0628\n",
            "Epoch 202/500\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0621 - val_loss: 0.0627\n",
            "Epoch 203/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0621 - val_loss: 0.0627\n",
            "Epoch 204/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0620 - val_loss: 0.0627\n",
            "Epoch 205/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0627\n",
            "Epoch 206/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0620 - val_loss: 0.0627\n",
            "Epoch 207/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0620 - val_loss: 0.0627\n",
            "Epoch 208/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0627\n",
            "Epoch 209/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 210/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 211/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 212/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 213/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 214/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.0626\n",
            "Epoch 215/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0618 - val_loss: 0.0626\n",
            "Epoch 216/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.0625\n",
            "Epoch 217/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.0625\n",
            "Epoch 218/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.0625\n",
            "Epoch 219/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.0625\n",
            "Epoch 220/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0617 - val_loss: 0.0625\n",
            "Epoch 221/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.0625\n",
            "Epoch 222/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.0625\n",
            "Epoch 223/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.0625\n",
            "Epoch 224/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0617 - val_loss: 0.0624\n",
            "Epoch 225/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0617 - val_loss: 0.0624\n",
            "Epoch 226/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0624\n",
            "Epoch 227/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0624\n",
            "Epoch 228/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0616 - val_loss: 0.0624\n",
            "Epoch 229/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0624\n",
            "Epoch 230/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0624\n",
            "Epoch 231/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0616 - val_loss: 0.0623\n",
            "Epoch 232/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 233/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 234/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 235/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 236/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 237/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0623\n",
            "Epoch 238/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0623\n",
            "Epoch 239/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0622\n",
            "Epoch 240/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0622\n",
            "Epoch 241/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0622\n",
            "Epoch 242/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0622\n",
            "Epoch 243/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0622\n",
            "Epoch 244/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0622\n",
            "Epoch 245/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0622\n",
            "Epoch 246/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0622\n",
            "Epoch 247/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0621\n",
            "Epoch 248/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0621\n",
            "Epoch 249/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0621\n",
            "Epoch 250/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0612 - val_loss: 0.0621\n",
            "Epoch 251/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0612 - val_loss: 0.0621\n",
            "Epoch 252/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0612 - val_loss: 0.0621\n",
            "Epoch 253/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0612 - val_loss: 0.0621\n",
            "Epoch 254/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0621\n",
            "Epoch 255/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.0620\n",
            "Epoch 256/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0612 - val_loss: 0.0620\n",
            "Epoch 257/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 258/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 259/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 260/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 261/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 262/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0611 - val_loss: 0.0620\n",
            "Epoch 263/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0620\n",
            "Epoch 264/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 265/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 266/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 267/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 268/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 269/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0610 - val_loss: 0.0619\n",
            "Epoch 270/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0609 - val_loss: 0.0619\n",
            "Epoch 271/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0619\n",
            "Epoch 272/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0619\n",
            "Epoch 273/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0609 - val_loss: 0.0618\n",
            "Epoch 274/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0609 - val_loss: 0.0618\n",
            "Epoch 275/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0618\n",
            "Epoch 276/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0609 - val_loss: 0.0618\n",
            "Epoch 277/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.0618\n",
            "Epoch 278/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0608 - val_loss: 0.0618\n",
            "Epoch 279/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0608 - val_loss: 0.0618\n",
            "Epoch 280/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0608 - val_loss: 0.0618\n",
            "Epoch 281/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.0618\n",
            "Epoch 282/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0608 - val_loss: 0.0617\n",
            "Epoch 283/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0608 - val_loss: 0.0617\n",
            "Epoch 284/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 285/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 286/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 287/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 288/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 289/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 290/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0607 - val_loss: 0.0617\n",
            "Epoch 291/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0606 - val_loss: 0.0617\n",
            "Epoch 292/500\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 293/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 294/500\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 295/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 296/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 297/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 298/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0606 - val_loss: 0.0616\n",
            "Epoch 299/500\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0605 - val_loss: 0.0616\n",
            "Epoch 300/500\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.0605 - val_loss: 0.0616\n",
            "Epoch 301/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.0616\n",
            "Epoch 302/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 303/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 304/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 305/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 306/500\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.0605 - val_loss: 0.0615\n",
            "Epoch 307/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.0615\n",
            "Epoch 308/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0604 - val_loss: 0.0615\n",
            "Epoch 309/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0604 - val_loss: 0.0615\n",
            "Epoch 310/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.0615\n",
            "Epoch 311/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.0615\n",
            "Epoch 312/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 313/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 314/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0604 - val_loss: 0.0614\n",
            "Epoch 315/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 316/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 317/500\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 318/500\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 319/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 320/500\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 321/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 322/500\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0603 - val_loss: 0.0614\n",
            "Epoch 323/500\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 324/500\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 325/500\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 326/500\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 327/500\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 328/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 329/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 330/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 331/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0602 - val_loss: 0.0613\n",
            "Epoch 332/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0613\n",
            "Epoch 333/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0613\n",
            "Epoch 334/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0613\n",
            "Epoch 335/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 336/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 337/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 338/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 339/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 340/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.0612\n",
            "Epoch 341/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 342/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 343/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 344/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 345/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 346/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0612\n",
            "Epoch 347/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0611\n",
            "Epoch 348/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0611\n",
            "Epoch 349/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0600 - val_loss: 0.0611\n",
            "Epoch 350/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 351/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 352/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 353/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 354/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 355/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 356/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 357/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 358/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0611\n",
            "Epoch 359/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0599 - val_loss: 0.0610\n",
            "Epoch 360/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 361/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 362/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 363/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 364/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 365/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 366/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 367/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 368/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 369/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0598 - val_loss: 0.0610\n",
            "Epoch 370/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0597 - val_loss: 0.0610\n",
            "Epoch 371/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0597 - val_loss: 0.0610\n",
            "Epoch 372/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0597 - val_loss: 0.0610\n",
            "Epoch 373/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 374/500\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 375/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 376/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 377/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 378/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 379/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 380/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0597 - val_loss: 0.0609\n",
            "Epoch 381/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 382/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 383/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 384/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 385/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 386/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0609\n",
            "Epoch 387/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0608\n",
            "Epoch 388/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0608\n",
            "Epoch 389/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0608\n",
            "Epoch 390/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0608\n",
            "Epoch 391/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0596 - val_loss: 0.0608\n",
            "Epoch 392/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 393/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 394/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 395/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 396/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 397/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 398/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 399/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 400/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0608\n",
            "Epoch 401/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0607\n",
            "Epoch 402/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0595 - val_loss: 0.0607\n",
            "Epoch 403/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 404/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 405/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 406/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 407/500\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 408/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 409/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 410/500\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 411/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 412/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 413/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 414/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0594 - val_loss: 0.0607\n",
            "Epoch 415/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0607\n",
            "Epoch 416/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 417/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 418/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 419/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 420/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 421/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 422/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 423/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 424/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 425/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 426/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 427/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0593 - val_loss: 0.0606\n",
            "Epoch 428/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0606\n",
            "Epoch 429/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0606\n",
            "Epoch 430/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0606\n",
            "Epoch 431/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0606\n",
            "Epoch 432/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 433/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 434/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 435/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 436/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 437/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 438/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 439/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 440/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0605\n",
            "Epoch 441/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 442/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 443/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 444/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 445/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 446/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 447/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0605\n",
            "Epoch 448/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 449/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 450/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 451/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 452/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 453/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 454/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0591 - val_loss: 0.0604\n",
            "Epoch 455/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 456/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 457/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 458/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 459/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 460/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 461/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 462/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 463/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 464/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0590 - val_loss: 0.0604\n",
            "Epoch 465/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0603\n",
            "Epoch 466/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0590 - val_loss: 0.0603\n",
            "Epoch 467/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0590 - val_loss: 0.0603\n",
            "Epoch 468/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0603\n",
            "Epoch 469/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 470/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 471/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 472/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 473/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 474/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 475/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 476/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 477/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 478/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 479/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 480/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0589 - val_loss: 0.0603\n",
            "Epoch 481/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0589 - val_loss: 0.0602\n",
            "Epoch 482/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0602\n",
            "Epoch 483/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 484/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 485/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 486/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 487/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 488/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 489/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 490/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 491/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 492/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 493/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 494/500\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 495/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 496/500\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0588 - val_loss: 0.0602\n",
            "Epoch 497/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0601\n",
            "Epoch 498/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0587 - val_loss: 0.0601\n",
            "Epoch 499/500\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.0587 - val_loss: 0.0601\n",
            "Epoch 500/500\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.0587 - val_loss: 0.0601\n"
          ]
        }
      ],
      "source": [
        "s = tf.Variable(10, name=\"sigma\", trainable=True, dtype=tf.float32)\n",
        "r = tf.Variable(28, name=\"rhow\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square((y_pred[:, 2] + y_pred[:, 1]*(1 + s) - y_pred[:, 0] * s * (r - 1)))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(9))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=500, batch_size=64, validation_data=(testX, testY), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "(218, 9)\n",
            "(218, 1096)\n",
            "Test RMSE: 8.179\n",
            "Test MAE: 7.233\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "yhat = model.predict(testX)\n",
        "print(yhat.shape)\n",
        "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
        "print(testX.shape)\n",
        "inv_yhat = np.concatenate((testX, yhat), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat1 = inv_yhat[:, -3:]\n",
        "inv_yhat = inv_yhat[:, -3]\n",
        "inv_y = np.concatenate((testX, testY), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y1 = inv_y[:, -3:]\n",
        "inv_y = inv_y[:, -3]\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
