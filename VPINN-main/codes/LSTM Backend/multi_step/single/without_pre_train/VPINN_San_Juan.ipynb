{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xSItPJipBaZ5"
      },
      "source": [
        "## Gathering Dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "1a821417-b2e6-4bf3-ad0b-494bb85bea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.3.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.21.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_SAN JUAN_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        4\n",
            "1        5\n",
            "2        4\n",
            "3        3\n",
            "4        6\n",
            "        ..\n",
            "1191    56\n",
            "1192    46\n",
            "1193    52\n",
            "1194    34\n",
            "1195    25\n",
            "Name: Cases, Length: 1196, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/sanjuan.csv\")\n",
        "training_set = data.iloc[:, 3]\n",
        "print(training_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, _and_ $\\frac{d^2x}{dt^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "461\n",
            "1       0.142857\n",
            "2      -0.142857\n",
            "3      -0.142857\n",
            "4       0.428571\n",
            "5      -0.571429\n",
            "          ...   \n",
            "1191   -1.000000\n",
            "1192   -1.428571\n",
            "1193    0.857143\n",
            "1194   -2.571429\n",
            "1195   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "2      -0.040816\n",
            "3       0.000000\n",
            "4       0.081633\n",
            "5      -0.142857\n",
            "6       0.122449\n",
            "          ...   \n",
            "1191   -0.081633\n",
            "1192   -0.061224\n",
            "1193    0.326531\n",
            "1194   -0.489796\n",
            "1195    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 7 # Weekly Data\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:]\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:]\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.142857\n",
            "1      -0.142857\n",
            "2      -0.142857\n",
            "3       0.428571\n",
            "4      -0.571429\n",
            "          ...   \n",
            "1190   -1.000000\n",
            "1191   -1.428571\n",
            "1192    0.857143\n",
            "1193   -2.571429\n",
            "1194   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "0      -0.040816\n",
            "1       0.000000\n",
            "2       0.081633\n",
            "3      -0.142857\n",
            "4       0.122449\n",
            "          ...   \n",
            "1189   -0.081633\n",
            "1190   -0.061224\n",
            "1191    0.326531\n",
            "1192   -0.489796\n",
            "1193    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True)\n",
        "gradient_t = gradient_t.reset_index(drop=True)\n",
        "gradient_tt = gradient_tt.reset_index(drop=True)\n",
        "print(gradient_t)\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1195,)\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "print(gradient_t.shape)\n",
        "print(training_set.shape[:-1])\n",
        "df = pd.concat((training_set[:-1], gradient_t), axis=1)\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df[:-1], gradient_tt), axis=1)\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation (_Van der Pol Oscillator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "45058d71-6952-4a40-afa5-84c2f42197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhhklEQVR4nO3de5zcdX3v8dd79pYbucckhEAAUQheAFcKVkAlyEUOWGttOLaGUzmx9djai6cnHPrwqO3jFLWntraeSg5q0VoRrZaoWC7RVqyILAURCJCEayAkm0Du2exlPueP+e1mdnZ2J5u5/mbez8djH/u7zXy/v/nNvOc7399NEYGZmTW/TL0rYGZmteHANzNrEQ58M7MW4cA3M2sRDnwzsxbhwDczaxENH/iSvihpu6SHj2DZz0h6MPl7QtKuGlTRzCwV1OjH4Us6H9gHfDkiXjOJx/0ucGZE/FbVKmdmliIN38KPiB8BL+VPk3SypH+RdL+kuyWdWuShVwFfq0klzcxSoL3eFThKa4HfjoiNkn4J+L/A24ZnSjoBOBH4QZ3qZ2bWcFIX+JJmAG8CviFpeHJXwWIrgW9GxFAt62Zm1shSF/jkuqF2RcQZEyyzEvhvtamOmVk6NHwffqGI2AM8JenXAJTz+uH5SX/+HOCeOlXRzKwhNXzgS/oaufB+taQtkt4PvBd4v6SfA48AV+Y9ZCVwczT64UdmZjXW8IdlmplZZTR8C9/MzCqjYXfazp8/P5YtW1bvapiZpcr999+/IyIWFJvXsIG/bNkyenp66l0NM7NUkfTMePPcpWNm1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi3CgW9m1iIc+Cm2cdtefvbUS6UXNDOjgU+8stIu+syPAHj6+nfUuSZmlgZu4ZuZtQgHvplZi3Dgm5m1CAe+mVmLcOCbmbUIB76ZWYtw4JuZtQgHvplZi6hI4Eu6RNLjkjZJWjPBcr8qKSR1V6JcMzM7cmUHvqQ24HPApcBy4CpJy4ssdwzwYeDecsu00VZ98Wds3La33tUwswZXiRb+2cCmiHgyIvqBm4Eriyz3p8Angb4KlGl5/u2JXv7XukfqXQ0za3CVCPwlwHN541uSaSMknQUsjYjvTfREklZL6pHU09vbW4GqtQ6p3jUws0ZX9Z22kjLAXwJ/VGrZiFgbEd0R0b1gwYJqV62pZJz4ZlZCJQL/eWBp3vhxybRhxwCvAf5V0tPAOcA677g1M6utSgT+fcApkk6U1AmsBNYNz4yI3RExPyKWRcQy4KfAFRHRU4GyLSG38M2shLIDPyIGgQ8BtwMbgFsi4hFJn5B0RbnPb0fGcW9mpVTkBigRcRtwW8G0j46z7FsqUaaN5ga+mZXiM22bhPPezEpx4DcJ9+GbWSkO/CaRcd6bWQkO/KbhxDeziTnwm4R7dMysFAd+k3Dem1kpDvwm4Ra+mZXiwG8SchvfzEpw4DcJt/DNrBQHfpPw1TLNrBQHfrNIed7fct9zfPw7vomLWTU58FNsSsfhzZfyvOeP/+khvvTvT9e7GmZNzYGfYvndOL60gpmV4sBPsYjDw457MyvFgZ9iweHEdwPfzEpx4KeYW/hmNhkO/BTLy3sflmlmJTnw0yw/8Z33ZlZCRQJf0iWSHpe0SdKaIvP/UNKjkh6StF7SCZUot9WN6sN34ptZCWUHvqQ24HPApcBy4CpJywsWewDojojXAd8EPlVuuVbQh++8N7MSKtHCPxvYFBFPRkQ/cDNwZf4CEfHDiDiQjP4UOK4C5bY89+iY2WRUIvCXAM/ljW9Jpo3n/cD3i82QtFpSj6Se3t7eClStuUX4sEwzO3I13Wkr6TeAbuDTxeZHxNqI6I6I7gULFtSyaqk0uoXvxDezibVX4DmeB5bmjR+XTBtF0grgOuCCiDhUgXItT8bHW5lZCZWIifuAUySdKKkTWAmsy19A0pnADcAVEbG9AmUao3fauhffzEopO/AjYhD4EHA7sAG4JSIekfQJSVcki30amAF8Q9KDktaN83R2hHYfHBg17j58MyulEl06RMRtwG0F0z6aN7yiEuXYYfds3jFq3HlvZqW45zelujraRo27hW9mpTjwU2pKe0Hgu41vZiU48FOqo210wLuFb2alOPBTaig76hAdt+/NrCQHfkqNCXw38c2sBAd+Sg0WBL6ZHZ1/e6KXWx8cc65oU6rIYZlWe4UtfDM7Oqu++DMA3r58EVM720osnW5u4adUM7XwI5pnXSy9/uKOx+tdhapz4KfUUDZb7ypUzMCQA9/qY2Do8OdoT8HZ683IgZ9ShS38NO+zzf/QmdXSx7/zyMhwe1t9PkQv7+/n4ed316QsB35KNVMfvgPf6uWHjx2+70Zbpj6B/+7P/4TL/+bHNSnLgZ9SY4/DT28Tv9+Bb3UyvevwTtr2Ol1jfHPvfgCyNWjEOfBTqpl22roP3+plSkd+4Ne+0XTno9tGhg8ODFW9PAd+Sr20v7/eVaiYgUG38K0++vPeezf++Cn29tV2x+1//XLPyLAD38Z1/fcfq3cVKmbfocF6V8FqZE+NA7WU/oLGxvO7DtapJnCw34HfEO7ZvJPL/+ZuDg1Wf4O0osKbuVhzemjLLl73sTu47Rdb612VEX0FrepaHu38/YLX4YADvzGs+dZDPPz8Hl7Y1Vfvqox4/XGzOG3xzJHx514+wDU39dSklVBpuw448FvBg8/tAuAnBTfvqZfHX9zLC7tHf6azNTwJ8He++h+jxmvRpeNLK0zg7o29rP7y/SNHkdRjp8549h0aZN6MrpHx4Z0/d2/s5e2nL6pXtY7KroPNsz/CxjfcfdLR1hjtzHf/3U/GTKtV3r9cZB9cLQ61rsgrL+kSSY9L2iRpTZH5XZK+nsy/V9KySpRbbR/4yv0cHBga2RCNdOz7/kNDzOga+32dabAzsJ7fdbDomzvfdd9+GMidPPbCroNc+62H3H1WA4+8sJtla77HZ+58oiblPf7iXgA6GyTw9xbZdzRUo8TP31k7rBaXGCn7lZfUBnwOuBRYDlwlaXnBYu8HXo6IVwKfAT5ZbrlH60hf1D19A2P61H7v5ge4pee5ko/df2iwqv3ST+/Yz7a9fcye2jFmXp0OJR7XL1//A97x2btHXved+w6Nmv9i3k/qzrYM77+ph6/97DnuenQ79z65k0de2N1wO/qaxRd//DQAf71+Y9XLenl/P9+4fwtQ2xb+ocGhkYMC+gezZLMxYWNiKBtjduROJCImHdT/8ezL9DzzctGyN27bO6nnmiyV+60i6VzgYxFxcTJ+LUBE/HneMrcny9wjqR14EVgQExTe3d0dPT1jvwVL2X1wgA/f/ABD2SAbwVA29/fYi3vZ23f4G/2MpbPZvqePk18xA8i1jKXcjUT2HRrkvqfHbpBCb331AiB3TPz+Q4Mc6B/isRcPb7D5MzrpbMtw8itm0NWee5NnI9dPmI3hN8vweG74uZcOMHNqB8fPncaTO/azbN40InInJw0MZXmydz/b9+ZC82P/aTkf+86jo+p05vGzmTe9i4Gh7Mj6AAS5HVQDQ8GUjgx7+wbZuruP04+dSUSuuyq//1LKncqV+8GQe5ZDg0N0tmUYyAb9g0NM72xHOnxOwHBZB/qH2N8/yIFDQzy5Y3/R1+74udNYPGsKW3f38exLBwDobM+M+2F708nzmNHVzmCyXbORu57Qvr5BfvH8boZ/fEnQfcIcpnUeWW9lkPuCnjmlnUjWoS2j5PkPv3+GIthzcGDU9l08awqnHzuTjrYMBweGxpz6FuS6CHL/D7+2uWm57T08eWQ8eeBANktHW2ZknYcfP/w+GfUcyWOyESNl5ZfN8Pstr8xsxKh1OWn+dE6cP51MRiOfnYl+Kw5mg10HBpg3o/NwOeOs5/Y9h9i4fd+ox7dlxAWvWjBun/lQNhgYyjIwlAvgXzy/m862DP1DWU4/diYzutpZOHNKLqCHsgwOZRlKPlN3b9zBa5bMZPP2/ZPuF3/TyfP4yeadHDdnKktmT2V6VztD2Rh3G/77pp0j02Z0tdO9bA7tmQztGdHWptz/jNi8fR9PbNs3YX1WnXsCN93zDABfuvqNvPXUV0yq7sMk3R8R3cXmVaIPfwmQ3+zdAvzSeMtExKCk3cA8YNTeG0mrgdUAxx9//FFX6KX9/WSUe6HbMsqdQVfwvnpqx34igh37+ulqz4z6kBzpqf7b9x6iLSMyEjO62pk/o2vUh2jn/n4iYO6MToayh8MkkyRpRrkvmoxyZ8pmI3hhdx8v7O5jMBvsPjjApu37mN7VTkdbhs62DAuO6RoJ/DecMHdMnR54dhevWjiDqR1teR/CXBBOaW+jfzDLwf4hNm3fR/9Qlq27+pjSkWEoApH70iseSDC8C6M9I3YfHBh5bad0ZEZeO4CpnW3MmtrB/kPjv7m37j7IzKntzOhqZ+aUdvb0TXxo5k827+Sk+dOZ0tGWu72jREdG9O49RH5PWwRs23OIOdOPvCFzaGCI/YcGyUYwpaONwaEgk4G2vPdQRmJrwQ6+rbv76GzPfbiHv2AKe9SUTFTevNzw4WkjZ0knX9DKQFuIl/b3s69vkI72zMiymcLH5T2mXZmR6SNljby/xn6J9w0M8fTO3Jftkzv28+SO/SyeNYV5MzpLdg32D2bZ2zc48p4YXsfh1+DwsJgxZWzMDGWDbXv6xt0vJonO9gxTk+2d3xjY8vJB5k3vzD2+Lff6d7RlyGTEMztzDYyHn98zYf3H85PNO0fK2H9okAXHdDG1o23UNsxft3z7Dg3y0v7+kUbCwFCWoWwwmA22vHxw5LWJgGmdbWN6EG7p2TIy/Ptff5AHP3pRxW9s1FA7bSNiLbAWci38o3mOWVM7WPehNxedt+tAPx/6xwf4k8tP41WvOCa38cZ5QXcfGOArP32av7ijeP/md3/3zbxmyayi87bt6eOezTu54vXHsrdvkFnTxna9jCciSm7k3QcH6Hn6JZbMmTpmXltG3PEHFxxxedW2bM33APiX3z+Pp3ccYGAoS2d7hosLdixf//3H+OKPnxr3ee74g/N51cJjxkyP5FdczzMvs7dvkPNOmT/q7MlKG/6V84UfP8VQNvjABSdXraxauPSv72bD1lw4PvFnl9LZXp3ulvufeYlf/bt7RsZvfF83K5YvPOLHZ5NWdv9gtuQ16zf37uOk+dORxJ6+AW7+2bPs2NfPyQums//QEJ/47qMsnTuVP3nHcj7wlfuLPsfyxTO57cPnlazXgf5B7n3qJba8dICVZx8/YXfV4FCW9mT+vz6+nau/dN+o+fmt/x9+5C1VuYtdJQL/eWBp3vhxybRiy2xJunRmATupsdnTOvmHawp/fBQ3a1oHs6Z1jpn+t//5TN766lcwvcgO02ELZ07hnWcuGXmeyTiSjTxragcXnraw6Nm2c4rUuREsnTONUxfNHHe+NPqaOktmT+Xf17yNbDbITHB0lCTa28Q5J82raH3H09WeC5trzjupJuVV28evOJ333HAPbzp5XtXCHnK/Ru+59m2c++c/AGDZ/OmTevzwe+BIblBy8oIZI8Mzp3Sw+vzRX8rvO/cEAO7asI3xdBzhlTOndbbz1lcfWddLe96XwUQ7rn/wRxcwd3p1PseV2ML3AadIOlFSJ7ASWFewzDpgVTL8buAHE/XfN4oFyWGPK047vEEvf92xE4Z9vTXIARBjTCvxQS38eA3vfJ4o7K183SfMYfX5J/GRi19d9bLyQ2zxrClVL2887W0Z2tsyvH35Iv77OOv9+qWzq16HYk5ddAwn5X1hVVrZ8RARg8CHgNuBDcAtEfGIpE9IuiJZ7AvAPEmbgD8Exhy62YguPn0hN/zmG/jgW18JMLLjtVEUi8JGOyzzU+9+HRefvnDSP08bbT2aVSYj/udlp3HW8XOqXlZH3iFkjdBoymTEu85aMmb67114Cn/yjsIDDStrvEsxV/smLBV51SPiNuC2gmkfzRvuA36tEmXVkiQuPn0R//Fs7oidYn3mjabRgvI93Ut5T/fSkssVVrutwdbDyteIv9aKfV7e/Mr5Ve3egvFvWHSoyhcSbKwma4NaNi/X3/jRy6v7rV8JjXYc/pEqvJ7/ojr+5LfWUSx4qx32UPzXOVQ/8Ov/uyoF5k7v5Onr31HvaoxR7M3aaC38o3HBqxbwmV8/o97VsBZQ7PNSizOBx+vi/OBbq3vUlwO/yaQ18POrvfKNS6t2lILV1/Xvei2vPa744cz1UDTw26v/GSpWQmd7hg++5ZVVLdeB32RSmvejPgD1ureoVd/Ks4/+hMpqKPZWq8bx72PLKDKt6qW6Dz/Vit3HNq0t/PxPQPsRHgNtVq5in6GpVTxxb9hpi2dy8ekL+bN3vuZwXWrwtnfgN5nXjXP2b5q0pXXPs6WOirzVjp1d/aPxOtoy3PCb3Zx+7OGTEYt9+VSaP1lN5n+/67X1rsJRyX+rN9J9B6y51fsXcX73pVv4NrGCN8ipi46p6nVkqin/zV7vD6G1jnq3LWr9XnfgN5Fm2dkZhZc2NauSwsD9jXNqu1M5v3zvtLUJjTk7NcWBP+pmYs57q5HCz9CfvbO2XaKju3Tch2+TkOaukGxe4jvvrVZqsaN0IvnneLmFb5OS5hb+YH7gO/GtRur9kRnVSPNOW5tI4fsjzYGff6s79+FbrdT7V7H78O2opfkKk0Nu4Vsd1Psj4z58O2ppbuHnB76Pw7daqUXIHqk3Lqv+PQkc+ClW+GZtxOuNH6nhLp35M7pqdrtCs0by2avOrHoZDvwmkuZL0Ay38D984StT/cVlNhnDbbYls6cyrbP617J04DeRNHfpDPfoNNJPbLNaqdUtvssKfElzJd0paWPyf0wnlKQzJN0j6RFJD0n69XLKtMPG3Pg7xWE5/IZP8zqYTdZwA6dWxymU28JfA6yPiFOA9RS/OfkB4H0RcTpwCfBXkmaXWa4VkeYWfoy08OtbD7NaGj6yrlY3dS+3lCuBtyTDNwH/CvyP/AUi4om84RckbQcWALvKLNsKpLnve/jY+/SugdnkLZo1hf952alc9trFNSmv3Bb+wojYmgy/CCycaGFJZwOdwOZx5q+W1COpp7e3t8yqNb8x19JJcfN4uIXvLh2rtRt+8w1A7l7K9bD6/JM5bs60mpRVsoUv6S5gUZFZ1+WPRERIGrcrStJi4CvAqogoemv2iFgLrAXo7u726TeTlObj10cOw0/vKlhKXXz6IjZ84hI60nyY2xEqGfgRsWK8eZK2SVocEVuTQN8+znIzge8B10XET4+6tjZK4YWf3KVjdnSmdqbzPhKTVW6XzjpgVTK8Cri1cAFJncC3gS9HxDfLLM8mkOYuHdylY1Z15Qb+9cBFkjYCK5JxJHVLujFZ5j3A+cDVkh5M/s4os1wrIs0t/OEzbZ33ZtVT1lE6EbETuLDI9B7gmmT4H4B/KKccK27sDVDqU49KGOnCd+CbVU2KI8IKpblLx0fpmFWfA7+JNEOXjplVjwO/iaS6hZ/897V0zKrHgd9E0nxpheHET/EamDU8B34TSXPrePg4fPfhm1WPAz/FCrMxzVmZTc69TvM6mDU6B34TSXePjs+0Nas2B36Kjbm0Qoqbx+EboJhVnQO/iaQ5LLO+Hr5Z1Tnwm0iau3Rwl45Z1TnwU6ywNdwMXTppXgezRufAbyJpbuH74mlm1efAbyLuwzeziTjwU6wwG9PcHeJLK5hVnwO/iaS5SyfCZ9qaVZsDv4mkOSzD19IxqzoHfooVdn+kOO8Pn2mb4nUwa3QO/CbSDC38NK+DWaMrK/AlzZV0p6SNyf85Eyw7U9IWSX9bTpk2vjT34Y8cllnnepg1s3Jb+GuA9RFxCrA+GR/PnwI/KrM8yzPmKJ0UJ/7IDa/SuwpmDa/cwL8SuCkZvgl4Z7GFJL0BWAjcUWZ5NoE0H9I4nPfu0jGrnnIDf2FEbE2GXyQX6qNIygD/B/hIqSeTtFpSj6Se3t7eMqvW/MZeWqE+9aiEcJeOWdWVDHxJd0l6uMjflfnLRe4TW+xO1B8EbouILaXKioi1EdEdEd0LFiw44pWwnDS3jt92aq6tsGTO1DrXxKx5tZdaICJWjDdP0jZJiyNiq6TFwPYii50LnCfpg8AMoFPSvoiYqL/fjkKaW/i/fcFJvKf7OObN6Kp3VcyaVsnAL2EdsAq4Pvl/a+ECEfHe4WFJVwPdDvvKGHscfnoTX5LD3qzKyu3Dvx64SNJGYEUyjqRuSTeWWzmbnDR36ZhZ9ZXVwo+IncCFRab3ANcUmf73wN+XU6aNL81dOmZWfT7Ttom4hW9mE3HgNxHnvZlNxIHfRNzCN7OJOPCbiAPfzCbiwG8i3mlrZhNx4DeRNB+Hb2bV58BvIm7hm9lEHPhNxH34ZjYRB34TyXhrmtkEHBFNxH34ZjYRB34TaXPgm9kEHPhN4l1nLeGck+bVuxpm1sDKvTyyNYi/fM8Z9a6CmTU4t/DNzFqEA9/MrEU48M3MWoQD38ysRTjwzcxaRFmBL2mupDslbUz+zxlnueMl3SFpg6RHJS0rp1wzM5u8clv4a4D1EXEKsD4ZL+bLwKcj4jTgbGB7meWamdkklRv4VwI3JcM3Ae8sXEDScqA9Iu4EiIh9EXGgzHLNzGySyg38hRGxNRl+EVhYZJlXAbskfUvSA5I+Lamt2JNJWi2pR1JPb29vmVUzM7N8Jc+0lXQXsKjIrOvyRyIiJMU4ZZwHnAk8C3wduBr4QuGCEbEWWAvQ3d1d7LnMzOwolQz8iFgx3jxJ2yQtjoitkhZTvG9+C/BgRDyZPOafgXMoEvhmZlY95XbprANWJcOrgFuLLHMfMFvSgmT8bcCjZZZrZmaTVG7gXw9cJGkjsCIZR1K3pBsBImII+AiwXtIvAAH/r8xyzcxsksq6WmZE7AQuLDK9B7gmb/xO4HXllGVmZuXxmbZmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiygp8SXMl3SlpY/J/zjjLfUrSI5I2SPqsJJVTrpmZTV65Lfw1wPqIOAVYn4yPIulNwC+Tu6fta4A3AheUWa6ZmU1SuYF/JXBTMnwT8M4iywQwBegEuoAOYFuZ5ZqZ2SSVG/gLI2JrMvwisLBwgYi4B/ghsDX5uz0iNpRZrpmZTVJ7qQUk3QUsKjLruvyRiAhJUeTxrwROA45LJt0p6byIuLvIsquB1QDHH3986dqbmdkRKxn4EbFivHmStklaHBFbJS0GthdZ7FeAn0bEvuQx3wfOBcYEfkSsBdYCdHd3j/nyMDOzo1dul846YFUyvAq4tcgyzwIXSGqX1EFuh627dMzMaqzcwL8euEjSRmBFMo6kbkk3Jst8E9gM/AL4OfDziPhOmeWamdkklezSmUhE7AQuLDK9B7gmGR4CPlBOOWZmVj6faWtm1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYtwoFvZtYiHPhmZi2irFscWv1d/67XcsrCY+pdDTNLgbJa+JJ+TdIjkrKSuidY7hJJj0vaJGlNOWXaaCvPPp43nDCn3tUwsxQot0vnYeBdwI/GW0BSG/A54FJgOXCVpOVllmtmZpNUVpdORGwAkDTRYmcDmyLiyWTZm4ErgUfLKdvMzCanFjttlwDP5Y1vSaaNIWm1pB5JPb29vTWomplZ6yjZwpd0F7CoyKzrIuLWSlYmItYCawG6u7ujks9tZtbqSgZ+RKwos4zngaV548cl08zMrIZq0aVzH3CKpBMldQIrgXU1KNfMzPKUe1jmr0jaApwLfE/S7cn0YyXdBhARg8CHgNuBDcAtEfFIedU2M7PJKvconW8D3y4y/QXgsrzx24DbyinLzMzKo4jG3DcqqRd4poynmA/sqFB16s3r0pi8Lo2p1dflhIhYUGxGwwZ+uST1RMS4Z/+midelMXldGpPXZXy+eJqZWYtw4JuZtYhmDvy19a5ABXldGpPXpTF5XcbRtH34ZmY2WjO38M3MLI8D38ysRTRd4KftZiuSlkr6oaRHk5vJfDiZPlfSnZI2Jv/nJNMl6bPJ+j0k6az6rsFYktokPSDpu8n4iZLuTer89eQSG0jqSsY3JfOX1bXiBSTNlvRNSY9J2iDp3LRuF0l/kLy/Hpb0NUlT0rJdJH1R0nZJD+dNm/R2kLQqWX6jpFUNtC6fTt5jD0n6tqTZefOuTdblcUkX500/upyLiKb5A9qAzcBJQCfwc2B5vetVos6LgbOS4WOAJ8jdKOZTwJpk+hrgk8nwZcD3AQHnAPfWex2KrNMfAv8IfDcZvwVYmQx/HvidZPiDwOeT4ZXA1+td94L1uAm4JhnuBGancbuQuxz5U8DUvO1xdVq2C3A+cBbwcN60SW0HYC7wZPJ/TjI8p0HW5e1AezL8ybx1WZ5kWBdwYpJtbeXkXN3fjBV+Mc8Fbs8bvxa4tt71muQ63ApcBDwOLE6mLQYeT4ZvAK7KW35kuUb4I3c11PXA24DvJh+8HXlv6JFtRO76Sucmw+3Jcqr3OiT1mZWEpAqmp267cPieFHOT1/m7wMVp2i7AsoKQnNR2AK4CbsibPmq5eq5LwbxfAb6aDI/Kr+HtUk7ONVuXzhHfbKURJT+dzwTuBRZGxNZk1ovAwmS40dfxr4A/BrLJ+DxgV+Quogej6zuyLsn83cnyjeBEoBf4UtI9daOk6aRwu0TE88BfAM8CW8m9zveTzu0ybLLboWG3T4HfIvcLBaqwLs0W+KklaQbwT8DvR8Se/HmR+xpv+ONnJV0ObI+I++tdlwpoJ/fT++8i4kxgP7mugxEp2i5zyN1W9ETgWGA6cEldK1VBadkOpUi6DhgEvlqtMpot8FN5sxVJHeTC/qsR8a1k8jZJi5P5i4HtyfRGXsdfBq6Q9DRwM7lunb8GZksavjJrfn1H1iWZPwvYWcsKT2ALsCUi7k3Gv0nuCyCN22UF8FRE9EbEAPAtctsqjdtl2GS3QyNvHyRdDVwOvDf5AoMqrEuzBX7qbrYiScAXgA0R8Zd5s9YBw0cSrCLXtz88/X3J0QjnALvzftrWVURcGxHHRcQycq/9DyLivcAPgXcnixWuy/A6vjtZviFaahHxIvCcpFcnky4EHiWF24VcV845kqYl77fhdUnddskz2e1wO/B2SXOSXzxvT6bVnaRLyHWDXhERB/JmrQNWJkdNnQicAvyMcnKunjtiqrRD5DJyR7psJnff3brXqUR930zu5+hDwIPJ32Xk+kzXAxuBu4C5yfICPpes3y+A7nqvwzjr9RYOH6VzUvJG3QR8A+hKpk9Jxjcl80+qd70L1uEMoCfZNv9M7uiOVG4X4OPAY8DDwFfIHfmRiu0CfI3cvocBcr+83n8024Fc//im5O+/NNC6bCLXJz/8+f983vLXJevyOHBp3vSjyjlfWsHMrEU0W5eOmZmNw4FvZtYiHPhmZi3CgW9m1iIc+GZmLcKBb2bWIhz4ZmYt4v8DYypVUqbIhsQAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "mu = 4\n",
        "L = df.iloc[:, 2] - mu * (df.iloc[:, 1] - (df.iloc[:, 0]**2 * df.iloc[:, 1]) - (1/mu) * df.iloc[:, 0])\n",
        "L.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI8Yfkw6oA0l",
        "outputId": "01d7b72a-3934-4f62-ca10-27be3fc0310c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var1(t-9)', 'var2(t-9)',\n",
              "       'var3(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var1(t-7)',\n",
              "       ...\n",
              "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
              "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
              "      dtype='object', length=186)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "dat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "f37830fc-a93f-4216-e5d6-8e44bb1f83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
            "10         4.0        5.0        4.0        3.0        6.0        2.0   \n",
            "11         5.0        4.0        3.0        6.0        2.0        4.0   \n",
            "12         4.0        3.0        6.0        2.0        4.0        5.0   \n",
            "13         3.0        6.0        2.0        4.0        5.0       10.0   \n",
            "14         6.0        2.0        4.0        5.0       10.0        6.0   \n",
            "\n",
            "    var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)  ...  var3(t+48)  var1(t+49)  \\\n",
            "10        4.0        5.0       10.0        6.0  ...    0.224490        14.0   \n",
            "11        5.0       10.0        6.0        8.0  ...   -0.183673        18.0   \n",
            "12       10.0        6.0        8.0        2.0  ...    0.122449        13.0   \n",
            "13        6.0        8.0        2.0        6.0  ...    0.061224        14.0   \n",
            "14        8.0        2.0        6.0       17.0  ...    0.020408        18.0   \n",
            "\n",
            "    var2(t+49)  var3(t+49)  var1(t+50)  var2(t+50)  var3(t+50)  var1(t+51)  \\\n",
            "10    0.571429   -0.183673        18.0   -0.714286    0.122449        13.0   \n",
            "11   -0.714286    0.122449        13.0    0.142857    0.061224        14.0   \n",
            "12    0.142857    0.061224        14.0    0.571429    0.020408        18.0   \n",
            "13    0.571429    0.020408        18.0    0.714286   -0.061224        23.0   \n",
            "14    0.714286   -0.061224        23.0    0.285714    0.714286        25.0   \n",
            "\n",
            "    var2(t+51)  var3(t+51)  \n",
            "10    0.142857    0.061224  \n",
            "11    0.571429    0.020408  \n",
            "12    0.714286   -0.061224  \n",
            "13    0.285714    0.714286  \n",
            "14    5.285714   -0.795918  \n",
            "\n",
            "[5 rows x 166 columns]\n",
            "Index(['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       ...\n",
            "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
            "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
            "      dtype='object', length=166)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "data.drop(['var2(t-10)', 'var3(t-10)', 'var2(t-9)', 'var3(t-9)', 'var2(t-8)',\n",
        "       'var3(t-8)', 'var2(t-7)', 'var3(t-7)', 'var2(t-6)', 'var3(t-6)',\n",
        "       'var2(t-5)', 'var3(t-5)', 'var2(t-4)', 'var3(t-4)', 'var2(t-2)',\n",
        "       'var3(t-2)', 'var2(t-1)', 'var3(t-1)','var2(t-3)', 'var3(t-3)'], axis = 1, inplace = True)#,18,19\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKb5l_gUaFvi"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOndQpQaFvi",
        "outputId": "56d94a79-1d05-4ff7-d70e-e2d8d00c83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(906, 1, 157) (906, 9) (227, 1, 157) (227, 9)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "test_size = len(data) - train_size\n",
        "train_1 = np.array(data[0:train_size])\n",
        "test_1 = np.array(data[train_size:len(data)])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train = scaler.fit_transform(train_1)\n",
        "test = scaler.transform(test_1)\n",
        "trainY = train[:,-9:]\n",
        "trainX = train[:,:-9]\n",
        "testY = test[:,-9:]\n",
        "testX = test[:,:-9]\n",
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-D_j8UaFvj"
      },
      "source": [
        "## Defining the Physical Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Jw7vitLaFvj"
      },
      "outputs": [],
      "source": [
        "mu = tf.Variable(4, name=\"mu\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def phys(y_pred, y_true):\n",
        "    return mean_absolute_error(y_true[:, 2] - mu * (y_true[:, 1] - (y_true[:, 0]**2 * y_true[:, 1]) - (1/mu) * y_true[:, 0]), y_pred[:, 2] - mu * (y_pred[:, 1] - (y_pred[:, 0]**2 * y_pred[:, 1]) - (1/mu) * y_pred[:, 0]))\n",
        "\n",
        "\n",
        "def phys2(y_pred, y_real):\n",
        "    pred = y_pred[2:]-2*y_pred[1:-1]-y_pred[:-2] - mu * ((y_pred[1:-1]-y_pred[:-2]) - (y_pred[:-2]**2 * (y_pred[1:-1]-y_pred[:-2])) - (1/mu) * y_pred[:-2])\n",
        "    real = y_real[2:]-2*y_real[1:-1]-y_real[:-2] - mu * ((y_real[1:-1]-y_real[:-2]) - (y_real[:-2]**2 * (y_real[1:-1]-y_real[:-2])) - (1/mu) * y_real[:-2])\n",
        "    return(mean_absolute_error(pred, real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874xZ-_u7X_s",
        "outputId": "883c11bb-1fe0-48af-e119-65529c186443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 2s 41ms/step - loss: 0.0253 - val_loss: 0.0272\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0373\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0186\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0131\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0126\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0121\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0113\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0106\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0099\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0096\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0097\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0105\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0116\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0124\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0118\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0099\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0076\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0058\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0048\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0043\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0041\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0045\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0060\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0072\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0083\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0086\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0074\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0056\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0040\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0030\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0028\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0034\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0044\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0048\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0044\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0038\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0031\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0020\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0021\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0022\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0024\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0014\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0013\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.9275e-04 - val_loss: 0.0013\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.8472e-04 - val_loss: 0.0013\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.7763e-04 - val_loss: 0.0013\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.7102e-04 - val_loss: 0.0013\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.6453e-04 - val_loss: 0.0013\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.5787e-04 - val_loss: 0.0013\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.5080e-04 - val_loss: 0.0012\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.4314e-04 - val_loss: 0.0012\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.3472e-04 - val_loss: 0.0012\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.2542e-04 - val_loss: 0.0012\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.1517e-04 - val_loss: 0.0012\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.0389e-04 - val_loss: 0.0012\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.9155e-04 - val_loss: 0.0012\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7815e-04 - val_loss: 0.0012\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.6372e-04 - val_loss: 0.0012\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.4831e-04 - val_loss: 0.0012\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.3200e-04 - val_loss: 0.0011\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.1489e-04 - val_loss: 0.0011\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.9711e-04 - val_loss: 0.0011\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.7878e-04 - val_loss: 0.0011\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.6003e-04 - val_loss: 0.0010\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.4101e-04 - val_loss: 0.0010\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.2183e-04 - val_loss: 9.7851e-04\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.0260e-04 - val_loss: 9.4929e-04\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.8342e-04 - val_loss: 9.1963e-04\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.6436e-04 - val_loss: 8.8973e-04\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.4549e-04 - val_loss: 8.5977e-04\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.2683e-04 - val_loss: 8.2991e-04\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.0841e-04 - val_loss: 8.0027e-04\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9023e-04 - val_loss: 7.7094e-04\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7228e-04 - val_loss: 7.4198e-04\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5455e-04 - val_loss: 7.1344e-04\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.3701e-04 - val_loss: 6.8534e-04\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1961e-04 - val_loss: 6.5769e-04\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.0232e-04 - val_loss: 6.3051e-04\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8510e-04 - val_loss: 6.0380e-04\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.6790e-04 - val_loss: 5.7755e-04\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.5069e-04 - val_loss: 5.5179e-04\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.3344e-04 - val_loss: 5.2652e-04\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1610e-04 - val_loss: 5.0179e-04\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.9868e-04 - val_loss: 4.7765e-04\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 3.8116e-04 - val_loss: 4.5417e-04\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 3.6357e-04 - val_loss: 4.3145e-04\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4596e-04 - val_loss: 4.0962e-04\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.2841e-04 - val_loss: 3.8883e-04\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.1102e-04 - val_loss: 3.6923e-04\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9396e-04 - val_loss: 3.5100e-04\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7740e-04 - val_loss: 3.3431e-04\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.6156e-04 - val_loss: 3.1931e-04\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4666e-04 - val_loss: 3.0612e-04\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3291e-04 - val_loss: 2.9483e-04\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.2048e-04 - val_loss: 2.8545e-04\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.0949e-04 - val_loss: 2.7796e-04\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.9999e-04 - val_loss: 2.7229e-04\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9197e-04 - val_loss: 2.6835e-04\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8537e-04 - val_loss: 2.6604e-04\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8008e-04 - val_loss: 2.6525e-04\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7601e-04 - val_loss: 2.6593e-04\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7305e-04 - val_loss: 2.6807e-04\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7115e-04 - val_loss: 2.7168e-04\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.7026e-04 - val_loss: 2.7685e-04\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7038e-04 - val_loss: 2.8370e-04\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7158e-04 - val_loss: 2.9239e-04\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7393e-04 - val_loss: 3.0311e-04\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7759e-04 - val_loss: 3.1603e-04\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.8275e-04 - val_loss: 3.3120e-04\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8966e-04 - val_loss: 3.4842e-04\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9858e-04 - val_loss: 3.6686e-04\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0966e-04 - val_loss: 3.8449e-04\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2279e-04 - val_loss: 3.9727e-04\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3706e-04 - val_loss: 3.9852e-04\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.5014e-04 - val_loss: 3.8003e-04\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5764e-04 - val_loss: 3.3690e-04\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5393e-04 - val_loss: 2.7530e-04\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3561e-04 - val_loss: 2.1338e-04\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0583e-04 - val_loss: 1.6809e-04\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7334e-04 - val_loss: 1.4281e-04\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4590e-04 - val_loss: 1.3149e-04\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2612e-04 - val_loss: 1.2775e-04\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1283e-04 - val_loss: 1.2767e-04\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0383e-04 - val_loss: 1.2904e-04\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.7367e-05 - val_loss: 1.3066e-04\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.2413e-05 - val_loss: 1.3196e-04\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.8422e-05 - val_loss: 1.3277e-04\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.5116e-05 - val_loss: 1.3312e-04\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.2340e-05 - val_loss: 1.3312e-04\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.9994e-05 - val_loss: 1.3291e-04\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.8006e-05 - val_loss: 1.3259e-04\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.6316e-05 - val_loss: 1.3224e-04\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.4872e-05 - val_loss: 1.3189e-04\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.3631e-05 - val_loss: 1.3156e-04\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.2556e-05 - val_loss: 1.3124e-04\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.1616e-05 - val_loss: 1.3093e-04\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.0787e-05 - val_loss: 1.3061e-04\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.0050e-05 - val_loss: 1.3029e-04\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.9390e-05 - val_loss: 1.2995e-04\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.8795e-05 - val_loss: 1.2958e-04\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.8253e-05 - val_loss: 1.2918e-04\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.7756e-05 - val_loss: 1.2875e-04\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.7294e-05 - val_loss: 1.2827e-04\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.6860e-05 - val_loss: 1.2775e-04\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.6448e-05 - val_loss: 1.2718e-04\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.6051e-05 - val_loss: 1.2656e-04\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.5665e-05 - val_loss: 1.2588e-04\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.5283e-05 - val_loss: 1.2513e-04\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.4902e-05 - val_loss: 1.2433e-04\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.4518e-05 - val_loss: 1.2346e-04\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.4126e-05 - val_loss: 1.2252e-04\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.3722e-05 - val_loss: 1.2151e-04\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.3306e-05 - val_loss: 1.2044e-04\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.2872e-05 - val_loss: 1.1930e-04\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.2421e-05 - val_loss: 1.1809e-04\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.1947e-05 - val_loss: 1.1682e-04\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.1453e-05 - val_loss: 1.1548e-04\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.0934e-05 - val_loss: 1.1410e-04\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.0395e-05 - val_loss: 1.1264e-04\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9827e-05 - val_loss: 1.1116e-04\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9243e-05 - val_loss: 1.0960e-04\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.8626e-05 - val_loss: 1.0807e-04\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8004e-05 - val_loss: 1.0642e-04\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7338e-05 - val_loss: 1.0487e-04\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6688e-05 - val_loss: 1.0313e-04\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5975e-05 - val_loss: 1.0166e-04\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.5316e-05 - val_loss: 9.9782e-05\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4551e-05 - val_loss: 9.8567e-05\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.3917e-05 - val_loss: 9.6379e-05\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.3083e-05 - val_loss: 9.5790e-05\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2529e-05 - val_loss: 9.2799e-05\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.1586e-05 - val_loss: 9.3760e-05\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1201e-05 - val_loss: 8.8620e-05\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0113e-05 - val_loss: 9.3604e-05\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0035e-05 - val_loss: 8.2844e-05\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.9010e-05 - val_loss: 9.9157e-05\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9598e-05 - val_loss: 7.4993e-05\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0905e-05 - val_loss: 1.2875e-04\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5693e-05 - val_loss: 8.4192e-05\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.5961e-05 - val_loss: 3.0487e-04\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2619e-04 - val_loss: 2.9893e-04\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3222e-04 - val_loss: 0.0013\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5053e-04 - val_loss: 5.5023e-04\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.8775e-04 - val_loss: 6.1652e-04\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.9861e-04 - val_loss: 2.3789e-04\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.6821e-04 - val_loss: 3.3325e-04\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7566e-04 - val_loss: 1.3654e-04\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.0435e-05 - val_loss: 1.6932e-04\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.1505e-05 - val_loss: 9.7053e-05\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.5840e-05 - val_loss: 1.3504e-04\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.4439e-05 - val_loss: 9.0451e-05\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0926e-05 - val_loss: 1.2231e-04\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8918e-05 - val_loss: 8.5218e-05\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.9011e-05 - val_loss: 1.1697e-04\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7195e-05 - val_loss: 8.0855e-05\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7769e-05 - val_loss: 1.1527e-04\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7224e-05 - val_loss: 7.6872e-05\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6756e-05 - val_loss: 1.1725e-04\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8859e-05 - val_loss: 7.3331e-05\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6020e-05 - val_loss: 1.2390e-04\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.2621e-05 - val_loss: 7.0979e-05\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6068e-05 - val_loss: 1.3781e-04\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.9896e-05 - val_loss: 7.1901e-05\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8098e-05 - val_loss: 1.6395e-04\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.3532e-05 - val_loss: 8.0387e-05\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4321e-05 - val_loss: 2.0916e-04\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0846e-04 - val_loss: 1.0158e-04\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7405e-05 - val_loss: 2.7305e-04\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4924e-04 - val_loss: 1.3105e-04\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.6472e-05 - val_loss: 3.1976e-04\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9536e-04 - val_loss: 1.4418e-04\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.9709e-05 - val_loss: 2.9323e-04\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0720e-04 - val_loss: 1.3744e-04\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.2877e-05 - val_loss: 2.4100e-04\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7781e-04 - val_loss: 1.2835e-04\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.7879e-05 - val_loss: 2.1880e-04\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.4980e-04 - val_loss: 1.1824e-04\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8898e-05 - val_loss: 2.0978e-04\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3425e-04 - val_loss: 1.1124e-04\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.4704e-05 - val_loss: 2.0568e-04\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2664e-04 - val_loss: 1.0732e-04\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.3073e-05 - val_loss: 2.0594e-04\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2413e-04 - val_loss: 1.0559e-04\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.3026e-05 - val_loss: 2.0963e-04\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2515e-04 - val_loss: 1.0551e-04\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4003e-05 - val_loss: 2.1527e-04\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2850e-04 - val_loss: 1.0655e-04\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5542e-05 - val_loss: 2.2100e-04\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3294e-04 - val_loss: 1.0799e-04\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7142e-05 - val_loss: 2.2490e-04\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3712e-04 - val_loss: 1.0905e-04\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8274e-05 - val_loss: 2.2559e-04\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3977e-04 - val_loss: 1.0917e-04\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8540e-05 - val_loss: 2.2282e-04\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4023e-04 - val_loss: 1.0819e-04\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7839e-05 - val_loss: 2.1744e-04\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3862e-04 - val_loss: 1.0634e-04\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6374e-05 - val_loss: 2.1066e-04\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3568e-04 - val_loss: 1.0405e-04\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4484e-05 - val_loss: 2.0333e-04\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3227e-04 - val_loss: 1.0175e-04\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2459e-05 - val_loss: 1.9563e-04\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2898e-04 - val_loss: 9.9770e-05\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0457e-05 - val_loss: 1.8711e-04\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2609e-04 - val_loss: 9.8359e-05\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.8512e-05 - val_loss: 1.7674e-04\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2354e-04 - val_loss: 9.7792e-05\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.6622e-05 - val_loss: 1.6293e-04\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2118e-04 - val_loss: 9.8748e-05\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4972e-05 - val_loss: 1.4387e-04\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1887e-04 - val_loss: 1.0331e-04\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4457e-05 - val_loss: 1.1857e-04\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1691e-04 - val_loss: 1.1754e-04\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7796e-05 - val_loss: 9.0351e-05\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1582e-04 - val_loss: 1.5581e-04\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.0624e-05 - val_loss: 7.2430e-05\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1370e-04 - val_loss: 2.3447e-04\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.9665e-05 - val_loss: 8.2937e-05\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0557e-04 - val_loss: 3.2785e-04\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3875e-04 - val_loss: 1.1694e-04\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0092e-04 - val_loss: 3.6999e-04\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9703e-04 - val_loss: 1.4228e-04\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0744e-04 - val_loss: 3.3725e-04\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.1590e-04 - val_loss: 1.4102e-04\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.7057e-05 - val_loss: 2.7625e-04\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8218e-04 - val_loss: 1.2437e-04\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.3266e-05 - val_loss: 2.2979e-04\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4327e-04 - val_loss: 1.0488e-04\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4987e-05 - val_loss: 1.9438e-04\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1578e-04 - val_loss: 9.1668e-05\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.4248e-05 - val_loss: 1.7289e-04\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.9929e-05 - val_loss: 8.3820e-05\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.8668e-05 - val_loss: 1.6180e-04\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.1923e-05 - val_loss: 7.9331e-05\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.6086e-05 - val_loss: 1.5782e-04\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.8986e-05 - val_loss: 7.7146e-05\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5368e-05 - val_loss: 1.5932e-04\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.9755e-05 - val_loss: 7.6945e-05\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.6089e-05 - val_loss: 1.6560e-04\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.3705e-05 - val_loss: 7.8825e-05\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.8188e-05 - val_loss: 1.7621e-04\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0064e-04 - val_loss: 8.2929e-05\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1690e-05 - val_loss: 1.9019e-04\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1022e-04 - val_loss: 8.8991e-05\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6417e-05 - val_loss: 2.0529e-04\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2137e-04 - val_loss: 9.5935e-05\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1696e-05 - val_loss: 2.1799e-04\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3189e-04 - val_loss: 1.0208e-04\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6357e-05 - val_loss: 2.2522e-04\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3909e-04 - val_loss: 1.0615e-04\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9298e-05 - val_loss: 2.2680e-04\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4154e-04 - val_loss: 1.0797e-04\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.0268e-05 - val_loss: 2.2518e-04\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4009e-04 - val_loss: 1.0806e-04\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9926e-05 - val_loss: 2.2278e-04\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3680e-04 - val_loss: 1.0704e-04\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9118e-05 - val_loss: 2.2056e-04\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3326e-04 - val_loss: 1.0532e-04\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8341e-05 - val_loss: 2.1862e-04\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.3023e-04 - val_loss: 1.0307e-04\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7718e-05 - val_loss: 2.1680e-04\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2780e-04 - val_loss: 1.0037e-04\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7182e-05 - val_loss: 2.1492e-04\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2584e-04 - val_loss: 9.7330e-05\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6622e-05 - val_loss: 2.1295e-04\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2414e-04 - val_loss: 9.4184e-05\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5971e-05 - val_loss: 2.1099e-04\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2255e-04 - val_loss: 9.1238e-05\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.5226e-05 - val_loss: 2.0914e-04\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2099e-04 - val_loss: 8.8713e-05\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4421e-05 - val_loss: 2.0746e-04\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1942e-04 - val_loss: 8.6667e-05\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3583e-05 - val_loss: 2.0587e-04\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1781e-04 - val_loss: 8.5022e-05\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.2721e-05 - val_loss: 2.0428e-04\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1612e-04 - val_loss: 8.3664e-05\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.1846e-05 - val_loss: 2.0262e-04\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1438e-04 - val_loss: 8.2506e-05\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0977e-05 - val_loss: 2.0092e-04\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1264e-04 - val_loss: 8.1516e-05\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 5.0145e-05 - val_loss: 1.9926e-04\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.1099e-04 - val_loss: 8.0695e-05\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9389e-05 - val_loss: 1.9773e-04\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0949e-04 - val_loss: 8.0061e-05\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8740e-05 - val_loss: 1.9638e-04\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0821e-04 - val_loss: 7.9631e-05\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8216e-05 - val_loss: 1.9525e-04\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0717e-04 - val_loss: 7.9411e-05\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7825e-05 - val_loss: 1.9436e-04\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0636e-04 - val_loss: 7.9396e-05\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.7563e-05 - val_loss: 1.9368e-04\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0576e-04 - val_loss: 7.9570e-05\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7421e-05 - val_loss: 1.9319e-04\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0535e-04 - val_loss: 7.9913e-05\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7382e-05 - val_loss: 1.9285e-04\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0509e-04 - val_loss: 8.0402e-05\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7432e-05 - val_loss: 1.9262e-04\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0493e-04 - val_loss: 8.1016e-05\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 4.7555e-05 - val_loss: 1.9250e-04\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0485e-04 - val_loss: 8.1737e-05\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7740e-05 - val_loss: 1.9245e-04\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0482e-04 - val_loss: 8.2556e-05\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7980e-05 - val_loss: 1.9249e-04\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0483e-04 - val_loss: 8.3467e-05\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.8269e-05 - val_loss: 1.9263e-04\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.0487e-04 - val_loss: 8.4473e-05\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 4.8609e-05 - val_loss: 1.9288e-04\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0494e-04 - val_loss: 8.5581e-05\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9002e-05 - val_loss: 1.9327e-04\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0505e-04 - val_loss: 8.6804e-05\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9455e-05 - val_loss: 1.9382e-04\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0521e-04 - val_loss: 8.8157e-05\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9974e-05 - val_loss: 1.9456e-04\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0543e-04 - val_loss: 8.9657e-05\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.0569e-05 - val_loss: 1.9551e-04\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0572e-04 - val_loss: 9.1322e-05\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.1248e-05 - val_loss: 1.9667e-04\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0608e-04 - val_loss: 9.3162e-05\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2020e-05 - val_loss: 1.9805e-04\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0653e-04 - val_loss: 9.5180e-05\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2892e-05 - val_loss: 1.9962e-04\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0708e-04 - val_loss: 9.7342e-05\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.3863e-05 - val_loss: 2.0127e-04\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0769e-04 - val_loss: 9.9556e-05\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4917e-05 - val_loss: 2.0285e-04\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0835e-04 - val_loss: 1.0161e-04\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6003e-05 - val_loss: 2.0397e-04\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0894e-04 - val_loss: 1.0309e-04\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.7010e-05 - val_loss: 2.0407e-04\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0927e-04 - val_loss: 1.0337e-04\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7728e-05 - val_loss: 2.0241e-04\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0903e-04 - val_loss: 1.0176e-04\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7872e-05 - val_loss: 1.9841e-04\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0789e-04 - val_loss: 9.8068e-05\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7202e-05 - val_loss: 1.9238e-04\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0571e-04 - val_loss: 9.3138e-05\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.5768e-05 - val_loss: 1.8576e-04\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0285e-04 - val_loss: 8.8563e-05\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.3970e-05 - val_loss: 1.8017e-04\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.9965e-05 - val_loss: 8.5402e-05\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2265e-05 - val_loss: 1.7624e-04\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.7534e-05 - val_loss: 8.3609e-05\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.0855e-05 - val_loss: 1.7356e-04\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.5578e-05 - val_loss: 8.2627e-05\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9709e-05 - val_loss: 1.7151e-04\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.3927e-05 - val_loss: 8.2018e-05\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.8743e-05 - val_loss: 1.6977e-04\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.2449e-05 - val_loss: 8.1597e-05\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.7919e-05 - val_loss: 1.6826e-04\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.1128e-05 - val_loss: 8.1341e-05\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.7241e-05 - val_loss: 1.6701e-04\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.9999e-05 - val_loss: 8.1278e-05\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6725e-05 - val_loss: 1.6608e-04\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.9101e-05 - val_loss: 8.1427e-05\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.6378e-05 - val_loss: 1.6547e-04\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.8443e-05 - val_loss: 8.1787e-05\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.6197e-05 - val_loss: 1.6515e-04\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.8013e-05 - val_loss: 8.2337e-05\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.6162e-05 - val_loss: 1.6506e-04\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7772e-05 - val_loss: 8.3036e-05\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.6245e-05 - val_loss: 1.6513e-04\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.7671e-05 - val_loss: 8.3840e-05\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6416e-05 - val_loss: 1.6528e-04\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.7660e-05 - val_loss: 8.4703e-05\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6644e-05 - val_loss: 1.6545e-04\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.7691e-05 - val_loss: 8.5590e-05\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6904e-05 - val_loss: 1.6559e-04\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7729e-05 - val_loss: 8.6477e-05\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7176e-05 - val_loss: 1.6569e-04\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.7750e-05 - val_loss: 8.7348e-05\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7449e-05 - val_loss: 1.6575e-04\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.7742e-05 - val_loss: 8.8198e-05\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7717e-05 - val_loss: 1.6576e-04\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7701e-05 - val_loss: 8.9029e-05\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.7975e-05 - val_loss: 1.6575e-04\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.7630e-05 - val_loss: 8.9840e-05\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8225e-05 - val_loss: 1.6571e-04\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.7531e-05 - val_loss: 9.0635e-05\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8464e-05 - val_loss: 1.6566e-04\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.7408e-05 - val_loss: 9.1409e-05\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.8691e-05 - val_loss: 1.6557e-04\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.7260e-05 - val_loss: 9.2163e-05\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8902e-05 - val_loss: 1.6544e-04\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7084e-05 - val_loss: 9.2888e-05\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9090e-05 - val_loss: 1.6526e-04\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.6875e-05 - val_loss: 9.3580e-05\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9251e-05 - val_loss: 1.6500e-04\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.6626e-05 - val_loss: 9.4232e-05\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9377e-05 - val_loss: 1.6465e-04\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.6332e-05 - val_loss: 9.4845e-05\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9464e-05 - val_loss: 1.6422e-04\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.5991e-05 - val_loss: 9.5421e-05\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9511e-05 - val_loss: 1.6370e-04\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.5603e-05 - val_loss: 9.5968e-05\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9520e-05 - val_loss: 1.6310e-04\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.5174e-05 - val_loss: 9.6506e-05\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9497e-05 - val_loss: 1.6247e-04\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.4720e-05 - val_loss: 9.7056e-05\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9454e-05 - val_loss: 1.6183e-04\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.4256e-05 - val_loss: 9.7644e-05\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9405e-05 - val_loss: 1.6123e-04\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.3803e-05 - val_loss: 9.8305e-05\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9370e-05 - val_loss: 1.6073e-04\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.3391e-05 - val_loss: 9.9075e-05\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9370e-05 - val_loss: 1.6037e-04\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.3047e-05 - val_loss: 9.9993e-05\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9427e-05 - val_loss: 1.6021e-04\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.2799e-05 - val_loss: 1.0110e-04\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9564e-05 - val_loss: 1.6031e-04\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.2680e-05 - val_loss: 1.0244e-04\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.9809e-05 - val_loss: 1.6070e-04\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.2722e-05 - val_loss: 1.0406e-04\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0188e-05 - val_loss: 1.6145e-04\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.2959e-05 - val_loss: 1.0598e-04\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0730e-05 - val_loss: 1.6255e-04\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.3422e-05 - val_loss: 1.0819e-04\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1457e-05 - val_loss: 1.6394e-04\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.4122e-05 - val_loss: 1.1050e-04\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.2360e-05 - val_loss: 1.6531e-04\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.5003e-05 - val_loss: 1.1241e-04\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.3347e-05 - val_loss: 1.6590e-04\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.5849e-05 - val_loss: 1.1284e-04\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.4152e-05 - val_loss: 1.6440e-04\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.6173e-05 - val_loss: 1.1047e-04\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.4326e-05 - val_loss: 1.5974e-04\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 8.5380e-05 - val_loss: 1.0534e-04\n"
          ]
        }
      ],
      "source": [
        "mu = tf.Variable(4, name=\"mu\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(\n",
        "        y_pred[:, 2] - mu * (y_pred[:, 1] - (y_pred[:, 0]**2 * y_pred[:, 1]) - (1/mu) * y_pred[:, 0]))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(9))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=500, batch_size=64, validation_data=(testX, testY), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 2ms/step\n",
            "(227, 9)\n",
            "(227, 157)\n",
            "Test RMSE: 95.382\n",
            "Test MAE: 73.428\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "yhat = model.predict(testX)\n",
        "print(yhat.shape)\n",
        "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
        "print(testX.shape)\n",
        "inv_yhat = np.concatenate((testX, yhat), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat1 = inv_yhat[:, -3:]\n",
        "inv_yhat = inv_yhat[:, -3]\n",
        "inv_y = np.concatenate((testX, testY), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y1 = inv_y[:, -3:]\n",
        "inv_y = inv_y[:, -3]\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
