{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xSItPJipBaZ5"
      },
      "source": [
        "## Gathering Dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "1a821417-b2e6-4bf3-ad0b-494bb85bea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.3.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.21.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_SAN JUAN_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        4\n",
            "1        5\n",
            "2        4\n",
            "3        3\n",
            "4        6\n",
            "        ..\n",
            "1191    56\n",
            "1192    46\n",
            "1193    52\n",
            "1194    34\n",
            "1195    25\n",
            "Name: Cases, Length: 1196, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/sanjuan.csv\")\n",
        "training_set = data.iloc[:, 3]\n",
        "print(training_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, _and_ $\\frac{d^2x}{dt^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "461\n",
            "1       0.142857\n",
            "2      -0.142857\n",
            "3      -0.142857\n",
            "4       0.428571\n",
            "5      -0.571429\n",
            "          ...   \n",
            "1191   -1.000000\n",
            "1192   -1.428571\n",
            "1193    0.857143\n",
            "1194   -2.571429\n",
            "1195   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "2      -0.040816\n",
            "3       0.000000\n",
            "4       0.081633\n",
            "5      -0.142857\n",
            "6       0.122449\n",
            "          ...   \n",
            "1191   -0.081633\n",
            "1192   -0.061224\n",
            "1193    0.326531\n",
            "1194   -0.489796\n",
            "1195    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 7 # Weekly Data\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:]\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:]\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.142857\n",
            "1      -0.142857\n",
            "2      -0.142857\n",
            "3       0.428571\n",
            "4      -0.571429\n",
            "          ...   \n",
            "1190   -1.000000\n",
            "1191   -1.428571\n",
            "1192    0.857143\n",
            "1193   -2.571429\n",
            "1194   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "0      -0.040816\n",
            "1       0.000000\n",
            "2       0.081633\n",
            "3      -0.142857\n",
            "4       0.122449\n",
            "          ...   \n",
            "1189   -0.081633\n",
            "1190   -0.061224\n",
            "1191    0.326531\n",
            "1192   -0.489796\n",
            "1193    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True)\n",
        "gradient_t = gradient_t.reset_index(drop=True)\n",
        "gradient_tt = gradient_tt.reset_index(drop=True)\n",
        "print(gradient_t)\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1195,)\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "print(gradient_t.shape)\n",
        "print(training_set.shape[:-1])\n",
        "df = pd.concat((training_set[:-1], gradient_t), axis=1)\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df[:-1], gradient_tt), axis=1)\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation (_Lotka Volterra Equation_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "45058d71-6952-4a40-afa5-84c2f42197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "a=0.1\n",
        "b=0.05\n",
        "c=1.1\n",
        "d=0.1\n",
        "L = df.iloc[:, 2] - a*a*df.iloc[:, 0] + 2*a*b*df.iloc[:, 0]*((a*df.iloc[:, 0]-df.iloc[:, 1])/(b*df.iloc[:, 0])) - b*b*df.iloc[:, 0]*((a*df.iloc[:, 0]-df.iloc[:, 1])/(b*df.iloc[:, 0]))*((a*df.iloc[:, 0]-df.iloc[:, 1])/(b*df.iloc[:, 0])) - b*d*(df.iloc[:,0]**2)*((a*df.iloc[:, 0]-df.iloc[:, 1])/(b*df.iloc[:, 0])) - c*b*df.iloc[:, 0]*((a*df.iloc[:, 0]-df.iloc[:, 1])/(b*df.iloc[:, 0]))\n",
        "L.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI8Yfkw6oA0l",
        "outputId": "01d7b72a-3934-4f62-ca10-27be3fc0310c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var1(t-9)', 'var2(t-9)',\n",
              "       'var3(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var1(t-7)',\n",
              "       ...\n",
              "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
              "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
              "      dtype='object', length=186)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "dat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "f37830fc-a93f-4216-e5d6-8e44bb1f83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
            "10         4.0        5.0        4.0        3.0        6.0        2.0   \n",
            "11         5.0        4.0        3.0        6.0        2.0        4.0   \n",
            "12         4.0        3.0        6.0        2.0        4.0        5.0   \n",
            "13         3.0        6.0        2.0        4.0        5.0       10.0   \n",
            "14         6.0        2.0        4.0        5.0       10.0        6.0   \n",
            "\n",
            "    var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)  ...  var3(t+48)  var1(t+49)  \\\n",
            "10        4.0        5.0       10.0        6.0  ...    0.224490        14.0   \n",
            "11        5.0       10.0        6.0        8.0  ...   -0.183673        18.0   \n",
            "12       10.0        6.0        8.0        2.0  ...    0.122449        13.0   \n",
            "13        6.0        8.0        2.0        6.0  ...    0.061224        14.0   \n",
            "14        8.0        2.0        6.0       17.0  ...    0.020408        18.0   \n",
            "\n",
            "    var2(t+49)  var3(t+49)  var1(t+50)  var2(t+50)  var3(t+50)  var1(t+51)  \\\n",
            "10    0.571429   -0.183673        18.0   -0.714286    0.122449        13.0   \n",
            "11   -0.714286    0.122449        13.0    0.142857    0.061224        14.0   \n",
            "12    0.142857    0.061224        14.0    0.571429    0.020408        18.0   \n",
            "13    0.571429    0.020408        18.0    0.714286   -0.061224        23.0   \n",
            "14    0.714286   -0.061224        23.0    0.285714    0.714286        25.0   \n",
            "\n",
            "    var2(t+51)  var3(t+51)  \n",
            "10    0.142857    0.061224  \n",
            "11    0.571429    0.020408  \n",
            "12    0.714286   -0.061224  \n",
            "13    0.285714    0.714286  \n",
            "14    5.285714   -0.795918  \n",
            "\n",
            "[5 rows x 166 columns]\n",
            "Index(['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       ...\n",
            "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
            "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
            "      dtype='object', length=166)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "data.drop(['var2(t-10)', 'var3(t-10)', 'var2(t-9)', 'var3(t-9)', 'var2(t-8)',\n",
        "       'var3(t-8)', 'var2(t-7)', 'var3(t-7)', 'var2(t-6)', 'var3(t-6)',\n",
        "       'var2(t-5)', 'var3(t-5)', 'var2(t-4)', 'var3(t-4)', 'var2(t-2)',\n",
        "       'var3(t-2)', 'var2(t-1)', 'var3(t-1)','var2(t-3)', 'var3(t-3)'], axis = 1, inplace = True)#,18,19\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKb5l_gUaFvi"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOndQpQaFvi",
        "outputId": "56d94a79-1d05-4ff7-d70e-e2d8d00c83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(906, 1, 157) (906, 9) (227, 1, 157) (227, 9)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "test_size = len(data) - train_size\n",
        "train_1 = np.array(data[0:train_size])\n",
        "test_1 = np.array(data[train_size:len(data)])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train = scaler.fit_transform(train_1)\n",
        "test = scaler.transform(test_1)\n",
        "trainY = train[:,-9:]\n",
        "trainX = train[:,:-9]\n",
        "testY = test[:,-9:]\n",
        "testX = test[:,:-9]\n",
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-D_j8UaFvj"
      },
      "source": [
        "## Defining the Physical Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Jw7vitLaFvj"
      },
      "outputs": [],
      "source": [
        "a = tf.Variable(0.1, name=\"alpha\", trainable=True, dtype=tf.float32)\n",
        "b = tf.Variable(0.05, name=\"beta\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(1.1, name=\"gamma\", trainable=True, dtype=tf.float32)\n",
        "d = tf.Variable(0.1, name=\"delta\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def phys(y_pred, y_true):\n",
        "    return mean_absolute_error((y_true[:, 2] - a*a*y_true[:, 0] + 2*a*b*y_true[:, 0]*((a*y_true[:, 0]-y_true[:, 1])/(b*y_true[:, 0])) - b*b*y_true[:, 0]*((a*y_true[:, 0]-y_true[:, 1])/(b*y_true[:, 0]))*((a*y_true[:, 0]-y_true[:, 1])/(b*y_true[:, 0])) - b*d*(y_true[:,0]**2)*((a*y_true[:, 0]-y_true[:, 1])/(b*y_true[:, 0])) - c*b*y_true[:, 0]*((a*y_true[:, 0]-y_true[:, 1])/(b*y_true[:, 0]))), (y_pred[:, 2] - a*a*y_pred[:, 0] + 2*a*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - b*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0]))*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - b*d*(y_pred[:,0]**2)*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - c*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0]))))\n",
        "\n",
        "def phys2(y_pred, y_real):\n",
        "    pred = y_pred[2:]-2*y_pred[1:-1]-y_pred[:-2] - a*a*y_pred[:-2] + 2*a*b*y_pred[:-2]*((a*y_pred[:-2]-(y_pred[1:-1]-y_pred[:-2]))/(b*y_pred[:-2])) - b*b*y_pred[:-2]*((a*y_pred[:-2]-(y_pred[1:-1]-y_pred[:-2]))/(b*y_pred[:-2]))*((a*y_pred[:-2]-(y_pred[1:-1]-y_pred[:-2]))/(b*y_pred[:-2])) - b*d*(y_pred[:-2]**2)*((a*y_pred[:-2]-(y_pred[1:-1]-y_pred[:-2]))/(b*y_pred[:-2])) - c*b*y_pred[:-2]*((a*y_pred[:-2]-(y_pred[1:-1]-y_pred[:-2]))/(b*y_pred[:-2]))\n",
        "    real = y_real[2:]-2*y_real[1:-1]-y_real[:-2] - a*a*y_real[:-2] + 2*a*b*y_real[:-2]*((a*y_real[:-2]-(y_real[1:-1]-y_real[:-2]))/(b*y_real[:-2])) - b*b*y_real[:-2]*((a*y_real[:-2]-(y_real[1:-1]-y_real[:-2]))/(b*y_real[:-2]))*((a*y_real[:-2]-(y_real[1:-1]-y_real[:-2]))/(b*y_real[:-2])) - b*d*(y_real[:-2]**2)*((a*y_real[:-2]-(y_real[1:-1]-y_real[:-2]))/(b*y_real[:-2])) - c*b*y_real[:-2]*((a*y_real[:-2]-(y_real[1:-1]-y_real[:-2]))/(b*y_real[:-2]))\n",
        "    return(mean_absolute_error(pred, real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874xZ-_u7X_s",
        "outputId": "883c11bb-1fe0-48af-e119-65529c186443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 5s 53ms/step - loss: 0.0353 - val_loss: 0.0187\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0342 - val_loss: 0.0867\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1189 - val_loss: 0.0714\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0522 - val_loss: 0.0219\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0168\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0189\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0187\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0177\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0170\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0164\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0160\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0157\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0152\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0148\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0144\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0139\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0135\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0130\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0125\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0121\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0115\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0113\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0111\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0105\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0101\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0068 - val_loss: 0.0097\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0094\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0089\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0087\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0084\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0342\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0108\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0112\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0102\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0101\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0099\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0093\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0089\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0085\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0080\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0076\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0073\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0069\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0066\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0059\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0056\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0053\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0050\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0048\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0045\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0041\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0031 - val_loss: 0.0039\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.0037\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0030\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0088\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6674 - val_loss: 1.2126\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0729 - val_loss: 2.7509\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9919 - val_loss: 3.0708\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1610 - val_loss: 3.0824\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.1591 - val_loss: 3.0375\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1270 - val_loss: 2.9872\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0926 - val_loss: 2.9401\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.0604 - val_loss: 2.8967\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.0306 - val_loss: 2.8565\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.0028 - val_loss: 2.8188\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9766 - val_loss: 2.7832\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9518 - val_loss: 2.7494\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.9280 - val_loss: 2.7172\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9052 - val_loss: 2.6862\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8833 - val_loss: 2.6565\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8621 - val_loss: 2.6278\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8415 - val_loss: 2.6001\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.8216 - val_loss: 2.5733\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.8022 - val_loss: 2.5473\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7832 - val_loss: 2.5220\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7648 - val_loss: 2.4974\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.7467 - val_loss: 2.4735\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.7291 - val_loss: 2.4502\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7118 - val_loss: 2.4275\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6949 - val_loss: 2.4053\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6783 - val_loss: 2.3836\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6620 - val_loss: 2.3623\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6460 - val_loss: 2.3416\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.6302 - val_loss: 2.3213\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.6147 - val_loss: 2.3013\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.5995 - val_loss: 2.2818\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.5844 - val_loss: 2.2627\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.5697 - val_loss: 2.2439\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5551 - val_loss: 2.2254\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.5407 - val_loss: 2.2073\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5265 - val_loss: 2.1895\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5125 - val_loss: 2.1720\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4987 - val_loss: 2.1548\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.4850 - val_loss: 2.1379\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4715 - val_loss: 2.1213\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4582 - val_loss: 2.1049\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4450 - val_loss: 2.0888\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4320 - val_loss: 2.0729\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.4191 - val_loss: 2.0573\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.4063 - val_loss: 2.0419\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3937 - val_loss: 2.0267\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3812 - val_loss: 2.0117\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3688 - val_loss: 1.9969\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3565 - val_loss: 1.9824\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3444 - val_loss: 1.9680\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3323 - val_loss: 1.9539\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3204 - val_loss: 1.9399\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3086 - val_loss: 1.9261\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2968 - val_loss: 1.9124\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2852 - val_loss: 1.8990\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2737 - val_loss: 1.8857\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.2622 - val_loss: 1.8726\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.2509 - val_loss: 1.8596\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2396 - val_loss: 1.8468\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2285 - val_loss: 1.8341\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2174 - val_loss: 1.8216\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2064 - val_loss: 1.8092\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1954 - val_loss: 1.7970\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1846 - val_loss: 1.7849\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1738 - val_loss: 1.7729\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1631 - val_loss: 1.7611\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1525 - val_loss: 1.7493\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1419 - val_loss: 1.7377\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1314 - val_loss: 1.7263\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1210 - val_loss: 1.7149\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.1106 - val_loss: 1.7037\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.1003 - val_loss: 1.6925\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0901 - val_loss: 1.6815\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0799 - val_loss: 1.6706\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0698 - val_loss: 1.6598\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0598 - val_loss: 1.6491\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0498 - val_loss: 1.6385\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0399 - val_loss: 1.6280\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0300 - val_loss: 1.6176\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.0202 - val_loss: 1.6073\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0104 - val_loss: 1.5971\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.0007 - val_loss: 1.5869\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9911 - val_loss: 1.5769\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9815 - val_loss: 1.5669\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9719 - val_loss: 1.5571\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9624 - val_loss: 1.5473\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9530 - val_loss: 1.5376\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9436 - val_loss: 1.5280\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9342 - val_loss: 1.5184\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9249 - val_loss: 1.5089\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.9157 - val_loss: 1.4996\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9065 - val_loss: 1.4902\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8973 - val_loss: 1.4810\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8882 - val_loss: 1.4718\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8791 - val_loss: 1.4627\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8701 - val_loss: 1.4537\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8611 - val_loss: 1.4448\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8522 - val_loss: 1.4359\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8433 - val_loss: 1.4270\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8345 - val_loss: 1.4183\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8257 - val_loss: 1.4096\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8169 - val_loss: 1.4009\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8082 - val_loss: 1.3924\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7995 - val_loss: 1.3839\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7908 - val_loss: 1.3754\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7822 - val_loss: 1.3670\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7736 - val_loss: 1.3587\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7651 - val_loss: 1.3504\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7566 - val_loss: 1.3422\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7482 - val_loss: 1.3340\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7397 - val_loss: 1.3259\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7314 - val_loss: 1.3178\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7230 - val_loss: 1.3098\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7147 - val_loss: 1.3019\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7064 - val_loss: 1.2940\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6982 - val_loss: 1.2861\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6900 - val_loss: 1.2783\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6819 - val_loss: 1.2706\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6737 - val_loss: 1.2629\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6656 - val_loss: 1.2552\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6576 - val_loss: 1.2476\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6495 - val_loss: 1.2400\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6416 - val_loss: 1.2325\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6336 - val_loss: 1.2251\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6257 - val_loss: 1.2176\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6178 - val_loss: 1.2103\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6099 - val_loss: 1.2029\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6021 - val_loss: 1.1956\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5943 - val_loss: 1.1884\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5865 - val_loss: 1.1812\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5788 - val_loss: 1.1740\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5711 - val_loss: 1.1669\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5634 - val_loss: 1.1598\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5558 - val_loss: 1.1528\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.5482 - val_loss: 1.1458\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5406 - val_loss: 1.1389\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5331 - val_loss: 1.1319\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5256 - val_loss: 1.1251\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5181 - val_loss: 1.1182\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5106 - val_loss: 1.1114\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5032 - val_loss: 1.1047\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4958 - val_loss: 1.0979\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4885 - val_loss: 1.0913\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4811 - val_loss: 1.0846\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4738 - val_loss: 1.0780\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4665 - val_loss: 1.0714\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4593 - val_loss: 1.0649\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4521 - val_loss: 1.0584\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.4449 - val_loss: 1.0519\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4377 - val_loss: 1.0455\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4306 - val_loss: 1.0391\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4235 - val_loss: 1.0327\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4164 - val_loss: 1.0264\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4094 - val_loss: 1.0201\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4023 - val_loss: 1.0139\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3954 - val_loss: 1.0077\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3884 - val_loss: 1.0015\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3814 - val_loss: 0.9953\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3745 - val_loss: 0.9892\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3676 - val_loss: 0.9831\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3608 - val_loss: 0.9770\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3540 - val_loss: 0.9710\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3472 - val_loss: 0.9650\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3404 - val_loss: 0.9591\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3336 - val_loss: 0.9532\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3269 - val_loss: 0.9473\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3202 - val_loss: 0.9414\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3135 - val_loss: 0.9356\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.3069 - val_loss: 0.9298\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3003 - val_loss: 0.9240\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2937 - val_loss: 0.9183\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2871 - val_loss: 0.9126\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2806 - val_loss: 0.9069\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2740 - val_loss: 0.9012\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2675 - val_loss: 0.8956\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2611 - val_loss: 0.8900\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2546 - val_loss: 0.8845\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2482 - val_loss: 0.8790\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2418 - val_loss: 0.8735\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2355 - val_loss: 0.8680\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2291 - val_loss: 0.8626\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2228 - val_loss: 0.8571\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2165 - val_loss: 0.8518\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2102 - val_loss: 0.8464\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2040 - val_loss: 0.8411\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1978 - val_loss: 0.8358\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1916 - val_loss: 0.8305\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1854 - val_loss: 0.8253\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1793 - val_loss: 0.8201\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1732 - val_loss: 0.8149\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1671 - val_loss: 0.8098\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1610 - val_loss: 0.8046\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1550 - val_loss: 0.7995\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1489 - val_loss: 0.7945\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1429 - val_loss: 0.7894\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1370 - val_loss: 0.7844\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1310 - val_loss: 0.7794\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1251 - val_loss: 0.7745\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1192 - val_loss: 0.7696\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1133 - val_loss: 0.7647\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1074 - val_loss: 0.7598\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1016 - val_loss: 0.7549\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0958 - val_loss: 0.7501\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0900 - val_loss: 0.7453\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0842 - val_loss: 0.7405\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0785 - val_loss: 0.7358\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0728 - val_loss: 0.7311\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0671 - val_loss: 0.7264\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0614 - val_loss: 0.7217\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0558 - val_loss: 0.7171\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0502 - val_loss: 0.7125\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0445 - val_loss: 0.7079\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0390 - val_loss: 0.7033\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0334 - val_loss: 0.6988\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0279 - val_loss: 0.6943\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0224 - val_loss: 0.6898\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0169 - val_loss: 0.6853\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0114 - val_loss: 0.6809\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0060 - val_loss: 0.6765\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0006 - val_loss: 0.6721\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9952 - val_loss: 0.6677\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9898 - val_loss: 0.6634\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9844 - val_loss: 0.6591\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9791 - val_loss: 0.6548\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9738 - val_loss: 0.6505\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9685 - val_loss: 0.6463\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9633 - val_loss: 0.6420\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9580 - val_loss: 0.6379\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9528 - val_loss: 0.6337\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9476 - val_loss: 0.6295\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9424 - val_loss: 0.6254\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9373 - val_loss: 0.6213\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.9321 - val_loss: 0.6172\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9270 - val_loss: 0.6132\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9219 - val_loss: 0.6092\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.9169 - val_loss: 0.6052\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9118 - val_loss: 0.6012\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9068 - val_loss: 0.5972\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.9018 - val_loss: 0.5933\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8968 - val_loss: 0.5894\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8919 - val_loss: 0.5855\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8869 - val_loss: 0.5816\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8820 - val_loss: 0.5778\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8771 - val_loss: 0.5740\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8723 - val_loss: 0.5702\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8674 - val_loss: 0.5664\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8626 - val_loss: 0.5626\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8578 - val_loss: 0.5589\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8530 - val_loss: 0.5552\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8482 - val_loss: 0.5515\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8435 - val_loss: 0.5479\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8388 - val_loss: 0.5442\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8341 - val_loss: 0.5406\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8294 - val_loss: 0.5370\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8247 - val_loss: 0.5334\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8201 - val_loss: 0.5299\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8154 - val_loss: 0.5263\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.8108 - val_loss: 0.5228\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8063 - val_loss: 0.5193\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.8017 - val_loss: 0.5158\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7972 - val_loss: 0.5124\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7927 - val_loss: 0.5090\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7882 - val_loss: 0.5056\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7837 - val_loss: 0.5022\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7792 - val_loss: 0.4988\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7748 - val_loss: 0.4954\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7704 - val_loss: 0.4921\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7660 - val_loss: 0.4888\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7616 - val_loss: 0.4855\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7572 - val_loss: 0.4823\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7529 - val_loss: 0.4790\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7486 - val_loss: 0.4758\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7443 - val_loss: 0.4726\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7400 - val_loss: 0.4694\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7358 - val_loss: 0.4662\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7315 - val_loss: 0.4631\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7273 - val_loss: 0.4599\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7231 - val_loss: 0.4568\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7189 - val_loss: 0.4537\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7148 - val_loss: 0.4507\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7106 - val_loss: 0.4476\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.7065 - val_loss: 0.4446\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.7024 - val_loss: 0.4416\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6983 - val_loss: 0.4386\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6942 - val_loss: 0.4356\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6902 - val_loss: 0.4326\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.6862 - val_loss: 0.4297\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6822 - val_loss: 0.4268\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6782 - val_loss: 0.4239\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6742 - val_loss: 0.4210\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6703 - val_loss: 0.4181\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6663 - val_loss: 0.4153\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.6624 - val_loss: 0.4124\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6585 - val_loss: 0.4096\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6546 - val_loss: 0.4068\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6508 - val_loss: 0.4040\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.6470 - val_loss: 0.4013\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6431 - val_loss: 0.3985\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6393 - val_loss: 0.3958\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.6355 - val_loss: 0.3931\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6318 - val_loss: 0.3904\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.6280 - val_loss: 0.3877\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.6243 - val_loss: 0.3851\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6206 - val_loss: 0.3824\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6169 - val_loss: 0.3798\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6132 - val_loss: 0.3772\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.6096 - val_loss: 0.3746\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6059 - val_loss: 0.3720\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6023 - val_loss: 0.3695\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.5987 - val_loss: 0.3669\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.5951 - val_loss: 0.3644\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.5915 - val_loss: 0.3619\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.5880 - val_loss: 0.3594\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.5844 - val_loss: 0.3569\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.5809 - val_loss: 0.3545\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.5774 - val_loss: 0.3520\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.5739 - val_loss: 0.3496\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.5705 - val_loss: 0.3472\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.5670 - val_loss: 0.3448\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.5636 - val_loss: 0.3424\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.5602 - val_loss: 0.3401\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.5568 - val_loss: 0.3377\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.5534 - val_loss: 0.3354\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.5500 - val_loss: 0.3330\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.5467 - val_loss: 0.3307\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.5434 - val_loss: 0.3284\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.5400 - val_loss: 0.3262\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5367 - val_loss: 0.3239\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5335 - val_loss: 0.3217\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5302 - val_loss: 0.3194\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.5270 - val_loss: 0.3172\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5237 - val_loss: 0.3150\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5205 - val_loss: 0.3128\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5173 - val_loss: 0.3107\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5141 - val_loss: 0.3085\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5110 - val_loss: 0.3064\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5078 - val_loss: 0.3042\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.5047 - val_loss: 0.3021\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.5015 - val_loss: 0.3000\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4984 - val_loss: 0.2979\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4954 - val_loss: 0.2958\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4923 - val_loss: 0.2938\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4892 - val_loss: 0.2917\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4862 - val_loss: 0.2897\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4832 - val_loss: 0.2877\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4801 - val_loss: 0.2857\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4772 - val_loss: 0.2837\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4742 - val_loss: 0.2817\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4712 - val_loss: 0.2797\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4683 - val_loss: 0.2778\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4653 - val_loss: 0.2758\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.4624 - val_loss: 0.2739\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4595 - val_loss: 0.2720\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4566 - val_loss: 0.2701\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4537 - val_loss: 0.2682\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4509 - val_loss: 0.2663\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4480 - val_loss: 0.2645\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4452 - val_loss: 0.2626\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4424 - val_loss: 0.2608\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4396 - val_loss: 0.2590\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4368 - val_loss: 0.2571\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4340 - val_loss: 0.2553\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4313 - val_loss: 0.2536\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4285 - val_loss: 0.2518\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4258 - val_loss: 0.2500\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4231 - val_loss: 0.2483\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4204 - val_loss: 0.2465\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4177 - val_loss: 0.2448\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4151 - val_loss: 0.2431\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4124 - val_loss: 0.2414\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4098 - val_loss: 0.2397\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4071 - val_loss: 0.2380\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4045 - val_loss: 0.2363\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4019 - val_loss: 0.2347\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3993 - val_loss: 0.2330\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3968 - val_loss: 0.2314\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3942 - val_loss: 0.2298\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3917 - val_loss: 0.2281\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3891 - val_loss: 0.2265\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3866 - val_loss: 0.2249\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3841 - val_loss: 0.2234\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3816 - val_loss: 0.2218\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3791 - val_loss: 0.2202\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3767 - val_loss: 0.2187\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3742 - val_loss: 0.2172\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3718 - val_loss: 0.2156\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3694 - val_loss: 0.2141\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3670 - val_loss: 0.2126\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3646 - val_loss: 0.2111\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3622 - val_loss: 0.2096\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3598 - val_loss: 0.2081\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3574 - val_loss: 0.2067\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3551 - val_loss: 0.2052\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3528 - val_loss: 0.2038\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3504 - val_loss: 0.2024\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3481 - val_loss: 0.2009\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3458 - val_loss: 0.1995\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3436 - val_loss: 0.1981\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3413 - val_loss: 0.1967\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3390 - val_loss: 0.1953\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3368 - val_loss: 0.1940\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.3346 - val_loss: 0.1926\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3323 - val_loss: 0.1912\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3301 - val_loss: 0.1899\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3279 - val_loss: 0.1886\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3258 - val_loss: 0.1872\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3236 - val_loss: 0.1859\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3214 - val_loss: 0.1846\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3193 - val_loss: 0.1833\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3172 - val_loss: 0.1820\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3150 - val_loss: 0.1807\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3129 - val_loss: 0.1795\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3108 - val_loss: 0.1782\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3087 - val_loss: 0.1770\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3067 - val_loss: 0.1757\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3046 - val_loss: 0.1745\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3026 - val_loss: 0.1733\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3005 - val_loss: 0.1720\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2985 - val_loss: 0.1708\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2965 - val_loss: 0.1696\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2945 - val_loss: 0.1684\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2925 - val_loss: 0.1673\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2905 - val_loss: 0.1661\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2885 - val_loss: 0.1649\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2866 - val_loss: 0.1638\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2846 - val_loss: 0.1626\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2827 - val_loss: 0.1615\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2808 - val_loss: 0.1604\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2789 - val_loss: 0.1592\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2770 - val_loss: 0.1581\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2751 - val_loss: 0.1570\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2732 - val_loss: 0.1559\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2713 - val_loss: 0.1548\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2695 - val_loss: 0.1537\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2676 - val_loss: 0.1527\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2658 - val_loss: 0.1516\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.1505\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2622 - val_loss: 0.1495\n"
          ]
        }
      ],
      "source": [
        "a = tf.Variable(0.1, name=\"alpha\", trainable=True, dtype=tf.float32)\n",
        "b = tf.Variable(0.05, name=\"beta\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(1.1, name=\"gamma\", trainable=True, dtype=tf.float32)\n",
        "d = tf.Variable(0.1, name=\"delta\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(y_pred[:, 2] - a*a*y_pred[:, 0] + 2*a*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - b*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0]))*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - b*d*(y_pred[:,0]**2)*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])) - c*b*y_pred[:, 0]*((a*y_pred[:, 0]-y_pred[:, 1])/(b*y_pred[:, 0])))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(9))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=500, batch_size=64, validation_data=(testX, testY), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n",
            "(227, 9)\n",
            "(227, 157)\n",
            "Test RMSE: 113.897\n",
            "Test MAE: 99.252\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "yhat = model.predict(testX)\n",
        "print(yhat.shape)\n",
        "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
        "print(testX.shape)\n",
        "inv_yhat = np.concatenate((testX, yhat), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat1 = inv_yhat[:, -3:]\n",
        "inv_yhat = inv_yhat[:, -3]\n",
        "inv_y = np.concatenate((testX, testY), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y1 = inv_y[:, -3:]\n",
        "inv_y = inv_y[:, -3]\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
