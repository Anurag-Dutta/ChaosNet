{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xSItPJipBaZ5"
      },
      "source": [
        "## Gathering Dependencies"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "1a821417-b2e6-4bf3-ad0b-494bb85bea08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.3.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.21.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7.3->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_SAN JUAN_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        4\n",
            "1        5\n",
            "2        4\n",
            "3        3\n",
            "4        6\n",
            "        ..\n",
            "1191    56\n",
            "1192    46\n",
            "1193    52\n",
            "1194    34\n",
            "1195    25\n",
            "Name: Cases, Length: 1196, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/sanjuan.csv\")\n",
        "training_set = data.iloc[:, 3]\n",
        "print(training_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, _and_ $\\frac{d^2x}{dt^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "461\n",
            "1       0.142857\n",
            "2      -0.142857\n",
            "3      -0.142857\n",
            "4       0.428571\n",
            "5      -0.571429\n",
            "          ...   \n",
            "1191   -1.000000\n",
            "1192   -1.428571\n",
            "1193    0.857143\n",
            "1194   -2.571429\n",
            "1195   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "2      -0.040816\n",
            "3       0.000000\n",
            "4       0.081633\n",
            "5      -0.142857\n",
            "6       0.122449\n",
            "          ...   \n",
            "1191   -0.081633\n",
            "1192   -0.061224\n",
            "1193    0.326531\n",
            "1194   -0.489796\n",
            "1195    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 7 # Weekly Data\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:]\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:]\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       0.142857\n",
            "1      -0.142857\n",
            "2      -0.142857\n",
            "3       0.428571\n",
            "4      -0.571429\n",
            "          ...   \n",
            "1190   -1.000000\n",
            "1191   -1.428571\n",
            "1192    0.857143\n",
            "1193   -2.571429\n",
            "1194   -1.285714\n",
            "Name: Cases, Length: 1195, dtype: float64\n",
            "0      -0.040816\n",
            "1       0.000000\n",
            "2       0.081633\n",
            "3      -0.142857\n",
            "4       0.122449\n",
            "          ...   \n",
            "1189   -0.081633\n",
            "1190   -0.061224\n",
            "1191    0.326531\n",
            "1192   -0.489796\n",
            "1193    0.183673\n",
            "Name: Cases, Length: 1194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True)\n",
        "gradient_t = gradient_t.reset_index(drop=True)\n",
        "gradient_tt = gradient_tt.reset_index(drop=True)\n",
        "print(gradient_t)\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1195,)\n",
            "()\n"
          ]
        }
      ],
      "source": [
        "print(gradient_t.shape)\n",
        "print(training_set.shape[:-1])\n",
        "df = pd.concat((training_set[:-1], gradient_t), axis=1)\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df[:-1], gradient_tt), axis=1)\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation (_Van der Pol Oscillator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "45058d71-6952-4a40-afa5-84c2f42197b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "L = df.iloc[:, 2] - df.iloc[:, 1]\n",
        "L.plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI8Yfkw6oA0l",
        "outputId": "01d7b72a-3934-4f62-ca10-27be3fc0310c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['var1(t-10)', 'var2(t-10)', 'var3(t-10)', 'var1(t-9)', 'var2(t-9)',\n",
              "       'var3(t-9)', 'var1(t-8)', 'var2(t-8)', 'var3(t-8)', 'var1(t-7)',\n",
              "       ...\n",
              "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
              "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
              "      dtype='object', length=186)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dat = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "dat.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "f37830fc-a93f-4216-e5d6-8e44bb1f83ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
            "10         4.0        5.0        4.0        3.0        6.0        2.0   \n",
            "11         5.0        4.0        3.0        6.0        2.0        4.0   \n",
            "12         4.0        3.0        6.0        2.0        4.0        5.0   \n",
            "13         3.0        6.0        2.0        4.0        5.0       10.0   \n",
            "14         6.0        2.0        4.0        5.0       10.0        6.0   \n",
            "\n",
            "    var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)  ...  var3(t+48)  var1(t+49)  \\\n",
            "10        4.0        5.0       10.0        6.0  ...    0.224490        14.0   \n",
            "11        5.0       10.0        6.0        8.0  ...   -0.183673        18.0   \n",
            "12       10.0        6.0        8.0        2.0  ...    0.122449        13.0   \n",
            "13        6.0        8.0        2.0        6.0  ...    0.061224        14.0   \n",
            "14        8.0        2.0        6.0       17.0  ...    0.020408        18.0   \n",
            "\n",
            "    var2(t+49)  var3(t+49)  var1(t+50)  var2(t+50)  var3(t+50)  var1(t+51)  \\\n",
            "10    0.571429   -0.183673        18.0   -0.714286    0.122449        13.0   \n",
            "11   -0.714286    0.122449        13.0    0.142857    0.061224        14.0   \n",
            "12    0.142857    0.061224        14.0    0.571429    0.020408        18.0   \n",
            "13    0.571429    0.020408        18.0    0.714286   -0.061224        23.0   \n",
            "14    0.714286   -0.061224        23.0    0.285714    0.714286        25.0   \n",
            "\n",
            "    var2(t+51)  var3(t+51)  \n",
            "10    0.142857    0.061224  \n",
            "11    0.571429    0.020408  \n",
            "12    0.714286   -0.061224  \n",
            "13    0.285714    0.714286  \n",
            "14    5.285714   -0.795918  \n",
            "\n",
            "[5 rows x 166 columns]\n",
            "Index(['var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       ...\n",
            "       'var3(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var1(t+50)',\n",
            "       'var2(t+50)', 'var3(t+50)', 'var1(t+51)', 'var2(t+51)', 'var3(t+51)'],\n",
            "      dtype='object', length=166)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 10, n_out = 52)\n",
        "data.drop(['var2(t-10)', 'var3(t-10)', 'var2(t-9)', 'var3(t-9)', 'var2(t-8)',\n",
        "       'var3(t-8)', 'var2(t-7)', 'var3(t-7)', 'var2(t-6)', 'var3(t-6)',\n",
        "       'var2(t-5)', 'var3(t-5)', 'var2(t-4)', 'var3(t-4)', 'var2(t-2)',\n",
        "       'var3(t-2)', 'var2(t-1)', 'var3(t-1)','var2(t-3)', 'var3(t-3)'], axis = 1, inplace = True)#,18,19\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKb5l_gUaFvi"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVOndQpQaFvi",
        "outputId": "56d94a79-1d05-4ff7-d70e-e2d8d00c83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(906, 1, 157) (906, 9) (227, 1, 157) (227, 9)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(data) * 0.8)\n",
        "test_size = len(data) - train_size\n",
        "train_1 = np.array(data[0:train_size])\n",
        "test_1 = np.array(data[train_size:len(data)])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train = scaler.fit_transform(train_1)\n",
        "test = scaler.transform(test_1)\n",
        "trainY = train[:,-9:]\n",
        "trainX = train[:,:-9]\n",
        "testY = test[:,-9:]\n",
        "testX = test[:,:-9]\n",
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = testX.reshape((testX.shape[0], 1, testX.shape[1]))\n",
        "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-D_j8UaFvj"
      },
      "source": [
        "## Defining the Physical Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Jw7vitLaFvj"
      },
      "outputs": [],
      "source": [
        "a = tf.Variable(0.1, name=\"alpha\", trainable=True, dtype=tf.float32)\n",
        "b = tf.Variable(0.05, name=\"beta\", trainable=True, dtype=tf.float32)\n",
        "c = tf.Variable(1.1, name=\"gamma\", trainable=True, dtype=tf.float32)\n",
        "d = tf.Variable(0.1, name=\"delta\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def phys(y_pred, y_true):\n",
        "    return mean_absolute_error((y_true[:, 2] - y_true[:, 1]), (y_pred[:, 2] - y_pred[:, 1]))\n",
        "\n",
        "def phys2(y_pred, y_real):\n",
        "    pred = y_pred[2:]-2*y_pred[1:-1]-y_pred[:-2] - (y_pred[1:-1]-y_pred[:-2])\n",
        "    real = y_real[2:]-2*y_real[1:-1]-y_real[:-2] - (y_real[1:-1]-y_pred[:-2])\n",
        "    return(mean_absolute_error(pred, real))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--1LVbHOBSIy"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "874xZ-_u7X_s",
        "outputId": "883c11bb-1fe0-48af-e119-65529c186443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 3s 42ms/step - loss: 0.0202 - val_loss: 0.0390\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0440\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0185\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0132\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0134\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0132\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0125\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0118\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0111\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0106\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0105\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0061 - val_loss: 0.0109\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0113\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0114\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0107\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0093\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0077\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.0043 - val_loss: 0.0065\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0057\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0054\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0054\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0056\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0062\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0069\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0075\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0076\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0071\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0060\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0049\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0035\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0033\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0033\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0034\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0037\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0041\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0046\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0049\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0050\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0048\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0026 - val_loss: 0.0043\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0037\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0028\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0026\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0027\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0028\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0029\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0030\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0031\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0030\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0030\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0028\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0026\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0024\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0015 - val_loss: 0.0023\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0019\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0016\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0015\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.9191e-04 - val_loss: 0.0015\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.7034e-04 - val_loss: 0.0015\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.4969e-04 - val_loss: 0.0014\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.2990e-04 - val_loss: 0.0014\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.1090e-04 - val_loss: 0.0014\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.9257e-04 - val_loss: 0.0013\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.7482e-04 - val_loss: 0.0013\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.5752e-04 - val_loss: 0.0013\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.4058e-04 - val_loss: 0.0012\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.2388e-04 - val_loss: 0.0012\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.0733e-04 - val_loss: 0.0012\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.9083e-04 - val_loss: 0.0011\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.7429e-04 - val_loss: 0.0011\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.5760e-04 - val_loss: 0.0011\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.4068e-04 - val_loss: 0.0010\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.2342e-04 - val_loss: 0.0010\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.0572e-04 - val_loss: 9.8056e-04\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.8747e-04 - val_loss: 9.4668e-04\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.6853e-04 - val_loss: 9.1162e-04\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.4876e-04 - val_loss: 8.7521e-04\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.2803e-04 - val_loss: 8.3728e-04\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.0616e-04 - val_loss: 7.9772e-04\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8300e-04 - val_loss: 7.5642e-04\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.5838e-04 - val_loss: 7.1337e-04\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.3218e-04 - val_loss: 6.6864e-04\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0430e-04 - val_loss: 6.2245e-04\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.7476e-04 - val_loss: 5.7522e-04\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.4368e-04 - val_loss: 5.2756e-04\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.1140e-04 - val_loss: 4.8035e-04\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7850e-04 - val_loss: 4.3467e-04\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4582e-04 - val_loss: 3.9167e-04\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.1436e-04 - val_loss: 3.5250e-04\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.8521e-04 - val_loss: 3.1799e-04\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5923e-04 - val_loss: 2.8853e-04\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3689e-04 - val_loss: 2.6397e-04\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.1817e-04 - val_loss: 2.4368e-04\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0261e-04 - val_loss: 2.2684e-04\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8961e-04 - val_loss: 2.1269e-04\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7856e-04 - val_loss: 2.0063e-04\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6901e-04 - val_loss: 1.9027e-04\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6064e-04 - val_loss: 1.8129e-04\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5322e-04 - val_loss: 1.7348e-04\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4659e-04 - val_loss: 1.6667e-04\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4065e-04 - val_loss: 1.6070e-04\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3529e-04 - val_loss: 1.5549e-04\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3044e-04 - val_loss: 1.5094e-04\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2604e-04 - val_loss: 1.4699e-04\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2204e-04 - val_loss: 1.4358e-04\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1840e-04 - val_loss: 1.4069e-04\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1509e-04 - val_loss: 1.3828e-04\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1207e-04 - val_loss: 1.3635e-04\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0934e-04 - val_loss: 1.3490e-04\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0687e-04 - val_loss: 1.3394e-04\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0465e-04 - val_loss: 1.3348e-04\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0268e-04 - val_loss: 1.3357e-04\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0095e-04 - val_loss: 1.3424e-04\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.9473e-05 - val_loss: 1.3552e-04\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.8240e-05 - val_loss: 1.3745e-04\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.7256e-05 - val_loss: 1.4007e-04\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.6524e-05 - val_loss: 1.4339e-04\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.6046e-05 - val_loss: 1.4741e-04\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.5823e-05 - val_loss: 1.5209e-04\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.5852e-05 - val_loss: 1.5738e-04\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.6132e-05 - val_loss: 1.6319e-04\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.6657e-05 - val_loss: 1.6941e-04\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.7423e-05 - val_loss: 1.7593e-04\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 9.8425e-05 - val_loss: 1.8261e-04\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.9659e-05 - val_loss: 1.8931e-04\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0112e-04 - val_loss: 1.9592e-04\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0279e-04 - val_loss: 2.0228e-04\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0464e-04 - val_loss: 2.0823e-04\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0665e-04 - val_loss: 2.1361e-04\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0876e-04 - val_loss: 2.1821e-04\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1088e-04 - val_loss: 2.2185e-04\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1291e-04 - val_loss: 2.2432e-04\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1472e-04 - val_loss: 2.2548e-04\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1616e-04 - val_loss: 2.2526e-04\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1708e-04 - val_loss: 2.2371e-04\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1737e-04 - val_loss: 2.2103e-04\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1695e-04 - val_loss: 2.1754e-04\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1584e-04 - val_loss: 2.1367e-04\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1411e-04 - val_loss: 2.0989e-04\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1192e-04 - val_loss: 2.0659e-04\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0947e-04 - val_loss: 2.0413e-04\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0696e-04 - val_loss: 2.0271e-04\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0458e-04 - val_loss: 2.0244e-04\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0247e-04 - val_loss: 2.0332e-04\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0074e-04 - val_loss: 2.0531e-04\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 9.9445e-05 - val_loss: 2.0830e-04\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.8619e-05 - val_loss: 2.1221e-04\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.8284e-05 - val_loss: 2.1694e-04\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.8448e-05 - val_loss: 2.2242e-04\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.9124e-05 - val_loss: 2.2860e-04\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0033e-04 - val_loss: 2.3547e-04\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0209e-04 - val_loss: 2.4303e-04\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0443e-04 - val_loss: 2.5129e-04\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0742e-04 - val_loss: 2.6025e-04\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.1111e-04 - val_loss: 2.6989e-04\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1557e-04 - val_loss: 2.8012e-04\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2086e-04 - val_loss: 2.9073e-04\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2706e-04 - val_loss: 3.0132e-04\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3416e-04 - val_loss: 3.1119e-04\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4211e-04 - val_loss: 3.1920e-04\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.5064e-04 - val_loss: 3.2375e-04\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5921e-04 - val_loss: 3.2276e-04\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.6684e-04 - val_loss: 3.1411e-04\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.7206e-04 - val_loss: 2.9646e-04\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.7308e-04 - val_loss: 2.7043e-04\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.6840e-04 - val_loss: 2.3918e-04\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.5765e-04 - val_loss: 2.0768e-04\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4216e-04 - val_loss: 1.8056e-04\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.2458e-04 - val_loss: 1.6024e-04\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0766e-04 - val_loss: 1.4676e-04\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.3170e-05 - val_loss: 1.3879e-04\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.1695e-05 - val_loss: 1.3471e-04\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.3007e-05 - val_loss: 1.3309e-04\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.6561e-05 - val_loss: 1.3288e-04\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.1798e-05 - val_loss: 1.3335e-04\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.8265e-05 - val_loss: 1.3401e-04\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.5624e-05 - val_loss: 1.3460e-04\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.3641e-05 - val_loss: 1.3500e-04\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.2147e-05 - val_loss: 1.3516e-04\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.1024e-05 - val_loss: 1.3508e-04\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.0178e-05 - val_loss: 1.3478e-04\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9536e-05 - val_loss: 1.3425e-04\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9043e-05 - val_loss: 1.3351e-04\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8654e-05 - val_loss: 1.3258e-04\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8334e-05 - val_loss: 1.3146e-04\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.8058e-05 - val_loss: 1.3017e-04\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.7803e-05 - val_loss: 1.2871e-04\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.7552e-05 - val_loss: 1.2710e-04\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.7294e-05 - val_loss: 1.2534e-04\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.7017e-05 - val_loss: 1.2345e-04\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6715e-05 - val_loss: 1.2142e-04\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.6381e-05 - val_loss: 1.1929e-04\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6011e-05 - val_loss: 1.1700e-04\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.5600e-05 - val_loss: 1.1467e-04\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.5153e-05 - val_loss: 1.1214e-04\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4658e-05 - val_loss: 1.0965e-04\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.4131e-05 - val_loss: 1.0690e-04\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.3549e-05 - val_loss: 1.0433e-04\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2948e-05 - val_loss: 1.0130e-04\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.2278e-05 - val_loss: 9.8839e-05\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.1619e-05 - val_loss: 9.5377e-05\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0854e-05 - val_loss: 9.3368e-05\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.0168e-05 - val_loss: 8.9036e-05\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.9290e-05 - val_loss: 8.8320e-05\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.8639e-05 - val_loss: 8.1925e-05\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7599e-05 - val_loss: 8.4620e-05\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.7113e-05 - val_loss: 7.3079e-05\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5839e-05 - val_loss: 8.4840e-05\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5875e-05 - val_loss: 6.0726e-05\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4502e-05 - val_loss: 9.8190e-05\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.6610e-05 - val_loss: 4.7558e-05\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 3.7575e-05 - val_loss: 1.7046e-04\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.2129e-05 - val_loss: 9.8430e-05\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 7.3600e-05 - val_loss: 5.8256e-04\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7846e-04 - val_loss: 6.4281e-04\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8068e-04 - val_loss: 0.0018\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 7.5477e-04 - val_loss: 5.0958e-04\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.2792e-04 - val_loss: 4.4633e-04\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6260e-04 - val_loss: 1.5965e-04\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2540e-04 - val_loss: 2.5139e-04\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1837e-04 - val_loss: 1.3464e-04\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.4781e-05 - val_loss: 1.9928e-04\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.7615e-05 - val_loss: 1.0183e-04\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.6671e-05 - val_loss: 1.6122e-04\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.4628e-05 - val_loss: 8.6328e-05\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3424e-05 - val_loss: 1.6255e-04\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.4493e-05 - val_loss: 7.1617e-05\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3971e-05 - val_loss: 1.7795e-04\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.0579e-05 - val_loss: 6.1878e-05\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.9118e-05 - val_loss: 2.1349e-04\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.4815e-05 - val_loss: 6.1072e-05\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 5.9460e-05 - val_loss: 2.7021e-04\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 9.9527e-05 - val_loss: 7.1768e-05\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.2236e-05 - val_loss: 3.2784e-04\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3012e-04 - val_loss: 8.4196e-05\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 7.8567e-05 - val_loss: 3.4068e-04\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4899e-04 - val_loss: 8.6123e-05\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.2289e-05 - val_loss: 3.0085e-04\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.4309e-04 - val_loss: 8.2159e-05\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.9076e-05 - val_loss: 2.5323e-04\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2404e-04 - val_loss: 7.6770e-05\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.7357e-05 - val_loss: 2.1989e-04\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.0744e-04 - val_loss: 7.1438e-05\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.9687e-05 - val_loss: 1.9924e-04\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.7625e-05 - val_loss: 6.7501e-05\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5199e-05 - val_loss: 1.8781e-04\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.3892e-05 - val_loss: 6.5459e-05\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.2755e-05 - val_loss: 1.8318e-04\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.5341e-05 - val_loss: 6.5904e-05\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.1867e-05 - val_loss: 1.8351e-04\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0193e-04 - val_loss: 6.9833e-05\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 3.2827e-05 - val_loss: 1.8646e-04\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.1411e-04 - val_loss: 7.8300e-05\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 3.6606e-05 - val_loss: 1.8731e-04\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3117e-04 - val_loss: 9.1433e-05\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.3830e-05 - val_loss: 1.7806e-04\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.4750e-04 - val_loss: 1.0754e-04\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.1828e-05 - val_loss: 1.5448e-04\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.5130e-04 - val_loss: 1.2237e-04\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.4034e-05 - val_loss: 1.2628e-04\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.3652e-04 - val_loss: 1.2845e-04\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.8654e-05 - val_loss: 1.0483e-04\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1340e-04 - val_loss: 1.2455e-04\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1468e-05 - val_loss: 8.9639e-05\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.3663e-05 - val_loss: 1.1806e-04\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.6511e-05 - val_loss: 7.7378e-05\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.0212e-05 - val_loss: 1.1398e-04\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.4141e-05 - val_loss: 6.6777e-05\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.1759e-05 - val_loss: 1.1383e-04\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.3792e-05 - val_loss: 5.7359e-05\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 6.6772e-05 - val_loss: 1.1877e-04\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.5282e-05 - val_loss: 4.9256e-05\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.4426e-05 - val_loss: 1.3114e-04\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.9166e-05 - val_loss: 4.3831e-05\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.4655e-05 - val_loss: 1.5559e-04\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.7031e-05 - val_loss: 4.4670e-05\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.8043e-05 - val_loss: 2.0027e-04\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.2019e-05 - val_loss: 5.8318e-05\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.5391e-05 - val_loss: 2.7597e-04\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.9189e-05 - val_loss: 9.1536e-05\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 8.6468e-05 - val_loss: 3.8360e-04\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3380e-04 - val_loss: 1.3644e-04\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.8262e-05 - val_loss: 4.7230e-04\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.9118e-04 - val_loss: 1.4932e-04\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.0428e-04 - val_loss: 4.2652e-04\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2295e-04 - val_loss: 1.1326e-04\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 9.2368e-05 - val_loss: 2.7877e-04\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.8641e-04 - val_loss: 9.2926e-05\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.3354e-05 - val_loss: 1.9870e-04\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.3251e-04 - val_loss: 8.0288e-05\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2910e-05 - val_loss: 1.7192e-04\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0347e-04 - val_loss: 6.8973e-05\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.3730e-05 - val_loss: 1.5867e-04\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.0712e-05 - val_loss: 6.2377e-05\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.0039e-05 - val_loss: 1.5379e-04\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.6094e-05 - val_loss: 5.9331e-05\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.9179e-05 - val_loss: 1.5551e-04\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.6261e-05 - val_loss: 5.9202e-05\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.0112e-05 - val_loss: 1.6221e-04\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.9786e-05 - val_loss: 6.1727e-05\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2394e-05 - val_loss: 1.7219e-04\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 9.5919e-05 - val_loss: 6.6381e-05\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.5682e-05 - val_loss: 1.8303e-04\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0385e-04 - val_loss: 7.2014e-05\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 3.9452e-05 - val_loss: 1.9124e-04\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1221e-04 - val_loss: 7.6916e-05\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.2893e-05 - val_loss: 1.9319e-04\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 1.1890e-04 - val_loss: 7.9558e-05\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5035e-05 - val_loss: 1.8725e-04\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.2176e-04 - val_loss: 7.9540e-05\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5185e-05 - val_loss: 1.7561e-04\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1993e-04 - val_loss: 7.7636e-05\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.3459e-05 - val_loss: 1.6283e-04\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.1467e-04 - val_loss: 7.4943e-05\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.0797e-05 - val_loss: 1.5260e-04\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0840e-04 - val_loss: 7.2319e-05\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.8307e-05 - val_loss: 1.4623e-04\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 1.0311e-04 - val_loss: 7.0353e-05\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.6662e-05 - val_loss: 1.4341e-04\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.9677e-05 - val_loss: 6.9368e-05\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.6033e-05 - val_loss: 1.4329e-04\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 9.8139e-05 - val_loss: 6.9407e-05\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 3.6293e-05 - val_loss: 1.4489e-04\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 9.8110e-05 - val_loss: 7.0263e-05\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 3.7184e-05 - val_loss: 1.4722e-04\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 9.9037e-05 - val_loss: 7.1553e-05\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 3.8391e-05 - val_loss: 1.4940e-04\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 1.0032e-04 - val_loss: 7.2840e-05\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 3.9604e-05 - val_loss: 1.5080e-04\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 1.0143e-04 - val_loss: 7.3779e-05\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 4.0580e-05 - val_loss: 1.5125e-04\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 1.0201e-04 - val_loss: 7.4243e-05\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 4.1214e-05 - val_loss: 1.5119e-04\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.0199e-04 - val_loss: 7.4355e-05\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 4.1576e-05 - val_loss: 1.5144e-04\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 1.0165e-04 - val_loss: 7.4439e-05\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 4.1894e-05 - val_loss: 1.5299e-04\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.0148e-04 - val_loss: 7.4922e-05\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 4.2488e-05 - val_loss: 1.5681e-04\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 1.0209e-04 - val_loss: 7.6253e-05\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 4.3697e-05 - val_loss: 1.6363e-04\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 1.0407e-04 - val_loss: 7.8819e-05\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 4.5826e-05 - val_loss: 1.7393e-04\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.0797e-04 - val_loss: 8.2833e-05\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 4.9095e-05 - val_loss: 1.8757e-04\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.1412e-04 - val_loss: 8.8086e-05\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 5.3533e-05 - val_loss: 2.0323e-04\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.2237e-04 - val_loss: 9.3575e-05\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 5.8736e-05 - val_loss: 2.1761e-04\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 1.3145e-04 - val_loss: 9.7352e-05\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 6.3554e-05 - val_loss: 2.2583e-04\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 1.3843e-04 - val_loss: 9.7472e-05\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 6.6141e-05 - val_loss: 2.2461e-04\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 1.3974e-04 - val_loss: 9.3838e-05\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 6.5063e-05 - val_loss: 2.1596e-04\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 1.3413e-04 - val_loss: 8.8214e-05\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 6.0765e-05 - val_loss: 2.0488e-04\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 1.2409e-04 - val_loss: 8.2158e-05\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 5.5130e-05 - val_loss: 1.9432e-04\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.1311e-04 - val_loss: 7.6405e-05\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 4.9717e-05 - val_loss: 1.8491e-04\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 1.0319e-04 - val_loss: 7.1392e-05\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 4.5193e-05 - val_loss: 1.7690e-04\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 9.4926e-05 - val_loss: 6.7390e-05\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 4.1723e-05 - val_loss: 1.7058e-04\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 8.8349e-05 - val_loss: 6.4494e-05\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 3.9277e-05 - val_loss: 1.6608e-04\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 8.3255e-05 - val_loss: 6.2663e-05\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 3.7745e-05 - val_loss: 1.6333e-04\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 7.9368e-05 - val_loss: 6.1772e-05\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 3.6981e-05 - val_loss: 1.6207e-04\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 7.6389e-05 - val_loss: 6.1616e-05\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 3.6809e-05 - val_loss: 1.6193e-04\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 7.4012e-05 - val_loss: 6.1935e-05\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 3.7037e-05 - val_loss: 1.6257e-04\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 7.1980e-05 - val_loss: 6.2515e-05\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.7512e-05 - val_loss: 1.6377e-04\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 7.0159e-05 - val_loss: 6.3309e-05\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 3.8201e-05 - val_loss: 1.6554e-04\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.8571e-05 - val_loss: 6.4398e-05\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 3.9164e-05 - val_loss: 1.6792e-04\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.7284e-05 - val_loss: 6.5812e-05\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.0451e-05 - val_loss: 1.7079e-04\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.6290e-05 - val_loss: 6.7443e-05\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.2034e-05 - val_loss: 1.7385e-04\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.5509e-05 - val_loss: 6.9109e-05\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3848e-05 - val_loss: 1.7686e-04\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 6.4867e-05 - val_loss: 7.0659e-05\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.5843e-05 - val_loss: 1.7971e-04\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 6.4350e-05 - val_loss: 7.2035e-05\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8018e-05 - val_loss: 1.8251e-04\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.4036e-05 - val_loss: 7.3293e-05\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0416e-05 - val_loss: 1.8560e-04\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.4096e-05 - val_loss: 7.4595e-05\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.3093e-05 - val_loss: 1.8950e-04\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.4775e-05 - val_loss: 7.6197e-05\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 5.6074e-05 - val_loss: 1.9489e-04\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.6345e-05 - val_loss: 7.8403e-05\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 5.9281e-05 - val_loss: 2.0236e-04\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.9024e-05 - val_loss: 8.1488e-05\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.2464e-05 - val_loss: 2.1220e-04\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 7.2875e-05 - val_loss: 8.5564e-05\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.5205e-05 - val_loss: 2.2393e-04\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 7.7724e-05 - val_loss: 9.0418e-05\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.7048e-05 - val_loss: 2.3610e-04\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.3190e-05 - val_loss: 9.5430e-05\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.7752e-05 - val_loss: 2.4628e-04\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.8696e-05 - val_loss: 9.9444e-05\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 6.7271e-05 - val_loss: 2.5136e-04\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 9.3161e-05 - val_loss: 1.0062e-04\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.5269e-05 - val_loss: 2.4832e-04\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.5037e-05 - val_loss: 9.7872e-05\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.1406e-05 - val_loss: 2.3771e-04\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.4093e-05 - val_loss: 9.2905e-05\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.6774e-05 - val_loss: 2.2400e-04\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 9.1695e-05 - val_loss: 8.7959e-05\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.2774e-05 - val_loss: 2.1084e-04\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 8.8715e-05 - val_loss: 8.3800e-05\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 4.9621e-05 - val_loss: 1.9961e-04\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.5386e-05 - val_loss: 8.0465e-05\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.7100e-05 - val_loss: 1.9051e-04\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 8.1856e-05 - val_loss: 7.7882e-05\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5093e-05 - val_loss: 1.8333e-04\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.8301e-05 - val_loss: 7.5961e-05\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.3567e-05 - val_loss: 1.7779e-04\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.4858e-05 - val_loss: 7.4592e-05\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.2509e-05 - val_loss: 1.7351e-04\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.1587e-05 - val_loss: 7.3625e-05\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.1885e-05 - val_loss: 1.7009e-04\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.8473e-05 - val_loss: 7.2878e-05\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 4.1641e-05 - val_loss: 1.6704e-04\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.5453e-05 - val_loss: 7.2144e-05\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1714e-05 - val_loss: 1.6389e-04\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 6.2436e-05 - val_loss: 7.1202e-05\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2040e-05 - val_loss: 1.6011e-04\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.9329e-05 - val_loss: 6.9822e-05\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2555e-05 - val_loss: 1.5520e-04\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.6046e-05 - val_loss: 6.7781e-05\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.3200e-05 - val_loss: 1.4863e-04\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.2519e-05 - val_loss: 6.4889e-05\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.3916e-05 - val_loss: 1.3998e-04\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8714e-05 - val_loss: 6.1039e-05\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.4639e-05 - val_loss: 1.2899e-04\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.4645e-05 - val_loss: 5.6279e-05\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5294e-05 - val_loss: 1.1576e-04\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.0397e-05 - val_loss: 5.0911e-05\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5794e-05 - val_loss: 1.0095e-04\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.6148e-05 - val_loss: 4.5566e-05\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.6052e-05 - val_loss: 8.5889e-05\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.2187e-05 - val_loss: 4.1159e-05\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.6021e-05 - val_loss: 7.2455e-05\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8905e-05 - val_loss: 3.8594e-05\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5748e-05 - val_loss: 6.2527e-05\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.6721e-05 - val_loss: 3.8256e-05\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5443e-05 - val_loss: 5.7209e-05\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.5994e-05 - val_loss: 3.9714e-05\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5560e-05 - val_loss: 5.6575e-05\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.7019e-05 - val_loss: 4.2258e-05\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.6905e-05 - val_loss: 6.0438e-05\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.0236e-05 - val_loss: 4.6059e-05\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0634e-05 - val_loss: 6.9365e-05\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 3.6439e-05 - val_loss: 5.2253e-05\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 5.7684e-05 - val_loss: 8.4031e-05\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.6135e-05 - val_loss: 6.0804e-05\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.7256e-05 - val_loss: 1.0250e-04\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.7563e-05 - val_loss: 6.8592e-05\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 7.5546e-05 - val_loss: 1.1812e-04\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 6.5574e-05 - val_loss: 7.1026e-05\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 7.7452e-05 - val_loss: 1.2215e-04\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 6.5011e-05 - val_loss: 6.5946e-05\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 7.1211e-05 - val_loss: 1.1081e-04\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.5920e-05 - val_loss: 5.5645e-05\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 6.0195e-05 - val_loss: 8.8720e-05\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.2973e-05 - val_loss: 4.4854e-05\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.8824e-05 - val_loss: 6.4456e-05\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.0527e-05 - val_loss: 3.7416e-05\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8937e-05 - val_loss: 4.5406e-05\n"
          ]
        }
      ],
      "source": [
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square((y_pred[:, 2] - y_pred[:, 1]))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(9))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX, trainY, epochs=500, batch_size=64, validation_data=(testX, testY), shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 2ms/step\n",
            "(227, 9)\n",
            "(227, 157)\n",
            "Test RMSE: 144.558\n",
            "Test MAE: 104.901\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "yhat = model.predict(testX)\n",
        "print(yhat.shape)\n",
        "testX = testX.reshape((testX.shape[0], testX.shape[2]))\n",
        "print(testX.shape)\n",
        "inv_yhat = np.concatenate((testX, yhat), axis=1)\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat1 = inv_yhat[:, -3:]\n",
        "inv_yhat = inv_yhat[:, -3]\n",
        "inv_y = np.concatenate((testX, testY), axis=1)\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y1 = inv_y[:, -3:]\n",
        "inv_y = inv_y[:, -3]\n",
        "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
